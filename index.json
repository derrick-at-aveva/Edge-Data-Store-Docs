{
    "V1/SDS/UOM/Supported_UOM_1-0.html":  {
                                              "href":  "V1/SDS/UOM/Supported_UOM_1-0.html",
                                              "title":  "Supported units of measure",
                                              "keywords":  "Supported units of measure The following table shows the supported units of measure. Supported units of measure are read-only. Uom Id Abbreviation Quantity Id Conversion Factor Conversion Offset count count Quantity 1 0 Ampere hour Ah Electric Charge 3600 0 coulomb C Electric Charge 1 0 kilogram per second kg/s kg s Mass Flow Rate 1 0 long ton per day lton/d lton d Mass Flow Rate 0.011759802 0 million pound per day MMlb/d MMlb d Mass Flow Rate 5.24991169 0 short ton per day ston/d ston d Mass Flow Rate 0.010499823 0 thousand pound per day klb/d klb d Mass Flow Rate 0.005249912 0 gram per second g/s g s Mass Flow Rate 0.001 0 pound per second lb/s lb s Mass Flow Rate 0.45359237 0 tonne per day t/d t d Mass Flow Rate 0.011574074 0 long ton lton Mass 1016.046909 0 million pound MM lb Mass 453592.37 0 ounce oz Mass 0.028349523 0 short ton ston Mass 907.18474 0 thousand pound klb Mass 453.59237 0 ton ton Mass 907.18474 0 gram g Mass 0.001 0 milligram mg Mass 1.00E-06 0 pound lb Mass 0.45359237 0 tonne t Mass 1000 0 kilogram kg Mass 1 0 second s Time 1 0 hour h Time 3600 0 day d Time 86400 0 month month Time 2628000 0 week week Time 604800 0 year yr Time 31536000 0 minute min Time 60 0 dyne dyne Force 1.00E-05 0 kilogram-force kgf Force 9.80665 0 pound-force lbf Force 4.448221615 0 newton N Force 1 0 watt W Power 1 0 million British thermal unit per day MM Btu/d Btu d Power 12211.29459 0 million British thermal unit per hour MM Btu/h Btu h Power 293071.0702 0 gigawatt GW Power 1000000000 0 megawatt MW Power 1000000 0 British thermal unit per hour Btu/h Btu h Power 0.29307107 0 calorie per second cal/s cal s Power 4.1868 0 horsepower hp Power 745.6998716 0 joule per second J/s J s Power 1 0 kilowatt kW Power 1000 0 megajoule per hour MJ/h MJ h Power 277.7777778 0 million calorie per hour MMcal/h MMcal h Power 1163 0 mole per second mol/s mol s Molar Flow Rate 1 0 gram mole per second gmol/s gmol s Molar Flow Rate 1 0 kilogram mole per second kmol/s kmol s Molar Flow Rate 1000 0 pound mole per second lbmol/s lbmol s Molar Flow Rate 453.59237 0 meter m Length 1 0 centimeter cm Length 0.01 0 inch in Length 0.0254 0 International nautical mile nmi Length 1852 0 kilometer km Length 1000 0 millimeter mm Length 0.001 0 foot ft Length 0.3048 0 mile mi Length 1609.344 0 sixteenth of an inch sxi Length 0.0015875 0 yard yd Length 0.9144 0 candela cd Luminous Intensity 1 0 meter per second m/s m s Speed 1 0 centimeter per second cm/s cm s Speed 0.01 0 foot per second ft/s ft s Speed 0.3048 0 International nautical mile per hour nmi/h nmi h Speed 0.514444444 0 kilometer per hour km/h km h Speed 0.277777778 0 mile per hour mi/h mi h Speed 0.44704 0 revolution per minute rpm Angular Velocity 0.104719755 0 radian per second rad/s rad s Angular Velocity 1 0 barrel per day bbl/d bbl d Volume Flow Rate 1.84E-06 0 cubic centimeter per second cm3/s cm3 s Volume Flow Rate 1.00E-06 0 cubic foot per second ft3/s ft3 s Volume Flow Rate 0.028316847 0 cubic meter per hour m3/h m3 h Volume Flow Rate 0.000277778 0 Imperial gallon per minute Imp gal/min gal min Volume Flow Rate 7.58E-05 0 liter per second L/s L s Volume Flow Rate 0.001 0 US gallon per minute US gal/min gal min Volume Flow Rate 6.31E-05 0 cubic meter per second m3/s m3 s Volume Flow Rate 1 0 pascal Pa Pressure 1 0 atmosphere atm Pressure 101325 0 bar bar Pressure 100000 0 inches of mercury inHg Pressure 3386.388158 0 kilogram-force per square centimeter kgf/cm2 kgf cm2 Pressure 98066.5 0 kilogram-force per square meter kgf/m2 kgf m2 Pressure 9.80665 0 kilopascal kPa Pressure 1000 0 millimeter of mercury mmHg Pressure 133.3223684 0 newton per square meter N/m2 N m2 Pressure 1 0 pound-force per square inch psi Pressure 6894.757293 0 pound-force per square inch (customary) psia Pressure 6894.757293 0 torr torr Pressure 133.3223684 0 square meter m2 Area 1 0 square foot ft2 Area 0.09290304 0 acre acre Area 4046.856422 0 square mile mi2 Area 2589988.11 0 square yard yd2 Area 0.83612736 0 hectare ha Area 10000 0 square centimeter cm2 Area 0.0001 0 square inch in2 Area 0.00064516 0 square kilometer km2 Area 1000000 0 square millimeter mm2 Area 1.00E-06 0 yobibyte YiB Computer Storage 1.21E+24 0 zebibyte ZiB Computer Storage 1.18E+21 0 exbibyte EiB Computer Storage 1.15E+18 0 pebibyte PiB Computer Storage 1.13E+15 0 tebibyte TiB Computer Storage 1.10E+12 0 gibibyte GiB Computer Storage 1073741824 0 mebibyte MiB Computer Storage 1048576 0 kibibyte KiB Computer Storage 1024 0 yottabyte YB Computer Storage 1.00E+24 0 zettabyte ZB Computer Storage 1.00E+21 0 exabyte EB Computer Storage 1.00E+18 0 petabyte PB Computer Storage 1.00E+15 0 terabyte TB Computer Storage 1.00E+12 0 gigabyte GB Computer Storage 1000000000 0 megabyte MB Computer Storage 1000000 0 kilobyte kB Computer Storage 1000 0 byte B Computer Storage 1 0 kelvin K Temperature 1 0 degree Celsius ??C Temperature 1 273.15 degree Rankine ??R Temperature 0.555555556 -2.56E-13 degree Fahrenheit ??F Temperature 0.555555556 255.3722222 milliampere mA Electric Current 0.001 0 ampere A Electric Current 1 0 joule per gram J/g J g Specific Energy 1000 0 joule per kilogram J/kg J kg Specific Energy 1 0 British thermal unit per pound Btu/lb Btu lb Specific Energy 2326 0 kilocalorie per kilogram kcal/kg kcal kg Specific Energy 4186.8 0 kilojoule per kilogram kJ/kg kJ kg Specific Energy 1000 0 kilojoule per pound kJ/lb kJ lb Specific Energy 2204.622622 0 British thermal unit per degree Rankine Btu/??R Btu ??R Entropy and Heat Capacity 1899.100535 0 British thermal unit per degree Fahrenheit Btu/??F Btu ??F Entropy and Heat Capacity 1899.100535 0 kilojoule per kelvin kJ/K kJ K Entropy and Heat Capacity 1000 0 joule per kelvin J/K J K Entropy and Heat Capacity 1 0 cubic foot per pound ft3/lb ft3 lb Specific Volume 0.062427961 0 cubic centimeter per gram cm3/g cm3 g Specific Volume 0.001 0 cubic meter per kilogram m3/kg m3 kg Specific Volume 1 0 hertz Hz Frequency 1 0 mole mol Amount of Substance 1 0 gram mole gmol Amount of Substance 1 0 kilogram mole kmol Amount of Substance 1000 0 pound mole lbmol Amount of Substance 453.59237 0 percent % Ratio 1 0 parts per billion ppb Ratio 1.00E-07 0 parts per million ppm Ratio 0.0001 0 ohm ?? Electric Resistance 1 0 gram per gram mole g/gmol g gmol Molecular Weight 0.001 0 pound per pound mole lb/lbmol lb lbmol Molecular Weight 0.001 0 kilogram per mole kg/mol kg mol Molecular Weight 1 0 kilogram per kilogram mole kg/kmol kg kmol Molecular Weight 0.001 0 British thermal unit per pound degree Rankine Btu/(lb Btu (lb ??R) Specific Entropy and Specific Heat Capacity 4186.8 0 British thermal unit per pound degree Fahrenheit Btu/(lb Btu (lb ??F) Specific Entropy and Specific Heat Capacity 4186.8 0 joule per gram kelvin J/(g J (g K) Specific Entropy and Specific Heat Capacity 1000 0 kilojoule per kilogram kelvin kJ/(kg kJ (kg K) Specific Entropy and Specific Heat Capacity 1000 0 joule per kilogram kelvin J/(kg J (kg K) Specific Entropy and Specific Heat Capacity 1 0 kilovolt kV Electric Potential 1000 0 millivolt mV Electric Potential 0.001 0 megavolt MV Electric Potential 1000000 0 volt V Electric Potential 1 0 joule J Energy 1 0 gigawatt hour GWh Energy 3.60E+12 0 megawatt hour MWh Energy 3600000000 0 watt hour Wh Energy 3600 0 British thermal unit Btu Energy 1055.055853 0 calorie cal Energy 4.1868 0 gigajoule GJ Energy 1000000000 0 kilojoule kJ Energy 1000 0 kilowatt hour kWh Energy 3600000 0 megajoule MJ Energy 1000000 0 watt second Ws Energy 1 0 kilocalorie kcal Energy 4186.8 0 million calorie MMcal Energy 4186800 0 million British thermal unit MM Btu Energy 1055055853 0 acre foot acre ft Volume 1233.481838 0 million imperial gallon Imp Mgal Volume 4546.09 0 thousand imperial gallon Imp kgal Volume 4.54609 0 barrel bbl Volume 0.158987295 0 Imperial gallon Imp gal Volume 0.00454609 0 million US gallon US Mgal Volume 3785.411784 0 thousand US gallon US kgal Volume 3.785411784 0 cubic centimeter cm3 Volume 1.00E-06 0 cubic foot ft3 Volume 0.028316847 0 kiloliter kL Volume 1 0 liter L Volume 0.001 0 megaliter M L Volume 1000 0 milliliter mL Volume 1.00E-06 0 thousand cubic meter k m3 Volume 1000 0 US gallon US gal Volume 0.003785412 0 million barrel MMbbl Volume 158987.2949 0 thousand barrel kbbl Volume 158.9872949 0 cubic meter m3 Volume 1 0 kilogram per cubic meter kg/m3 kg m3 Density 1 0 gram per liter g/L g L Density 1 0 kilogram per liter kg/L kg L Density 1000 0 pound per barrel lb/bbl lb bbl Density 2.853010174 0 pound per cubic foot lb/ft3 lb ft3 Density 16.01846337 0 pound per US gallon lb/US lb US gal Density 119.8264273 0 tonne per cubic meter t/m3 t m3 Density 1000 0 radian rad Plane Angle 1 0 degree ?? Plane Angle 0.017453293 0 revolution r Plane Angle 6.283185307 0 pascal second Pa*s Dynamic Viscosity 1 0 poise P Dynamic Viscosity 0.1 0 delta degree Fahrenheit delta ??F Temperature (Delta) 0.555555556 0 delta degree Rankine delta ??R Temperature (Delta) 0.555555556 0 delta kelvin delta K Temperature (Delta) 1 0 delta degree Celsius delta ??C Temperature (Delta) 1 0"
                                          },
    "V1/SDS/UOM/SdsUOMQuantity_API_1-0.html":  {
                                                   "href":  "V1/SDS/UOM/SdsUOMQuantity_API_1-0.html",
                                                   "title":  "SdsUomQuantity API",
                                                   "keywords":  "SdsUomQuantity API The REST APIs provide programmatic access to read and write SDS data. The APIs in this section interact with SdsUomQuantitys. For more information, see SdsUomQuantity . Get Quantity Returns the quantity corresponding to the specified quantity Id within a given namespace. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Quantities/{quantityId} api v1 Tenants default Namespaces {namespaceId} Quantities {quantityId} Parameters string namespaceId The namespace; either default or diagnostics. string quantityId The quantity identifier. Response The response includes a status code and a response body. Response body The requested SdsUomQuantity. Example response body for quantityId = \"Length\": HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"Id\": \"Length\", \"Name\": \"Length\", \"BaseUom\": { \"Id\": \"meter\", \"Abbreviation\": \"m\", \"Name\": \"meter\", \"DisplayName\": \"meter\", \"QuantityId\": \"Length\", \"ConversionFactor\": 1 }, \"Dimensions\": [ 1, 0, 0, 0, 0, 0, 0 ] } Get Quantities Returns a list of all quantities available within a given namespace. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Quantities?skip={skip}\u0026count={count} api v1 Tenants default Namespaces {namespaceId} Quantities?skip={skip}\u0026count={count} Parameters string namespaceId The namespace; either default or diagnostics. int skip An optional parameter representing the zero-based offset of the first SdsUomQuantity to retrieve. If not specified, a default value of 0 is used. int count An optional parameter representing the maximum number of SdsUomQuantity to retrieve. If not specified, a default value of 100 is used. Response The response includes a status code and a response body. Response body A list of SdsUomQuantity objects. Example response body: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Id\": \"Angular Velocity\", \"Name\": \"Angular Velocity\", \"BaseUom\": { \"Id\": \"radian per second\", \"Abbreviation\": \"rad/s\", \"rad s\", \"Name\": \"radian per second\", \"DisplayName\": \"radian per second\", \"QuantityId\": \"Angular Velocity\", \"ConversionFactor\": 1 }, \"Dimensions\": [ 0, 0, -1, 0, 0, 0, 0 ] }, { \"Id\": \"Area\", \"Name\": \"Area\", \"BaseUom\": { \"Id\": \"square meter\", \"Abbreviation\": \"m2\", \"Name\": \"square meter\", \"DisplayName\": \"square meter\", \"QuantityId\": \"Area\", \"ConversionFactor\": 1 }, \"Dimensions\": [ 2, 0, 0, 0, 0, 0, 0 ] }, ] Get Quantity Uom Returns the unit of measure associated with the specified uomId belonging to the quantity with the specified quantityId. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Quantities/{quantityId}/Units/{uomId} api v1 Tenants default Namespaces {namespaceId} Quantities {quantityId} Units {uomId} Parameters string namespaceId The namespace; either default or diagnostics. string quantityId The quantity identifier. string uomId The unit of measure identifier. Response The response includes a status code and a response body. Response body The requested SdsUom Example response for quantityId = \"Length\" and uomId =\"mile\": HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"Id\": \"mile\", \"Abbreviation\": \"mi\", \"Name\": \"mile\", \"DisplayName\": \"mile\", \"QuantityId\": \"Length\", \"ConversionFactor\": 1609.344 } Get Quantity Uoms Returns the list of units of measure that belongs to the quantity with the specified quantityId. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Quantities/{quantityId}/Units api v1 Tenants default Namespaces {namespaceId} Quantities {quantityId} Units Parameters string namespaceId The namespace; either default or diagnostics. string quantityId The quantity identifier. Response The response includes a status code and a response body. Response body A collection of SdsUom objects for the specified quantity. Example response for quantityId = \"Electric Current\": HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Id\": \"milliampere\", \"Abbreviation\": \"mA\", \"Name\": \"milliampere\", \"DisplayName\": \"milliampere\", \"QuantityId\": \"Electric Current\", \"ConversionFactor\": 0.001 }, { \"Id\": \"ampere\", \"Abbreviation\": \"A\", \"Name\": \"ampere\", \"DisplayName\": \"ampere\", \"QuantityId\": \"Electric Current\", \"ConversionFactor\": 1 } ]"
                                               },
    "V1/SDS/UOM/SdsUOMAPI_1-0.html":  {
                                          "href":  "V1/SDS/UOM/SdsUOMAPI_1-0.html",
                                          "title":  "SdsUom API",
                                          "keywords":  "SdsUom API The REST APIs provide programmatic access to read and write SDS data. The APIs in this section interact with SdsUoms. For more information, see SdsUom . Get Uom Returns the unit of measure corresponding to the specified uomId within a given namespace. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Units/{uomId} api v1 Tenants default Namespaces {namespaceId} Units {uomId} Parameters string namespaceId The namespace; either default or diagnostics. string uomId The unit of measure identifier. Response The response includes a status code and a response body. Response body The requested SdsUom. Example response body for uomId = \"ounce\": HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"Id\": \"ounce\", \"Abbreviation\": \"oz\", \"Name\": \"ounce\", \"DisplayName\": \"ounce\", \"QuantityId\": \"Mass\", \"ConversionFactor\": 0.028349523 } Get Uoms Returns a list of all available units of measure in the system. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Units?skip={skip}\u0026count={count} api v1 Tenants default Namespaces {namespaceId} Units?skip={skip}\u0026count={count} Parameters string namespaceId The namespace; either default or diagnostics. int skip An optional parameter representing the zero-based offset of the first SdsUomQuantity to retrieve. If not specified, a default value of 0 is used. int count An optional parameter representing the maximum number of SdsUomQuantity to retrieve. If not specified, a default value of 100 is used. Response The response includes a status code and a response body. Response body A list of SdsUom objects. Example response body: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Id\": \"count\", \"Abbreviation\": \"count\", \"Name\": \"count\", \"DisplayName\": \"count\", \"QuantityId\": \"Quantity\", \"ConversionFactor\": 1 }, { \"Id\": \"Ampere hour\", \"Abbreviation\": \"Ah\", \"Name\": \"Ampere hour\", \"DisplayName\": \"Ampere hour\", \"QuantityId\": \"Electric Charge\", \"ConversionFactor\": 3600 }, { \"Id\": \"coulomb\", \"Abbreviation\": \"C\", \"Name\": \"coulomb\", \"DisplayName\": \"coulomb\", \"QuantityId\": \"Electric Charge\", \"ConversionFactor\": 1 } ] Associate a unit of measure with an SdsType At SdsType creation, you can associate an SdsUom with an SdsTypeProperty. For more information, see SdsTypeProperty . Associate a unit of measure with an SdsStream At SdsStream creation, you can override any unit of measure associated with an SdsTypeProperty belonging to the SdsType of the stream. This enables the reuse of an SdsType that may have default unit information associated with it already. For more information, see SdsStream ."
                                      },
    "V1/SDS/Types/SDS_Type_Examples_1-0.html":  {
                                                    "href":  "V1/SDS/Types/SDS_Type_Examples_1-0.html",
                                                    "title":  "Examples of SdsTypes",
                                                    "keywords":  "Examples of SdsTypes The examples in this section refer to the following types and are defined in Python and JavaScript samples. In the sample code, SdsType , SdsTypeProperty , and SdsTypeCode are defined as in the code snippets shown here: Python class SdsTypeCode(Enum): Empty = 0 Object = 1 DBNull = 2 Boolean = 3 Char = 4 ... class SdsTypeProperty(object): \"\"\"SDS type property definition\"\"\" def __init__(self): self.__isKey = False @property def Id(self): return self.__id @Id.setter def Id(self, id): self.__id = id ... @property def IsKey(self): return self.__isKey @IsKey.setter def IsKey(self, iskey): self.__isKey = iskey @property def SdsType(self): return self.__SdsType @SdsType.setter def SdsType(self, SdsType): self.__SdsType=SdsType ... class SdsType(object): \"\"\"SDS type definitions\"\"\" def __init__(self): self.SdsTypeCode = SdsTypeCode.Object @property def Id(self): return self.__id @Id.setter def Id(self, id): self.__id = id ... @property def BaseType(self): return self.__baseType @BaseType.setter def BaseType(self, baseType): self.__baseType = baseType @property def SdsTypeCode(self): return self.__typeCode @SdsTypeCode.setter def SdsTypeCode(self, typeCode): self.__typeCode = typeCode @property def Properties(self): return self.__properties @Properties.setter def Properties(self, properties): self.__properties = properties JavaScript SdsTypeCodeMap: { Empty: 0, \"Object\": 1, DBNull: 2, \"Boolean\": 3, Char: 4, ... SdsTypeProperty: function (SdsTypeProperty) { if (SdsTypeProperty.Id) { this.Id = SdsTypeProperty.Id; } if (SdsTypeProperty.Name) { this.Name = SdsTypeProperty.Name; } if (SdsTypeProperty.Description) { this.Description = SdsTypeProperty.Description; } if (SdsTypeProperty.SdsType) { this.SdsType = SdsTypeProperty.SdsType; } if (SdsTypeProperty.IsKey) { this.IsKey = SdsTypeProperty.IsKey; } }, SdsType: function (SdsType) { if (SdsType.Id) { this.Id = SdsType.Id } if (SdsType.Name) { this.Name = SdsType.Name; } if (SdsType.Description) { this.Description = SdsType.Description; } if (SdsType.SdsTypeCode) { this.SdsTypeCode = SdsType.SdsTypeCode; } if (SdsType.Properties) { this.Properties = SdsType.Properties; } }, Working with the following types (both Python and JavaScript classes are shown): Python class State(Enum): Ok = 0 Warning = 1 Alarm = 2 class Simple(object): Time = property(getTime, setTime) def getTime(self): return self.__time def setTime(self, time): self.__time = time State = property(getState, setState) def getState(self): return self.__state def setState(self, state): self.__state = state Measurement = property(getMeasurement, setMeasurement) def getMeasurement(self): return self.__measurement def setMeasurement(self, measurement): self.__measurement = measurement JavaScript var State = { Ok: 0, Warning: 1, Alarm: 2, } var Simple = function () { this.Time = null; this.State = null; this.Measurement = null; } Define the SdsType as follows: Python # Create the properties # Time is the primary key time = SdsTypeProperty() time.Id = \"Time\" time.Name = \"Time\" time.IsKey = True time.SdsType = SdsType() time.SdsType.Id = \"DateTime\" time.SdsType.Name = \"DateTime\" time.SdsType.SdsTypeCode = SdsTypeCode.DateTime # State is not a pre-defined type. A SdsType must be defined to represent the enum stateTypePropertyOk = SdsTypeProperty() stateTypePropertyOk.Id = \"Ok\" stateTypePropertyOk.Value = State.Ok stateTypePropertyWarning = SdsTypeProperty() stateTypePropertyWarning.Id = \"Warning\" stateTypePropertyWarning.Value = State.Warning stateTypePropertyAlarm = SdsTypeProperty() stateTypePropertyAlarm.Id = \"Alarm\" stateTypePropertyAlarm.Value = State.Alarm stateType = SdsType() stateType.Id = \"State\" stateType.Name = \"State\" stateType.Properties = [ stateTypePropertyOk, stateTypePropertyWarning, \\ stateTypePropertyAlarm ] state = SdsTypeProperty() state.Id = \"State\" state.Name = \"State\" state.SdsType = stateType # Value property is a simple non-indexed, pre-defined type value = SdsTypeProperty() value.Id = \"Measurement\" value.Name = \"Measurement\" value.SdsType = SdsType() value.SdsType.Id = \"Double\" value.SdsType.Name = \"Double\" # Create the Simple SdsType simpleType = SdsType() simpleType.Id = \"Simple\" simpleType.Name = \"Simple\" simpleType.Description = \"Basic sample type\" simpleType.SdsTypeCode = SdsTypeCode.Object simpleType.Properties = [ time ] JavaScript //    Time is the primary key var timeProperty = new SdsObjects.SdsTypeProperty({ \"Id\": \"Time\", \"IsKey\": true, \"SdsType\": new SdsObjects.SdsType({ \"Id\": \"dateType\", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.DateTime }) }); //    State is not a pre-defined type. An SdsType must be defined to represent the enum var stateTypePropertyOk = new SdsObjects.SdsTypeProperty({ \"Id\": \"Ok\", \"Value\": State.Ok }); var stateTypePropertyWarning = new SdsObjects.SdsTypeProperty({ \"Id\": \"Warning\", \"Value\": State.Warning }); var stateTypePropertyAlarm = new SdsObjects.SdsTypeProperty({ \"Id\": \"Alarm\", \"Value\": State.Alarm }); var stateType = new SdsObjects.SdsType({ \"Id\": \"State\", \"Name\": \"State\", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.Int32Enum, \"Properties\": [stateTypePropertyOk, stateTypePropertyWarning, stateTypePropertyAlarm, stateTypePropertyRed] }); //    Measurement property is a simple non-indexed, pre-defined type var measurementProperty = new SdsObjects.SdsTypeProperty({ \"Id\": \"Measurement\", \"Name\": \"Measurement\", \"SdsType\": new SdsObjects.SdsType({ \"Id\": \"doubleType\", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.Double }) }); //    Create the Simple SdsType var simpleType = new SdsObjects.SdsType({ \"Id\": \"Simple\", \"Name\": \"Simple\", \"Description\": \"This is a simple SDS type \", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.Object, \"Properties\": [timeProperty, stateProperty, measurementProperty] }); Working with a derived class is easy. For the following derived class: class Derived(Simple): @property def Observation(self): return self.__observation @Observation.setter def Observation(self, observation): self.__observation = observation Extend the SdsType as follows: Python # Observation property is a simple non-indexed, standard data type observation = SdsTypeProperty() observation.Id = \"Observation\" observation.Name = \"Observation\" observation.SdsType = SdsType() observation.SdsType.Id = \"String\" observation.SdsType.Name = \"String\" observation.SdsType.SdsTypeCode = SdsTypeCode.String # Create the Derived SdsType derived = SdsType() derived.Id = \"Derived\" derived.Name = \"Derived\" derived.Description = \"Derived sample type\" derived.BaseType = simpleType # Set the base type to the derived type derived.SdsTypeCode = SdsTypeCode.Object derived.Properties = [ observation ] JavaScript var observationProperty = new SdsObjects.SdsTypeProperty({ \"Id\": \"Observation\", \"SdsType\": new SdsObjects.SdsType({ \"Id\": \"strType\", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.String }) }); var derivedType = new SdsObjects.SdsType({ \"Id\": \"Derived\", \"Name\": \"Derived\", \"Description\": \" Derived sample type\", \"BaseType\": simpleType, \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.Object, \"Properties\": [ observationProperty ] });"
                                                },
    "V1/SDS/Types/SDSType_API_1-0.html":  {
                                              "href":  "V1/SDS/Types/SDSType_API_1-0.html",
                                              "title":  "SdsType API",
                                              "keywords":  "SdsType API The REST APIs provide programmatic access to read and write SDS data. The following APIs interact with SdsTypes. See Types for general SdsType information. Get Type Returns the type corresponding to the specified typeId within a given namespace. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Types/{typeId} api v1 Tenants default Namespaces {namespaceId} Types {typeId} Parameters string namespaceId The namespace; either default or diagnostics. string typeId The type identifier. Response The response includes a status code and a response body. Response body The requested SdsType. Example response body: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"Id\": \"Simple\", \"Name\": \"Simple\", \"SdsTypeCode\": 1, \"Properties\": [ { \"Id\": \"Time\", \"Name\": \"Time\", \"IsKey\": true, \"SdsType\": { \"Id\": \"19a87a76-614a-385b-ba48-6f8b30ff6ab2\", \"Name\": \"DateTime\", \"SdsTypeCode\": 16 } }, { \"Id\": \"State\", \"Name\": \"State\", \"SdsType\": { \"Id\": \"e20bdd7e-590b-3372-ab39-ff61950fb4f3\", \"Name\": \"State\", \"SdsTypeCode\": 609, \"Properties\": [ { \"Id\": \"Ok\", \"Value\": 0 }, { \"Id\": \"Warning\", \"Value\": 1 }, { \"Id\": \"Alarm\", \"Value\": 2 } ] } }, { \"Id\": \"Measurement\", \"Name\": \"Measurement\", \"SdsType\": { \"Id\": \"6fecef77-20b1-37ae-aa3b-e6bb838d5a86\", \"Name\": \"Double\", \"SdsTypeCode\": 14 } } ] } Get Type Reference Count Returns a dictionary mapping the object name to the number of references held by streams, stream views, and parent types for the specified type. For more information on the use of types to define streams and stream views, see Streams and Stream views . For further details about type referencing, see Type reusability . Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Types/{typeId}/ReferenceCount api v1 Tenants default Namespaces {namespaceId} Types {typeId} ReferenceCount Parameters string namespaceId The namespace; either default or diagnostics. string typeId The type identifier. Response The response includes a status code and a response body. Response body A dictionary mapping object name to number of references. Example response body: { \"SdsStream\": 3, \"SdsStreamView\": 2, \"SdsType\": 1 } Get Types Returns a list of types within a given namespace. If you specify the optional search query parameter, the list of types returned will match the search criteria. If you do not specify the search query parameter, the list will include all types in the namespace. For information about specifying those respective parameters, see Search in SDS . Note: The results will also include types that were automatically created by SDS as a result of type referencing. For further details about type referencing, see Type reusability . Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Types?query={query}\u0026skip={skip}\u0026count={count}\u0026orderby={orderby} api v1 Tenants default Namespaces {namespaceId} Types?query={query}\u0026skip={skip}\u0026count={count}\u0026orderby={orderby} Parameters string namespaceId The namespace; either default or diagnostics. string query An optional query string to match which SdsTypes will be returned. For information about specifying the query parameter, see Search in SDS . int skip An optional value representing the zero-based offset of the first SdsType to retrieve. If not specified, a default value of 0 is used. int count An optional value representing the maximum number of SdsTypes to retrieve. If not specified, a default value of 100 is used. string orderby An optional parameter representing sorted order which SdsTypes will be returned. A field name is required. The sorting is based on the stored values for the given field (of type string). For example, orderby=name would sort the returned results by the name values (ascending by default). Additionally, a value can be provided along with the field name to identify whether to sort ascending or descending, by using values asc or desc , respectively. For example, orderby=name desc would sort the returned results by the name values, descending. If no value is specified, there is no sorting of results. Response The response includes a status code and a response body. Response body A collection of zero or more SdsTypes. Example response body: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Id\": \"Simple\", \"Name\": \"Simple\", \"SdsTypeCode\": 1, \"Properties\": [ { \"Id\": \"Time\", \"Name\": \"Time\", \"IsKey\": true, \"SdsType\": { \"Id\": \"19a87a76-614a-385b-ba48-6f8b30ff6ab2\", \"Name\": \"DateTime\", \"SdsTypeCode\": 16 } }, { \"Id\": \"State\", \"Name\": \"State\", \"SdsType\": { \"Id\": \"e20bdd7e-590b-3372-ab39-ff61950fb4f3\", \"Name\": \"State\", \"SdsTypeCode\": 609, \"Properties\": [ { \"Id\": \"Ok\", \"Value\": 0 }, { \"Id\": \"Warning\", \"Value\": 1 }, { \"Id\": \"Alarm\", \"Value\": 2 } ] } }, { \"Id\": \"Measurement\", \"Name\": \"Measurement\", \"SdsType\": { \"Id\": \"6fecef77-20b1-37ae-aa3b-e6bb838d5a86\", \"Name\": \"Double\", \"SdsTypeCode\": 14 } } ] }, ] Get or Create Type Creates the specified type. If a type with a matching identifier already exists, SDS compares the existing type with the type that was sent. If the types are identical, a Found (302) error is returned with the Location header set to the URI where the type may be retrieved using a Get function. If the types do not match, a Conflict (409) error is returned. Note: A Conflict (409) error will also be returned if the type contains reference to any existing type, but the referenced type definition in the body does not match the existing type. You may reference an existing type without including the reference type definition in the body by using only the Ids. For further details about type referencing, see Type reusability . For a matching type ( Found ), clients that are capable of performing a redirect that includes the authorization header can automatically redirect to retrieve the type. However, most clients, including the .NET HttpClient, consider redirecting with the authorization token to be a security vulnerability. When a client performs a redirect and strips the authorization header, SDS cannot authorize the request and returns Unauthorized (401). For this reason, OSIsoft recommends that when using clients that do not redirect with the authorization header, you should disable automatic redirect and perform the redirect manually. Request POST api/v1/Tenants/default/Namespaces/{namespaceId}/Types/{typeId} api v1 Tenants default Namespaces {namespaceId} Types {typeId} Parameters string namespaceId The namespace; either default or diagnostics. string typeId The type identifier. The identifier must match the SdsType.Id field in the request body. Request body The request content is the serialized SdsType. Example SdsType content: { \"Id\": \"Simple\", \"Name\": \"Simple\", \"SdsTypeCode\": 1, \"Properties\": [ { \"Id\": \"Time\", \"Name\": \"Time\", \"IsKey\": true, \"SdsType\": { \"Id\": \"19a87a76-614a-385b-ba48-6f8b30ff6ab2\", \"Name\": \"DateTime\", \"SdsTypeCode\": 16 } }, { \"Id\": \"State\", \"Name\": \"State\", \"SdsType\": { \"Id\": \"e20bdd7e-590b-3372-ab39-ff61950fb4f3\", \"Name\": \"State\", \"SdsTypeCode\": 609, \"Properties\": [ { \"Id\": \"Ok\", \"Value\": 0 }, { \"Id\": \"Warning\", \"Value\": 1 }, { \"Id\": \"Alarm\", \"Value\": 2 } ] } }, { \"Id\": \"Measurement\", \"Name\": \"Measurement\", \"SdsType\": { \"Id\": \"6fecef77-20b1-37ae-aa3b-e6bb838d5a86\", \"Name\": \"Double\", \"SdsTypeCode\": 14 } } ] } Response The response includes a status code and a response body. Response body The request content is the serialized SdsType. OSIsoft recommends that you use JSON. Example Response body: HTTP/1.1 HTTP 1.1 201 Content-Type: application/json application json { \"Id\": \"Simple\", \"Name\": \"Simple\", \"Description\": null, \"SdsTypeCode\": 1, \"IsGenericType\": false, \"IsReferenceType\": false, \"GenericArguments\": null, \"Properties\": [ { \"Id\": \"Time\", \"Name\": \"Time\", \"Description\": null, \"Order\": 0, \"IsKey\": true, \"FixedSize\": 0, \"SdsType\": { \"Id\": \"19a87a76-614a-385b-ba48-6f8b30ff6ab2\", \"Name\": \"DateTime\", \"Description\": null, \"SdsTypeCode\": 16, \"IsGenericType\": false, \"IsReferenceType\": false, \"GenericArguments\": null, \"Properties\": null, \"BaseType\": null, \"DerivedTypes\": null, \"InterpolationMode\": 0, \"ExtrapolationMode\": 0 }, \"Value\": null, \"Uom\": null, \"InterpolationMode\": null }, { \"Id\": \"State\", \"Name\": \"State\", \"Description\": null, \"Order\": 0, \"IsKey\": false, \"FixedSize\": 0, \"SdsType\": { \"Id\": \"e20bdd7e-590b-3372-ab39-ff61950fb4f3\", \"Name\": \"State\", \"Description\": null, \"SdsTypeCode\": 609, \"IsGenericType\": false, \"IsReferenceType\": false, \"GenericArguments\": null, \"Properties\": [ { \"Id\": \"Ok\", \"Name\": null, \"Description\": null, \"Order\": 0, \"IsKey\": false, \"FixedSize\": 0, \"SdsType\": null, \"Value\": 0, \"Uom\": null, \"InterpolationMode\": null }, { \"Id\": \"Warning\", \"Name\": null, \"Description\": null, \"Order\": 0, \"IsKey\": false, \"FixedSize\": 0, \"SdsType\": null, \"Value\": 1, \"Uom\": null, \"InterpolationMode\": null }, { \"Id\": \"Alarm\", \"Name\": null, \"Description\": null, \"Order\": 0, \"IsKey\": false, \"FixedSize\": 0, \"SdsType\": null, \"Value\": 2, \"Uom\": null, \"InterpolationMode\": null } ], \"BaseType\": null, \"DerivedTypes\": null, \"InterpolationMode\": 0, \"ExtrapolationMode\": 0 }, \"Value\": null, \"Uom\": null, \"InterpolationMode\": null }, { \"Id\": \"Measurement\", \"Name\": \"Measurement\", \"Description\": null, \"Order\": 0, \"IsKey\": false, \"FixedSize\": 0, \"SdsType\": { \"Id\": \"6fecef77-20b1-37ae-aa3b-e6bb838d5a86\", \"Name\": \"Double\", \"Description\": null, \"SdsTypeCode\": 14, \"IsGenericType\": false, \"IsReferenceType\": false, \"GenericArguments\": null, \"Properties\": null, \"BaseType\": null, \"DerivedTypes\": null, \"InterpolationMode\": 0, \"ExtrapolationMode\": 0 }, \"Value\": null, \"Uom\": null, \"InterpolationMode\": null } ], \"BaseType\": null, \"DerivedTypes\": null, \"InterpolationMode\": 0, \"ExtrapolationMode\": 0 } Delete Type Deletes a type from the specified tenant and namespace. Note that a type cannot be deleted if any streams, stream views, or other types reference it. Request DELETE api/v1/Tenants/default/Namespaces/{namespaceId}/Types/{typeId} api v1 Tenants default Namespaces {namespaceId} Types {typeId} Parameters string namespaceId The namespace; either default or diagnostics. string typeId The type identifier. Response The response includes a status code."
                                          },
    "V1/SDS/Types/SdsTypeProperty_1-0.html":  {
                                                  "href":  "V1/SDS/Types/SdsTypeProperty_1-0.html",
                                                  "title":  "SdsTypeProperty",
                                                  "keywords":  "SdsTypeProperty The properties collection defines each field in an SdsType. The following table shows the required and optional SdsTypeProperty fields. Fields that are not included are reserved for internal SDS use. Property Type Optionality Details Id String Required Identifier for referencing the type. Name String Optional Friendly name. Description String Optional Description text. SdsType SdsType Required Field defining the property\u0027s Type. IsKey Boolean Required Identifies the property as the Key (Primary Index). Value Object Optional Value of the property. Order Int Optional Order of comparison within a compound index. InterpolationMode SdsInterpolationMode Optional Interpolation setting of the property. Default is null. Uom String Optional Unit of Measure of the property. For a list of units of measures that are supported for an SdsTypeProperty, see Units of measure . The SdsTypeProperty identifier has the same requirements as the SdsType identifier, which are: Is not case sensitive. Can contain spaces. Cannot contain forward slash (\"/\"). (\" \"). Contains a maximum of 100 characters. The Boolean value, IsKey identifies the SdsType Key. Each SdsType needs a Key to function as the primary index. A key defined by more than one property is called a compound key. A compound key can be defined by a maximum of three properties. In a compound key, each property that is included in the key is specified as IsKey . The Order field defines the precedence of fields applied to the index. The Value field is used for properties that represent a value. For example, the named constant for an enum is a property with a value. When representing an enum in a SdsType, the SdsType properties collection defines the constant list for the enum. The SdsTypeProperty Identifier represents the name of the constant and the SdsTypeProperty value represents the value of the constant (see the enum State definitions below). InterpolationMode is assigned when the property of the event should be interpolated in a specific way that differs from the InterpolationMode of the SdsType. InterpolationMode is only applied to a property that is not part of the Index. If the InterpolationMode is not set, the property inherits the IntepolationMode of the SdsType. An SdsType with the InterpolationMode set to Discrete cannot have a property with an InteroplationMode . For more information on interpolation of events, see Interpolation . Uom is the unit of measure for the property. The Uom of a property may be specified by the name or the abbreviation. The names and abbreviations of Uoms are case sensitive. The InterpolationMode and Uom of a property can be overridden on the stream. For more information, see PropertyOverrides in Streams ."
                                              },
    "V1/SDS/Types/SdsTypeCode_1-0.html":  {
                                              "href":  "V1/SDS/Types/SdsTypeCode_1-0.html",
                                              "title":  "SdsTypeCode",
                                              "keywords":  "SdsTypeCode The SdsTypeCode is a numeric identifier used by SDS to identify SdsTypes. An SdsTypeCode exists for every supported type. Atomic types, such as strings, floats, and arrays, are defined entirely by the SdsTypeCode. Atomic types do not need fields to define the type. Types requiring additional definition, such as enums and objects, are identified using a generic SdsTypeCode, such as ByteEnum, Int32Enum, NullableInt32Enum, or Object, plus additional SdsProperty fields. Supported Types The following types are supported and defined by the SdsTypeCode: Type SdsTypeCode Array 400 Boolean 3 BooleanArray 203 Byte 6 ByteArray 206 ByteEnum 606 Char 4 CharArray 204 DateTime 16 DateTimeArray 216 DateTimeOffset 20 DateTimeOffsetArray 220 DBNull 2 Decimal 15 DecimalArray 215 Double 14 DoubleArray 214 Empty 0 Guid 19 GuidArray 219 IDictionary 402 IEnumerable 403 IList 401 Int16 7 Int16Array 207 Int16Enum 607 Int32 9 Int32Array 209 Int32Enum 609 Int64 11 Int64Array 211 Int64Enum 611 NullableBoolean 103 NullableByte 106 NullableByteEnum 706 NullableChar 104 NullableDateTime 116 NullableDateTimeOffset 120 NullableDecimal 115 NullableDouble 114 NullableGuid 119 NullableInt16 107 NullableInt16Enum 707 NullableInt32 109 NullableInt32Enum 709 NullableInt64 111 NullableInt64Enum 711 NullableSByte 105 NullableSByteEnum 705 NullableSingle 113 NullableTimeSpan 121 NullableUInt16 108 NullableUInt16Enum 708 NullableUInt32 110 NullableUInt32Enum 710 NullableUInt64 112 NullableUInt64Enum 712 Object 1 SByte 5 SByteArray 205 SByteEnum 605 Single 13 SingleArray 213 String 18 StringArray 218 TimeSpan 21 TimeSpanArray 221 UInt16 8 UInt16Array 208 UInt16Enum 608 UInt32 10 UInt32Array 210 UInt32Enum 610 UInt64 12 UInt64Array 212 UInt64Enum 612 Version 22 VersionArray 222"
                                          },
    "V1/SDS/Write_Data_1-0.html":  {
                                       "href":  "V1/SDS/Write_Data_1-0.html",
                                       "title":  "Write data",
                                       "keywords":  "Write data The SDS REST APIs provide programmatic access to write data to SDS. All writes rely on a stream???s key or primary index. The primary index determines the order of events in the stream. Secondary indexes are updated, but they do not contribute to the request. All references to indexes are to the primary index. Single stream writes The following methods support writing a single or multiple values: Insert Values inserts a collection of events. Patch Values updates specific fields for a collection of events. Replace Values replaces a collection of events. Remove Values deletes the events based on the request parameters. Update Values add or replaces a collection of events. The base URI for writing SDS data to a single stream is: api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. Request body format With the exception of Remove Values , all single stream write calls require a request body containing the events to insert or modify. The events must be formatted as a serialized JSON array of the stream\u0027s type. JSON arrays are comma-delimited lists of a type enclosed within square brackets. The following code shows a list of three WaveData events that are properly formatted for insertion. For the complete example, see the OCS-Samples . [ { \"Order\":2, \"Tau\":0.25722883666666846, \"Radians\":1.6162164471269089, \"Sin\":1.9979373673043652, \"Cos\":-0.090809010174665111, \"Tan\":-44.003064529862513, \"Sinh\":4.8353589272389, \"Cosh\":5.2326566823391856, \"Tanh\":1.8481468289554672 }, { \"Order\":4, \"Tau\":0.25724560000002383, \"Radians\":1.6163217742567466, \"Sin\":1.9979277915696148, \"Cos\":-0.091019446679060964, \"Tan\":-43.901119254534827, \"Sinh\":4.8359100947709592, \"Cosh\":5.233166005842703, \"Tanh\":1.8481776000882766 }, { \"Order\":6, \"Tau\":0.25724560000002383, \"Radians\":1.6163217742567466, \"Sin\":1.9979277915696148, \"Cos\":-0.091019446679060964, \"Tan\":-43.901119254534827, \"Sinh\":4.8359100947709592, \"Cosh\":5.233166005842703, \"Tanh\":1.8481776000882766 } ] You can serialize your data using one of many available JSON serializers available at Introducing JSON . Indexes SDS writes rely on the primary index for positioning within streams and locating existing events. Most writes use the index as specified by the value; however, for deletes, indexes are specified as strings in the URI. For more details about working with indexes, see Indexes . To specify compound indexes in the URI, specify each field that composes the index, in the specified order, separated by the pipe character, ???|???."
                                   },
    "V1/SDS/Compression_1-0.html":  {
                                        "href":  "V1/SDS/Compression_1-0.html",
                                        "title":  "Compression",
                                        "keywords":  "Compression To more efficiently utilize network bandwidth, the EDS Sequential Data Store supports compression for reading data and writing data through the REST API. Supported compression schemes the EDS Sequential Data Store supports the following compression schemes: gzip deflate Request compression (write data) Specify the compression scheme in the Content-Encoding HTTP header of compressed-content requests. This header provides context to the API to properly decode the request content. Response compression (read data) Request compressed responses from the REST API by specifying one of the supported compression schemes using the Accept-Encoding HTTP header. Compressed responses from the REST API include a Content-Encoding HTTP header indicating the compression scheme used to compress the response content. Note: Specifying a compression scheme with the Accept-Encoding HTTP header does not guarantee a compressed response. Always refer to presence and value of the Content-Encoding HTTP header of the response to properly decode the response content."
                                    },
    "V1/ReleaseNotes/ReleaseNotes_1-0.html":  {
                                                  "href":  "V1/ReleaseNotes/ReleaseNotes_1-0.html",
                                                  "title":  "Release notes",
                                                  "keywords":  "Release notes Edge Data Store is a new product from OSIsoft. It is supported on a variety of platforms and processors. In addition to ready-to-use install kits, OSIsoft also provides examples of how to create Docker containers in a separate file, and provides tar.gz files with binaries for customers who want to build their own custom installers or containers for Linux. For detailed installation instructions, see Install Edge Data Store . Edge Data Store includes the following components, which are installed as part of Edge Data Store: Modbus TCP EDS adapter OPC UA EDS adapter Data egress Health OMF endpoint REST API EdgeCmd is a command line utility available as a separate install kit that allows access to and modification of Edge Data Store configuration. Security Edge Data Store was developed following the Security Development Lifecycle (SDL) process. This is a new product so there are no security issues in previous releases that were fixed with this release. There are no known security issues with this initial release."
                                              },
    "V1/Overview/AnalyticsQuickStart.html":  {
                                                 "href":  "V1/Overview/AnalyticsQuickStart.html",
                                                 "title":  "Edge Data Store analytics quick start",
                                                 "keywords":  "Edge Data Store analytics quick start This topic provides a quick start for a very simple analytic you can write using Edge Data Store. The intended input device is an Modbus TCP EDS adapter or other sensor that outputs 4 Boolean values. The normal range of operation is that the values are neither all true or all false. If all values are true, the exception condition High is triggered. If all values are false, the exception condition Low is triggered. Any other combination of Boolean values is Normal. Three analytic streams are created to track these changes. The ValueRangeHigh stream is 1 when High and 0 when anything else. The ValueRangeLow stream is -1 when Low and 0 when anything else. The ValueRangeOut stream is -1 when Low, 0 when Normal, and 1 when High. This example assumes Edge Data Store was installed with the default port (5590): using System; using System.Collections.Generic; using System.Net.Http; using System.Text; using Newtonsoft.Json; using Newtonsoft.Json.Linq; namespace ExceptionReportingSample { class ModbusField { public string StreamId { get; set; } public int ScanRate { get; set; } } enum Alert { Normal, High, Low } class ExceptionReporting { static HttpClient _client = new HttpClient(); private static List\u003cstring\u003e StreamIds = new List\u003cstring\u003e(new string[] { \"SwitchState1\", \"SwitchState2\", \"SwitchState3\", \"SwitchState4\" }); private const string ValueRangeHigh = \"ValueRangeHigh\"; private const string ValueRangeLow = \"ValueRangeLow\"; private const string ValueRangeOut = \"ValueRangeOut\"; private const string TypeId = \"ValueRange\"; private const string ModbusComponentId = \"Modbus1\"; private const double lowValue = -1.0; private const double highValue = 1.0; private const double normalValue = 0.0; public static Alert _alert = Alert.Normal; static TimeSpan GetPollingIntervalFromModbus(string modbusComponentId, List\u003cstring\u003e StreamIds) { int pollingMilliseconds = 5000; string endpoint = $\"http://localhost:5590/api/v1/configuration/{modbusComponentId}/DataSelection\"; $\"http:  localhost:5590 api v1 configuration {modbusComponentId} DataSelection\"; string modbusConfig = _client.GetStringAsync(endpoint).Result; List\u003cModbusField\u003e values = JsonConvert.DeserializeObject\u003cList\u003cModbusField\u003e\u003e(modbusConfig); foreach (var value in values) { foreach (string StreamId in StreamIds) { if (StreamId == value.StreamId \u0026\u0026 value.ScanRate \u003c pollingMilliseconds) { pollingMilliseconds = value.ScanRate; } } } return TimeSpan.FromMilliseconds(pollingMilliseconds); } static bool GetStreamValue(string StreamId) { bool value = false; string lastValueUri = string.Format(\"http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/{0}/Data/Last\", string.Format(\"http:  localhost:5590 api v1 tenants default namespaces default streams {0} Data Last\", StreamId); string lastValueJson = _client.GetStringAsync(lastValueUri).Result; Dictionary\u003cstring, object\u003e values = JsonConvert.DeserializeObject\u003cDictionary\u003cstring, object\u003e\u003e(lastValueJson); object objValue = values[\"Value\"]; if (objValue is Boolean) value = (bool)objValue; return value; } static bool FindOrCreateType(string typeId) { string typeUri = string.Format(\"http://localhost:5590/api/v1/tenants/default/namespaces/default/types/{0}\", string.Format(\"http:  localhost:5590 api v1 tenants default namespaces default types {0}\", typeId); HttpResponseMessage response = _client.GetAsync(typeUri).Result; if (response.IsSuccessStatusCode) return true; string typeJson = @\"{\"\"Id\"\": \"\"\" + typeId + @\"\"\",\"\"Name\"\": \"\"\" + typeId + @\"\"\",\"\"SdsTypeCode\"\": 1,\"\"Properties\"\": [{\"\"Id\"\": \"\"Time\"\",\"\"Name\"\": \"\"Time\"\",\"\"IsKey\"\": true,\"\"SdsType\"\": {\"\"SdsTypeCode\"\": 16}},{\"\"Id\"\": \"\"Measurement\"\",\"\"Name\"\": \"\"Measurement\"\",\"\"SdsType\"\": {\"\"SdsTypeCode\"\": 14}}]}\"; var content = new StringContent(typeJson, Encoding.UTF8, \"application/json\"); \"application json\"); response = _client.PostAsync(typeUri, content).Result; return response.IsSuccessStatusCode; } static bool FindOrCreateStream(string streamId, string typeId) { string streamUri = string.Format(\"http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/{0}/\", string.Format(\"http:  localhost:5590 api v1 tenants default namespaces default streams {0} \", streamId); HttpResponseMessage response = _client.GetAsync(streamUri).Result; if (response.IsSuccessStatusCode) return true; string streamJson = @\"{\"\"Id\"\": \"\"\" + streamId + @\"\"\",\"\"Name\"\": \"\"\" + streamId + @\"\"\",\"\"TypeId\"\": \"\"\" + typeId + @\"\"\"}\"; var content = new StringContent(streamJson, Encoding.UTF8, \"application/json\"); \"application json\"); response = _client.PostAsync(streamUri, content).Result; return response.IsSuccessStatusCode; } static bool WriteStreamValue(string StreamId, double value, DateTime timestamp) { string dataUri = string.Format(\"http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/{0}/Data\", string.Format(\"http:  localhost:5590 api v1 tenants default namespaces default streams {0} Data\", StreamId); string dataJson = @\"[{\"\"Time\"\": \"\"\" + timestamp.ToString(\"o\") + @\"\"\",\"\"Measurement\"\":\" + value.ToString() + \"}]\"; var content = new StringContent(dataJson, Encoding.UTF8, \"application/json\"); \"application json\"); HttpResponseMessage response = _client.PostAsync(dataUri, content).Result; return response.IsSuccessStatusCode; } static Alert CheckStatus(int numberTrue) { if (numberTrue \u003e 3) return Alert.High; if (numberTrue \u003c 1) return Alert.Low; return Alert.Normal; } static bool ReportChange(Alert oldAlert, Alert newAlert) { bool success = true; DateTime now = DateTime.UtcNow; switch (oldAlert) { case Alert.Normal: if (Alert.Low == newAlert) { return WriteStreamValue(ValueRangeLow, lowValue, now) \u0026\u0026 WriteStreamValue(ValueRangeOut, lowValue, now); } if (Alert.High == newAlert) { return WriteStreamValue(ValueRangeHigh, highValue, now) \u0026\u0026 WriteStreamValue(ValueRangeOut, highValue, now); } break; case Alert.High: if (Alert.Low == newAlert) { return WriteStreamValue(ValueRangeLow, lowValue, now) \u0026\u0026 WriteStreamValue(ValueRangeOut, lowValue, now) \u0026\u0026 WriteStreamValue(ValueRangeHigh, normalValue, now); } if (Alert.Normal == newAlert) { return WriteStreamValue(ValueRangeOut, normalValue, now) \u0026\u0026 WriteStreamValue(ValueRangeHigh, normalValue, now); } break; case Alert.Low: if (Alert.Normal == newAlert) { return WriteStreamValue(ValueRangeOut, normalValue, now) \u0026\u0026 WriteStreamValue(ValueRangeLow, normalValue, now); } if (Alert.High == newAlert) { return WriteStreamValue(ValueRangeLow, normalValue, now) \u0026\u0026 WriteStreamValue(ValueRangeOut, highValue, now) \u0026\u0026 WriteStreamValue(ValueRangeHigh, highValue, now); } break; default: break; } return success; } static void Main(string[] args) { TimeSpan pollingInterval = GetPollingIntervalFromModbus(ModbusComponentId, StreamIds); FindOrCreateType(TypeId); FindOrCreateStream(ValueRangeHigh, TypeId); FindOrCreateStream(ValueRangeLow, TypeId); FindOrCreateStream(ValueRangeOut, TypeId); while (true) { int numberTrue = 0; foreach (string StreamId in StreamIds) { bool value = GetStreamValue(StreamId); if (value) numberTrue++; } Alert currentAlert = CheckStatus(numberTrue); if (currentAlert != _alert) { if (ReportChange(_alert, currentAlert)) { _alert = currentAlert; } } System.Threading.Thread.Sleep(pollingInterval); Console.WriteLine(\"ValueRange should be \" + _alert); } } } }"
                                             },
    "V1/OpcUa/SupportedFeaturesOPCUA_1-0.html":  {
                                                     "href":  "V1/OpcUa/SupportedFeaturesOPCUA_1-0.html",
                                                     "title":  "Data type mapping",
                                                     "keywords":  "Data type mapping The following table lists OPC UA data types from which the OPC UA EDS adapter supports data collection and corresponding stream data types that will be created in Edge Data Store. OPC UA data type Stream data type Boolean Boolean Byte Int16 SByte Int16 Int16 Int16 UInt16 UInt16 Int32 Int32 UInt32 UInt32 Int64 Int64 UInt64 UInt64 Float Float32 Double Float64 DateTime DateTime String String"
                                                 },
    "V1/Configuration/System configuration_1-0.html":  {
                                                           "href":  "V1/Configuration/System configuration_1-0.html",
                                                           "title":  "System configuration",
                                                           "keywords":  "System configuration Edge Data Store uses JSON configuration files in a protected directory on Windows and Linux to store configuration that is read on startup. While the files are accessible to view, OSIsoft recommends that you use REST or the EdgeCmd command line tool to make any changes to the files. As part of making Edge Data Store as secure as possible, any passwords or secrets are stored in encrypted form (with cryptographic key material stored separately in a secure location.) Editing the files directly may cause unexpected behavior. Note: Use REST to edit any single component or facet of the system or configure the system as a whole with a single REST call."
                                                       },
    "V1/Configuration/System components configuration_1-0.html":  {
                                                                      "href":  "V1/Configuration/System components configuration_1-0.html",
                                                                      "title":  "System components configuration",
                                                                      "keywords":  "System components configuration Edge Data Store components are Modbus TCP EDS adapter, OPC UA EDS adapter, and the Storage component. These components are only active if they are configured for the system to use them. EDS itself needs only a small amount of configuration - the list of components and the HTTP Port used for REST calls. The default System_Components.json file for the System component contains the following information. [ { \"ComponentId\": \"Storage\", \"ComponentType\": \"EDS.Component\" } ] The Storage component is required for Edge Data Store to run and only one Storage component instance is supported. Each Modbus device needs a separate Modbus TCP EDS adapter component instance to connect to EDS, and each OPC UA device needs a separate OPC UA EDS adapter component instance to connect to EDS. Multiple Modbus TCP EDS adapter component instances and the OPC UA EDS adapter component instances are supported. Add system components Using any text editor, create a JSON file with the ComponentId and ComponentType. The following example adds a Modbus TCP EDS adapter instance. { \"ComponentId\": \"Modbus1\", \"ComponentType\": \"Modbus\" } Note: The ComponentId must be a unique value. This example uses the ComponentId Modbus1, since it is the first Modbus TCP EDS adapter. Save the JSON file with the name AddComponent.json . From the same directory where the file exists, run the following curl script: curl -i -d \"@AddComponent.json\" -H \"Content-Type: application/json\" application json\" http://localhost:5590/api/v1/configuration/system/components http:  localhost:5590 api v1 configuration system components After the curl command completes successfully, the new component is available for configuration and use. Parameters for system components The following parameters are used to define system components. Parameters Required Type Nullable Description ComponentId Required string Yes The unique ID of the component instance. It can be any alphanumeric string, for example Storage. ComponentType Required string Yes The type of the component, for example EDS.Component. There are three types of components: Storage identified by EDS.Component , OPC UA EDS Adapter identified by OpcUa , and Modbus TCP EDS Adapter identified by Modbus . System components example [ { \"componentId\": \"OpcUa1\", \"componentType\": \"OpcUa\" }, { \"componentId\": \"Modbus1\", \"componentType\": \"Modbus\" }, { \"componentId\": \"Storage\", \"componentType\": \"EDS.Component\" } ]"
                                                                  },
    "V1/Configuration/Storage runtime config_1-0.html":  {
                                                             "href":  "V1/Configuration/Storage runtime config_1-0.html",
                                                             "title":  "Storage runtime configuration",
                                                             "keywords":  "Storage runtime configuration The Edge Data Store storage component is install with default configurations that are sufficient for most scenarios; however, the runtime characteristics of the storage component can be configured. Note: Consult with OSIsoft Support personnel before modifying the default configuration. Configure storage runtime To update the storage runtime configuration, complete the following: Create a JSON file with the storage runtime configuration. Note: See the following Parameters table for all available runtime parameters to define. See the following Examples section for an example of a valid runtime configuration file. Save the JSON file with the name Storage_Runtime.config.json. From the same directory where the file exists, run the following curl script: curl -i -d \"@Storage_Runtime.config.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/storage/Runtime http:  localhost:5590 api v1 configuration storage Runtime Note: The @ symbol is a required prefix for the above command. Parameters Parameter Required Type Description IngressDebugExpiration Required string If set, defines how long OMF ingress debug files should be produced. StreamStorageLimitMb Required integer The maximum size in megabytes that a stream can reach. StreamStorageTargetMb Required integer The size in megabytes that a stream will be reduced to after StreamStorageLimitMb size is reached for a single stream. EnableTransactionLog No Boolean Enables or disables the transaction log. The transaction log helps to ensure no data is lost should a device lose power. TransactionLogLimitMB No integer Maximum size for transaction log file. Transaction log files larger than this size will be deleted, resulting is loss of data should the device lose power. CheckpointRateInSec No integer How often to flush new data to store. Examples The following is a valid runtime configuration example. { \"streamStorageLimitMb\": 2, \"streamStorageTargetMb\": 1, \"ingressDebugExpiration\": \"0001-01-01T00:00:00\", \"checkpointRateInSec\": 30, \"transactionLogLimitMB\": 250, \"enableTransactionLog\": true } Storage runtime configuration properties Property Type Required Nullable Defined by IngressDebugExpiration string Required No StorageRuntimeConfiguration (this schema) StreamStorageLimitMb integer Required No StorageRuntimeConfiguration (this schema) StreamStorageTargetMb integer Required No StorageRuntimeConfiguration (this schema) EnableTransactionLog bool No No StorageRuntimeConfiguration (this schema) TransactionLogLimitMB integer No No StorageRuntimeConfiguration (this schema) CheckpointRateInSec integer No No StorageRuntimeConfiguration (this schema) IngressDebugExpiration Use the Ingress Debug Expiration property when debugging OMF to set the date and time when debugging should be disabled. If a future date and time is is specified, incoming OMF messages are logged and HTTP request and response content is stored to disk for review. The debug logging stops at the data and time specified. Set the value to null to disable logging. Examples of valid strings representing date and time: UTC: \"yyyy-mm-ddThh:mm:ssZ\" Local: \"mm-dd-yyyy hh:mm:ss\" When logging is activated, the content of an incoming OMF message, including the headers, is written to a file in the Logs directory. For an active application, this file can become quite large. As a result, debug information is stored to disk in another format than usual log messages. A single file is written to the usual logs directory for every incoming OMF type, container, and data message. IngressDebugExpiration type string format: date-time date and time (according to RFC 3339, section 5.6 ) minimum length: 1 character StreamStorageLimitMb Use the StreamStorageLimitMb property to set the maximum size in megabytes that a stream can reach. When a stream exceeds the size specified, older data is deleted from the file until the stream is at or below the StreamStorageTargetMb value. The target value, set in the StreamStorageTargetMb property, needs to be smaller than the maximum specified in this property. StreamStorageLimitMb type integer minimum value: 2 maximum value: 2147483647 StreamStorageTargetMb Use the StreamStorageTargetMb property to set the size in megabytes that a stream will be reduced to after StreamStorageLimitMb size is reached for a single stream. When a stream exceeds the size specified in the StreamStorageLimitMb property, older data is deleted from the file until the stream is at or below the StreamStorageTargetMb value. The target value needs to be smaller than the maximum specified in the StreamStorageLimitMb property. StreamStorageTargetMb type integer minimum value: 1 maximum value: 2147483647 EnableTransactionLog Use the EnableTransactionLog property to define whether the Storage component maintains a transaction log between checkpoint operations. The transaction log helps the product reduce data loss, should the host device lose power. EnableTransactionLog type bool TransactionLogLimitMB Use the TransactionLogLimitMB property to define the maximum size, in MB, of a transaction log. When a transaction log exceeds this size, it is deleted, which reduces the amount of data that can be recovered should the host device lose power. TransactionLogLimitMB type integer minimum value: 1 maximum value: 2147483647 CheckpointRateInSec Use the CheckpointRateInSec property to define, in seconds, how often the storage component ensures recent data and configuration changes are flushed to storage. A setting of 0 disables checkpointing. Disabling checkpointing reduces the resiliency of the product and thus data loss can occur if the host device loses power. CheckpointRateInSec type integer minimum value: 0 maximum value: 86400 Note: All of the following requirements need to be fulfilled. Requirement 1 #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required IngressDebugExpiration string Required StreamStorageLimitMb integer Required StreamStorageTargetMb integer Required EnableTransactionLog Boolean Optional TransactionLogLimitMB integer Optional CheckpointRateInSec integer Optional"
                                                         },
    "V1/Installation/InstallationOverview_1-0.html":  {
                                                          "href":  "V1/Installation/InstallationOverview_1-0.html",
                                                          "title":  "Installation",
                                                          "keywords":  "Installation You can install Edge Data Store in one of two ways: Using an install kit. For more information, see Install Edge Data Store . Using Docker containers. For more information, see Docker . For a list of supported platforms and processors, see System requirements ."
                                                      },
    "V1/DataIngress/EDSDataIngress_1-0.html":  {
                                                   "href":  "V1/DataIngress/EDSDataIngress_1-0.html",
                                                   "title":  "Data ingress configuration",
                                                   "keywords":  "Data ingress configuration Edge Data Store supports the following protocols to ingress data: OPC UA EDS adapter : Use standard OPC UA equipment and protocols to send data to EDS. Modbus TCP EDS adapter : Use standard Modbus TCP equipment and protocols to send data to EDS. OMF Ingress: Use OSIsoft Message Format to send data from a custom application into EDS. OMF is a REST and JSON based data format designed for simplicity of custom application design. For more information, see OSIsoft Message Format . SDS Ingress: Use OSIsoft Sequential Data Store (SDS) REST to send data from a custom application into EDS. SDS offers the most options to send, store, and retrieve data from EDS. For more information about using REST API calls with SDS, see Write data API ."
                                               },
    "docfx.console.2.43.2/content/articles/intro.html":  {
                                                             "href":  "docfx.console.2.43.2/content/articles/intro.html",
                                                             "title":  "Add your introductions here!",
                                                             "keywords":  "Add your introductions here!"
                                                         },
    "docfx.console.2.43.2/content/api/index.html":  {
                                                        "href":  "docfx.console.2.43.2/content/api/index.html",
                                                        "title":  "PLACEHOLDER",
                                                        "keywords":  "PLACEHOLDER TODO: Add .NET projects to src folder and run docfx to generate a REAL API Documentation !"
                                                    },
    "zArchive/Schemas/System_schema.html":  {
                                                "href":  "zArchive/Schemas/System_schema.html",
                                                "title":  "Sample system configuration",
                                                "keywords":  "Sample system configuration \"System\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"Components\": [{ \"componentId\": \"OpcUa1\", \"componentType\": \"OpcUa\" }, { \"componentId\": \"Modbus1\", \"componentType\": \"Modbus\" }, { \"componentId\": \"Storage\", \"componentType\": \"EDS.Component\" } ], \"HealthEndpoints\": [], \"Port\": { \"port\": 5590 } } System configuration properties Property Type Required Nullable Defined by Logging SystemLoggingConfiguration Optional Yes EdgeLoggerConfiguration Components [SystemComponentsConfiguration] Optional Yes ComponentsConfiguration HealthEndpoints [SystemHealthEndpointsConfiguration] Optional Yes HealthEndpointsConfiguration Port SystemPortConfiguration Optional Yes PortConfiguration"
                                            },
    "zArchive/Schemas/System_Port_schema.html":  {
                                                     "href":  "zArchive/Schemas/System_Port_schema.html",
                                                     "title":  "Sample system port configuration",
                                                     "keywords":  "Sample system port configuration { \"Port\": 5590 } System port configuration properties Property Type Required Nullable Defined by Port integer minimum value: 1024 maximum value: 65535 Optional No PortConfiguration (this schema) Note: All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required Port integer Optional"
                                                 },
    "zArchive/Schemas/ConfigurationSchemaList.html":  {
                                                          "href":  "zArchive/Schemas/ConfigurationSchemaList.html",
                                                          "title":  "Configuration schemas",
                                                          "keywords":  "Configuration schemas Edge Data Store is configured through a series of JSON files. The schemas for these files are provided in the installation directory and are documented following. Edge Data Store configuration schemas Use the following schemas to configure Edge Data Store: EdgeLoggerConfiguration PortConfiguration OmfHealthEndpointConfiguration EdgeDataStoreConfig EDS adapters configuration schemas Use the following schemas to configure EDS adapters: OPC UA DataSourceConfiguration DataCollectionItem EdgeLoggerConfiguration Modbus TCP DataSourceConfiguration DataSelectionConfiguration EdgeLoggerConfiguration Storage configuration schemas Use the following schemas to configure the Storage component: EdgeLoggerConfiguration StorageRuntimeConfiguration OEMConfiguration Periodic Egress Endpoints"
                                                      },
    "V1/OpcUa/OPCUAAdapterSecurityConfiguration_1-0.html":  {
                                                                "href":  "V1/OpcUa/OPCUAAdapterSecurityConfiguration_1-0.html",
                                                                "title":  "Adapter security",
                                                                "keywords":  "Adapter security The OPC UA security standard is concerned with the authentication of client and server applications, the authentication of users, and confidentiality of their communication. As the security model relies heavily on Transport Level Security (TLS) to establish a secure communication link with an OPC UA server, each client, including the OPC UA EDS adapter, must have a digital certificate deployed and configured. Certificates uniquely identify client applications and machines on servers, and allow for creation of a secure communication link when trusted on both sides. The OPC UA EDS adapter instance generates a self-signed certificate when the first secure connection attempt is made. Each OPC UA EDS adapter instance creates a certificate store to persist both its own certificates and those received from the server. Configure OPC UA EDS adapter security In the data source configuration, set UseSecureConnection to true . For more information, see Data source configuration . The adapter instance verifies whether the server certificate is present in the adapter trusted certificates folder and is therefore trusted. If the certificates were not exchanged before the first attempted connection, the adapter instance saves the server certificate within the adapter rejected certificates folder and returns the following warning message about the rejected server certificate: ~~2019-09-08 11:45:48.093 +01:00~~ [Warning] Rejected Certificate: \"DC=MyServer.MyDomain.int, O=Prosys OPC, CN=Simulation Manually move the server certificate from the RejectedCertificates\\certs folder to the Trusted\\certs folder using a file explorer or command-line interpreter. Linux example using command-line: mv /usr/share/OSIsoft/EdgeDataStore/OpcUa1/Certificates/RejectedCertificates/certs/SimulationServer\\  usr share OSIsoft EdgeDataStore OpcUa1 Certificates RejectedCertificates certs SimulationServer\\ \\[F9823DCF607063DBCECCF6F8F39FD2584F46AEBB\\].der /usr/share/OSIsoft/EdgeDataStore/OpcUa1/Certificates/Trusted/certs/  usr share OSIsoft EdgeDataStore OpcUa1 Certificates Trusted certs  Note: Administrator or root privileges are required to perform this operation. Once the certificate is in the adapter instance trusted certificates folder, the adapter instance trusts the server and the connection attempt makes the connection call to the configured server. Add the adapter certificate to the server\u0027s trust store. The connection succeeds only when the adapter certificate is trusted on the server side. For more details on how to make a client certificate trusted, see your OPC UA server documentation. In general, OPC UA servers work in a similar fashion as the clients, a similar approach may work to make the server certificate trusted on the client side. When certificates are mutually trusted, the connection attempt succeeds and the adapter instance is connected to the most secure endpoint provided by the server. Certificate locations For all of the following locations, {ComponentID} identifies the adapter instance. Adapter rejected certificates Windows: %programdata%\\OSIsoft\\EdgeDataStore\\{ComponentId}\\Certificates\\RejectedCertificates\\certs Linux: /usr/share/OSIsoft/EdgeDataStore/{ComponentId}/Certificates/RejectedCertificates/certs  usr share OSIsoft EdgeDataStore {ComponentId} Certificates RejectedCertificates certs Adapter trusted certificates Windows: %programdata%\\OSIsoft\\EdgeDataStore\\{ComponentId}\\Certificates\\Trusted\\certs Linux: /usr/share/OSIsoft/EdgeDataStore/{ComponentId}/Certificates/Trusted/certs  usr share OSIsoft EdgeDataStore {ComponentId} Certificates Trusted certs Adapter\u0027s certificate Windows: %programdata%\\OSIsoft\\EdgeDataStore\\{ComponentId}\\Certificates\\My\\certs Linux: /usr/share/OSIsoft/EdgeDataStore/{ComponentId}/Certificates/My/certs  usr share OSIsoft EdgeDataStore {ComponentId} Certificates My certs"
                                                            },
    "V1/LinuxWindows/LinuxWindows_1-0.html":  {
                                                  "href":  "V1/LinuxWindows/LinuxWindows_1-0.html",
                                                  "title":  "Linux and Windows platform differences",
                                                  "keywords":  "Linux and Windows platform differences Edge Data Store is available on both Windows and Linux platforms and it works the same way on both platforms. There are a few differences to be aware of. Files are stored in different locations based on the platform and Linux systems have a file descriptor limit that can affect EDS function. File locations Windows Program binaries are located in the C:\\Program Files\\OSIsoft\\EdgeDataStore directory by default. For information about changing this location, see Install Edge Data Store . Configuration, log, and data files are placed under C:\\ProgramData\\OSIsoft\\EdgeDataStore . This is not configurable. If you uninstall EDS, this folder structure is not automatically removed. For information about clearing these files, see Uninstall Edge Data Store . Key material for encrypted secrets of configuration files is stored using the Windows DPAPI in a secure Windows store. This is not configurable. Linux File locations for Linux cannot be configured. Program binaries are located in the /opt/OSIsoft/EdgeDataStore  opt OSIsoft EdgeDataStore directory. Configuration, log, and data files are placed under /usr/share/OSIsoft/EdgeDataStore  usr share OSIsoft EdgeDataStore . If you uninstall EDS, this folder structure is not automatically removed. For information about clearing these files, see Uninstall Edge Data Store . Key material for encrypted secrets of configuration files is stored using limited access files under /usr/share/OSIsoft/EdgeDataStore  usr share OSIsoft EdgeDataStore . When the Debian installer is used, Edge Data Store is installed using the service identity osisoft.edgedatastore.service. If you need to restart the service from the Linux command line, use the following command: sudo systemctl restart osisoft.edgedatastore.service File descriptors (handles) When installed on a Linux operating system, EDS is configured with a file descriptor limit that may be higher than the corresponding limit for most processes. The limit is controlled by the LimitNOFILE variable in the file /lib/systemd/system/osisoft.edgedatastore.service  lib systemd system osisoft.edgedatastore.service . Linux operating systems impose a limit on the number of file descriptors used in a process. The number of open file descriptors is directly related to the number of streams used in EDS (for example, data ingress). Every EDS stream uses two file descriptors. EDS will no longer function properly when it reaches the limit of available file descriptors. To ensure EDS functions properly, it is necessary to either limit the number of streams used in EDS or increase the maximum file descriptors allowed per process. File descriptor usage differs on different Linux operating systems and devices, and may differ slightly from execution to execution, so it is important to understand your system and adjust accordingly. For example, when tested on a Raspberry Pi 3 Model B+ using a Raspbian operating system, an installation of EDS with no user-defined streams had an average of 424 open file descriptors. The same installation with 250 streams had an average of 932 open file descriptors. The file descriptor limit per process for the operating system used was 1024. Windows has an object called a handle that is used in much the same way that Linux uses file descriptors. However, Windows does not have a limitation on the number of handles."
                                              },
    "zArchive/Schemas/System_Logging_schema.html":  {
                                                        "href":  "zArchive/Schemas/System_Logging_schema.html",
                                                        "title":  "System logging configuration properties",
                                                        "keywords":  "System logging configuration properties Property Type Required Nullable Defined by LogFileCountLimit integer Optional Yes EdgeLoggerConfiguration (this schema) LogFileSizeLimitBytes integer Optional Yes EdgeLoggerConfiguration (this schema) LogLevel reference #/definitions/EdgeLogLevel # definitions EdgeLogLevel Optional No EdgeLoggerConfiguration (this schema) Note: All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required LogFileCountLimit integer Optional LogFileSizeLimitBytes integer Optional LogLevel reference #/definitions/EdgeLogLevel # definitions EdgeLogLevel Optional"
                                                    },
    "zArchive/Schemas/Storage_PeriodicEgressEndpoints_schema.html":  {
                                                                         "href":  "zArchive/Schemas/Storage_PeriodicEgressEndpoints_schema.html",
                                                                         "title":  "Sample periodic egress configuration",
                                                                         "keywords":  "Sample periodic egress configuration [{ \"Id\": \"OCS Data\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"default\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"\u003cmakeunique\u003e\", \"TypePrefix\": \"\u003cmakeunique\u003e\", \"Endpoint\": \"https://\u003cOCS \"https:  \u003cOCS OMF endpoint\u003e\", \"ClientId\": \"\u003cclientid\u003e\", \"ClientSecret\": \"\u003cclientsecret\u003e\", \"UserName\": null, \"Password\": null, \"DebugExpiration\": null, \"TokenEndpoint\": null, \"ValidateEndpointCertificate\": true }, { \"Id\": \"PI Web API Data\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"default\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"\u003cmakeunique\u003e\", \"TypePrefix\": \"\u003cmakeunique\u003e\", \"Endpoint\": \"https://\u003cyourserver\u003e/piwebapi/omf/\", \"https:  \u003cyourserver\u003e piwebapi omf \", \"ClientId\": null, \"ClientSecret\": null, \"UserName\": \"\u003cusername\u003e\", \"Password\": \"\u003cpassword\u003e\", \"DebugExpiration\": null, \"TokenEndpoint\": null, \"ValidateEndpointCertificate\": true }, { \"Id\": \"OCS Diagnostics\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"diagnostics\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"\u003cmakeunique\u003e\", \"TypePrefix\": \"\u003cmakeunique\u003e\", \"Endpoint\": \"https://\u003cOCS \"https:  \u003cOCS OMF endpoint\u003e\", \"ClientId\": \"\u003cclientid\u003e\", \"ClientSecret\": \"\u003cclientsecret\u003e\", \"UserName\": null, \"Password\": null, \"DebugExpiration\": null, \"TokenEndpoint\": null, \"ValidateEndpointCertificate\": true }, { \"Id\": \"PI Web API Diagnostics\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"diagnostics\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"\u003cmakeunique\u003e\", \"TypePrefix\": \"\u003cmakeunique\u003e\", \"Endpoint\": \"https://\u003cyourserver\u003e/piwebapi/omf/\", \"https:  \u003cyourserver\u003e piwebapi omf \", \"ClientId\": null, \"ClientSecret\": null, \"UserName\": \"\u003cusername\u003e\", \"Password\": \"\u003cpassword\u003e\", \"DebugExpiration\": null, \"TokenEndpoint\": null, \"ValidateEndpointCertificate\": true } ] Periodic egress configuration properties Property Type Required Nullable Defined by Backfill boolean Optional No PeriodicEgressConfiguration (this schema) ClientId string Optional Yes PeriodicEgressConfiguration (this schema) ClientSecret string Optional Yes PeriodicEgressConfiguration (this schema) DebugExpiration string Optional Yes PeriodicEgressConfiguration (this schema) Description string Optional Yes PeriodicEgressConfiguration (this schema) EgressFilter string Optional Yes PeriodicEgressConfiguration (this schema) Enabled boolean Optional No PeriodicEgressConfiguration (this schema) Endpoint string Required No PeriodicEgressConfiguration (this schema) ExecutionPeriod string Required No PeriodicEgressConfiguration (this schema) Id string Optional Yes PeriodicEgressConfiguration (this schema) Name string Optional Yes PeriodicEgressConfiguration (this schema) NamespaceId string Optional Yes PeriodicEgressConfiguration (this schema) Password string Optional Yes PeriodicEgressConfiguration (this schema) StreamPrefix string Optional Yes PeriodicEgressConfiguration (this schema) TokenEndpoint string Optional Yes PeriodicEgressConfiguration (this schema) TypePrefix string Optional Yes PeriodicEgressConfiguration (this schema) UserName string Optional Yes PeriodicEgressConfiguration (this schema) ValidateEndpointCertificate boolean Optional No PeriodicEgressConfiguration (this schema) Note: All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required Backfill boolean Optional ClientId string Optional ClientSecret string Optional DebugExpiration string Optional Description string Optional EgressFilter string Optional Enabled boolean Optional Endpoint string Required ExecutionPeriod string Required Id string Optional Name string Optional NamespaceId string Optional Password string Optional StreamPrefix string Optional TokenEndpoint string Optional TypePrefix string Optional UserName string Optional ValidateEndpointCertificate boolean Optional"
                                                                     },
    "zArchive/Schemas/Storage_Logging_schema.html":  {
                                                         "href":  "zArchive/Schemas/Storage_Logging_schema.html",
                                                         "title":  "Storage logging configuration properties",
                                                         "keywords":  "Storage logging configuration properties Property Type Required Nullable Defined by LogFileCountLimit integer Optional Yes EdgeLoggerConfiguration (this schema) LogFileSizeLimitBytes integer Optional Yes EdgeLoggerConfiguration (this schema) LogLevel reference Optional No EdgeLoggerConfiguration (this schema) Note: All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required LogFileCountLimit integer Optional LogFileSizeLimitBytes integer Optional LogLevel Optional"
                                                     },
    "zArchive/Schemas/OpcUa_schema.html":  {
                                               "href":  "zArchive/Schemas/OpcUa_schema.html",
                                               "title":  "OPC UA configuration properties",
                                               "keywords":  "OPC UA configuration properties Property Type Required Nullable Defined by Logging OpcUaLoggingConfiguration Optional Yes EdgeLoggerConfiguration DataSource DataSourceConfiguration Optional Yes ComponentsConfiguration DataSelection [OpcUaDataSelectionConfiguration] Optional Yes DataSelectionConfiguration"
                                           },
    "zArchive/Schemas/OpcUa_Logging_schema.html":  {
                                                       "href":  "zArchive/Schemas/OpcUa_Logging_schema.html",
                                                       "title":  "OPC UA logging configuration properties",
                                                       "keywords":  "OPC UA logging configuration properties Property Type Required Nullable Defined by LogFileCountLimit integer Optional Yes EdgeLoggerConfiguration (this schema) LogFileSizeLimitBytes integer Optional Yes EdgeLoggerConfiguration (this schema) LogLevel reference Optional No EdgeLoggerConfiguration (this schema) Note: All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required LogFileCountLimit integer Optional LogFileSizeLimitBytes integer Optional LogLevel Optional"
                                                   },
    "V1/Egress/Egress execution details_1-0.html":  {
                                                        "href":  "V1/Egress/Egress execution details_1-0.html",
                                                        "title":  "Egress execution details",
                                                        "keywords":  "Egress execution details After an egress endpoint is configured, data egress occurs periodically for that endpoint based on its configuration and independently from other endpoints. Note: Only streams with a single, timeseries-based index can be egressed. EDS uses OMF messages to egress data and understanding how those messages are constructed can help with understanding how data is egressed. OMF defines three types of messages: types, containers, and data. Types and containers define the data being egressed and data is the actual timeseries data. For EDS, types and containers are sent only on the first egress for an endpoint; subsequently, only new or changed types and containers are egressed. Type creation must be successful to perform container creation, and container creation must be successful to perform data egress. Type, container, and data items are batched into one or more OMF messages for egress. Per the requirements defined in the OMF specification, a single message cannot exceed 192KB in size. Compression is automatically applied to outbound egress messages. On the destination, failure to add a single item results in the message failing. In that case, Edge Data Store egresses each item individually, per type or stream (that is each type, each stream, all data for a single stream). Types, containers, and data will continue to be egressed as long as the destination continues to respond to HTTP requests - retrying previous failures as needed. If egress fails with one of the following errors, EDS will retry the request up to five times: TimeoutException HttpRequestException HttpStatusCode RequestTimeout (408) HttpStatusCode BadGateway (502) HttpStatusCode ServiceUnavailable (503) HttpStatusCode GatewayTimeout (504) There is an increasing delay before each retry. The total time for all five retries is one minute; during which time, all other egress messages for this definition are queued. If a TimeoutException or HttpRequestException error still occurs at the fifth retry, the egress fails, and EDS waits five minutes before trying the whole process again. If one of the other errors still occurs at the fifth retry, the message fails and EDS sends the next message in the queue. For data collection and egress, in-memory and on-disk storage are used to track the last successfully egressed data event, per stream. Data is egressed in order and includes future events. Note: When an event with a future timestamp is successfully egressed, only values after the associated timestamp of that event will be egressed."
                                                    },
    "docfx.console.2.43.2/content/index.html":  {
                                                    "href":  "docfx.console.2.43.2/content/index.html",
                                                    "title":  "This is the HOMEPAGE.",
                                                    "keywords":  "This is the HOMEPAGE . Refer to Markdown for how to write markdown files. Quick Start Notes: Add images to images folder if the file is referencing an image."
                                                },
    "V1/Configuration/Storage_1-0.html":  {
                                              "href":  "V1/Configuration/Storage_1-0.html",
                                              "title":  "Storage",
                                              "keywords":  "Storage The EDS storage component includes a storage component based on Sequential Data Store (SDS) technology, with a rich array of functionality available through REST APIs. Configure storage runtime characteristics, logging, and data egress to customize the storage component. For more information about SDS and SDS REST APIs, see SDS reference ."
                                          },
    "zArchive/Reference/REST commands_1-0.html":  {
                                                      "href":  "zArchive/Reference/REST commands_1-0.html",
                                                      "title":  "REST commands",
                                                      "keywords":  "REST commands The following tables provide an overview of available REST commands that you can use with components of Edge Data Store. Note: The difference between the POST and PUT methods is that POST enables you to create a configuration, while PUT replaces a configuration. If you use POST on an existing configuration, the request will fail. Administration Description Method Endpoint Delete and reset all event and configuration data related to the Edge Data Store component POST http://localhost:5590/api/v1/administration/Storage/Reset http:  localhost:5590 api v1 administration Storage Reset Reset Edge Data Store POST http://localhost:5590/api/v1/administration/System/Reset http:  localhost:5590 api v1 administration System Reset Stop an individual EDS adapter POST http://localhost:5590/api/v1/administration/EDS http:  localhost:5590 api v1 administration EDS adapterId/Stop adapterId Stop Start an individual EDS adapter POST http://localhost:5590/api/v1/administration/EDS http:  localhost:5590 api v1 administration EDS adapterId/Start adapterId Start Configuration Description Method Endpoint Verify correct installation of Edge Data Store Configure minimum Edge Data Store Configure maximum Ede Data Store PUT http://localhost:5590/api/v1/configuration http:  localhost:5590 api v1 configuration System Description Method Endpoint Configure system components PUT http://localhost:5590/api/v1/configuration/system/components http:  localhost:5590 api v1 configuration system components Configure system port PUT http://localhost:5590/api/v1/configuration/system/port http:  localhost:5590 api v1 configuration system port Configure system logging PUT http://localhost:5590/api/v1/configuration/System/Logging http:  localhost:5590 api v1 configuration System Logging Configure system health endpoints PUT http://localhost:5590/api/v1/configuration/System/HealthEndpoints http:  localhost:5590 api v1 configuration System HealthEndpoints Storage Description Method Endpoint Configure data egress (to either OCS or PI Web API) PUT http://localhost:5590/api/v1/configuration/storage/PeriodicEgressEndpoints/ http:  localhost:5590 api v1 configuration storage PeriodicEgressEndpoints  EDS adapters Note: Substitute the ID number of the adapter that you are configuring, for example OpcUa1 or OpcUa2 or Modbus3 , and so on. OPC UA Description Method Endpoint Configure an OPC UA data source PUT http://localhost:5590/api/v1/configuration/OpcUa1/Datasource http:  localhost:5590 api v1 configuration OpcUa1 Datasource Configure OPC UA data selection PUT http://localhost:5590/api/v1/configuration/OpcUa1/Dataselection http:  localhost:5590 api v1 configuration OpcUa1 Dataselection Change OPC UA logging configuration PUT http://localhost:5590/api/v1/configuration/OpcUa1/Logging http:  localhost:5590 api v1 configuration OpcUa1 Logging Modbus TCP Description Method Endpoint Configure a Modbus TCP data source PUT http://localhost:5590/api/v1/configuration/Modbus1/Datasource http:  localhost:5590 api v1 configuration Modbus1 Datasource Configure Modbus TCP data selection PUT http://localhost:5590/api/v1/configuration/Modbus1/Datasource http:  localhost:5590 api v1 configuration Modbus1 Datasource Change Modbus TCP logging configuration PUT http://localhost:5590/api/v1/configuration/Modbus1/Logging http:  localhost:5590 api v1 configuration Modbus1 Logging Tenants Types Description Method Endpoint Create an SDS type POST http://localhost:5590/api/v1/tenants/default/namespaces/default/types/Simple http:  localhost:5590 api v1 tenants default namespaces default types Simple Streams Description Method Endpoint Create an SDS stream POST http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/Simple http:  localhost:5590 api v1 tenants default namespaces default streams Simple View streams that have been created in Storage POST http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/ http:  localhost:5590 api v1 tenants default namespaces default streams  Write data events to the SDS stream POST http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/Simple/Data http:  localhost:5590 api v1 tenants default namespaces default streams Simple Data Read last data value written to server POST http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/Simple/Data/Last http:  localhost:5590 api v1 tenants default namespaces default streams Simple Data Last Read a time range of values written to server. (Example) POST http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/Simple/Data?startIndex=2017-07-08T13:00:00Z\u0026count=100 http:  localhost:5590 api v1 tenants default namespaces default streams Simple Data?startIndex=2017-07-08T13:00:00Z\u0026count=100 Read last container data value written to the server (using SDS) POST http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/MyCustomContainer/Data/Last http:  localhost:5590 api v1 tenants default namespaces default streams MyCustomContainer Data Last Read a time range of container values written to server (using SDS) (Example) POST http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/MyCustomContainer/Data?startIndex=2017-07-08T13:00:00Z\u0026count=100 http:  localhost:5590 api v1 tenants default namespaces default streams MyCustomContainer Data?startIndex=2017-07-08T13:00:00Z\u0026count=100 OMF Description Method Endpoint Create an OMF type Create an OMF container Write data events to the OMF container POST http://localhost:5590/api/v1/tenants/default/namespaces/default/omf/ http:  localhost:5590 api v1 tenants default namespaces default omf  Create an OMF container POST http://localhost:5590/api/v1/tenants/default/namespaces/default/omf/ http:  localhost:5590 api v1 tenants default namespaces default omf "
                                                  },
    "zArchive/Reference/Reference_1-0.html":  {
                                                  "href":  "zArchive/Reference/Reference_1-0.html",
                                                  "title":  "Reference",
                                                  "keywords":  "Reference This topic provides documentation of Sequential Data Store functions. It also includes current Release Notes for the Edge Data Store."
                                              },
    "zArchive/Reference/Edgecmd commands_1-0.html":  {
                                                         "href":  "zArchive/Reference/Edgecmd commands_1-0.html",
                                                         "title":  "EdgeCmd commands",
                                                         "keywords":  "EdgeCmd commands The following tables list the commands available in the EdgeCmd utility. Every EdgeCmd utility command has to be preceded by edgecmd . Help edgecmd command Description Examples edgecmd Help Display general instructions on how to use the EdgeCmd utility. edgecmd Help \u003ccomponentName\u003e Display help for a specific Edge Data Store component. edgecmd Help System edgecmd Help \u003ccomponentName\u003e \u003cfacetName\u003e Display help for a specific facet of an Edge Data store component. edgecmd Help System Port Configuration System edgecmd command Description Examples edgecmd Configuration Display the entire configuration for every Edge Data Store component. edgecmd Configuration System Components Display the components that are currently configured. edgecmd Configuration System Components componentId=\u003ccomponentId\u003e componentType=\u003ccomponentType\u003e Add a new component. edgecmd Configuration System Components componentId=Modbus1 componentType=Modbus edgecmd Configuration System Components id=\u003ccomponentId\u003e delete Delete a component. edgecmd Configuration System Components id=Modbus1 delete Components edgecmd command Description Examples edgecmd Configuration \u003ccomponentId\u003e Display component specific configuration. edgecmd Configuration System or edgecmd Configuration OpcUa1 edgecmd Configuration \u003ccomponentId\u003e \u003cfacetName\u003e Display facet specific configuration of an Edge Data Store component. edgecmd Configuration Storage Logging edgecmd Configuration \u003ccomponentId\u003e \u003cfacetName\u003e id=\u003cIndexToRetrieve\u003e Display the configuration of specific entry of a facet. edgecmd Configuration Storage PeriodicEgressEndpoints id=Endpoint1 edgecmd Configuration \u003ccomponentId\u003e DataSource Configure the data source for a Modbus TCP EDS adapter component or an OPC UA EDS adapter component. For examples, see OPC UA data source configuration and Modbus TCP data source configuration . edgecmd Configuration \u003ccomponentId\u003e DataSelection Configure the data selection for a Modbus TCP EDS adapter component or an OPC UA EDS adapter component. For examples, see OPC UA data selection configuration and Modbus TCP data selection configuration . edgecmd Configuration \u003ccomponentId\u003e Logging Configure logging for a Modbus TCP EDS adapter component or an OPC UA EDS adapter component. For examples, see Component-level logging configuration . Configuration with JSON files edgecmd command Description Examples edgecmd Configuration file=\u003cPathToJsonFile\u003e Import a bulk configuration through a JSON file. edgecmd Configuration file=\"~/Bulk_Storage_Runtime.json\" file=\"~ Bulk_Storage_Runtime.json\" edgecmd Configuration \u003ccomponentId\u003e \u003cfacetName\u003e file=\u003cPathToJsonFile\u003e Import a facet specific configuration file for a component. edgecmd Configuration Modbus1 DataSource file=\"~/Modbus_DataSource.json\" file=\"~ Modbus_DataSource.json\""
                                                     },
    "V1/Troubleshooting/Troubleshooting_1-0.html":  {
                                                        "href":  "V1/Troubleshooting/Troubleshooting_1-0.html",
                                                        "title":  "Troubleshoot Edge Data Store",
                                                        "keywords":  "Troubleshoot Edge Data Store Edge Data Store includes both local and remote means of diagnosing issues encountered while using or developing against EDS. Edge Data Store supports a diagnostics namespace that stores streams containing diagnostic information from Edge Data Store itself. Egress this data to either a PI Web Server or OSIsoft Cloud Services to monitor the state of a system remotely. For details about egressing diagnostic data, see Diagnostics configuration . In addition to diagnostics data, all components in Edge Data Store support OMF health messages. Configure health messages to send health data to either PI Web Server or OSIsoft Cloud Service endpoints for remote monitoring of devices. For more information, see Health endpoints configuration . OMF ingress Complete the following steps when a custom application fails to write stream data to EDS: Verify the custom application is sending OMF messages in the correct order: 1) OMF type, 2) OMF container, 3) OMF data. Note: OMF messages must be sent in the correct order to be ingressed into Edge Data Store. Refer to logging of warnings, errors, and messages for help with diagnosing these issues. OMF ingress logging Ingress logging messages provide a record of ingress events. Complete the following steps to capture the most information for troubleshooting: Refer to System-level logging configuration to set logging parameters. For maximum message logging information, set the log level to Trace . OMF ingress message debugging Use debugging information to troubleshoot problems between an OMF application and Edge Data Store. Complete the following steps to enable debugging: Refer to Storage runtime configuration to enable debugging. Set an appropriate time value for the IngressDebugExpiration property. Note: You can also disable debugging by setting the expiration value to null . Examples of valid strings representing date and time: UTC: \"yyyy-mm-ddThh:mm:ssZ\" Local: \"mm-dd-yyyy hh:mm:ss\" Periodic egress EDS periodic egress extracts data from SDS streams and sends the appropriate sequences of type, container, and data OMF messages on startup. Note: If unexpected data appears in an OCS or PI System, check if multiple devices are writing to the same SDS stream. Check all egress configuration files in Edge Data Store to verify whether any endpoints are duplicated. A duplicate endpoint means that more than one device is egressing data to it, resulting in unexpected data. Assign stream prefixes in the periodic egress endpoint configuration to ensure that output data streams are logically separated in the systems of record. For instructions, see Configure data egress . Note: Type prefixes may be helpful if you have changed a stream type definition on EDS. OMF types on both OCS and the PI System are immutable once created. If the type of the data stream changes, it is best to either delete the old type definition (if nothing is still using it) or add a type prefix to create a new unique type that will be used by new streams egressing from EDS to the systems of record. Periodic egress logging Egress logging messages provide a record of egress events. Complete the following to capture maximum information for troubleshooting: Refer to System-level logging configuration to set logging parameters. For maximum message logging information, set the log level to Trace . Periodic egress debugging Use debugging information to troubleshoot problems between Edge Data Store and the egress destination. Complete the following steps to enable debugging: Refer to Data egress configuration to enable debugging. Set an appropriate time value for the DebugExpiration property. Note: Disable debugging by setting the expiration value to null . Examples of valid strings representing date and time: UTC: \"yyyy-mm-ddThh:mm:ssZ\" Local: \"mm-dd-yyyy hh:mm:ss\" Debugging folder/file folder file structure Because the overall number and content length of each request/response request response pair captured by debugging can be quite large, debugging information is stored to disk in a separate location from other log messages. Debug folders and files are created under the Edge Data Store data folder as follows: Windows: %programdata%\\OSIsoft\\EdgeDataStore\\Storage\\egressdump\\{tenantId}\\{namespaceId}\\{egressId}\\{omfType}\\{Ticks}-{Guid}-{Req/Res}.txt %programdata%\\OSIsoft\\EdgeDataStore\\Storage\\egressdump\\{tenantId}\\{namespaceId}\\{egressId}\\{omfType}\\{Ticks}-{Guid}-{Req Res}.txt Linux: /usr/share/OSIsoft/EdgeDataStore/Storage/egressdump/{tenantId}/{namespaceId}/{egressId}/{omfType}/{Ticks}-{Guid}-{Req/Res}.txt  usr share OSIsoft EdgeDataStore Storage egressdump {tenantId} {namespaceId} {egressId} {omfType} {Ticks}-{Guid}-{Req Res}.txt The OMF specific elements of the file structure are defined in the following table: Element Represents omfType The OMF message type: Type, Container, or Data. Ticks The time in milliseconds (tick count) for UTC DateTime when determined message would be written to disk. Guid The unique GUID for each request/response request response pair. Req/Res Req Res Whether the message was HTTP request or response."
                                                    },
    "V1/SDS/Streams/Sds_Streams_API_1-0.html":  {
                                                    "href":  "V1/SDS/Streams/Sds_Streams_API_1-0.html",
                                                    "title":  "SdsStream API",
                                                    "keywords":  "SdsStream API The REST APIs provide programmatic access to read and write SDS data. The APIs in this section interact with SdsStreams. For general SdsStream information, see Streams . Get Stream Returns the specified stream. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId} api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. Response The response includes a status code and a response body. Response body The requested SdsStream. Example response body: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"Id\":\"Simple\", \"Name\":\"Simple\", \"TypeId\":\"Simple\", } Get Streams Returns a list of streams. If the optional search query parameter is specified, the list of streams returned will match the search criteria. If the search query parameter is not specified, the list will include all streams in the namespace. See Search in SDS for information about specifying those respective parameters. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams?query={query}\u0026skip={skip}\u0026count={count}\u0026orderby={orderby} api v1 Tenants default Namespaces {namespaceId} Streams?query={query}\u0026skip={skip}\u0026count={count}\u0026orderby={orderby} Parameters string namespaceId The namespace; either default or diagnostics. string query An optional parameter representing a string search. For information about specifying the search parameter, see Search in SDS . int skip An optional parameter representing the zero-based offset of the first SdsStream to retrieve. If not specified, a default value of 0 is used. int count An optional parameter representing the maximum number of SdsStreams to retrieve. If not specified, a default value of 100 is used. string orderby An optional parameter representing sorted order which SdsStreams will be returned. A field name is required. The sorting is based on the stored values for the given field (of type string). For example, orderby=name would sort the returned results by the name values (ascending by default). Additionally, a value can be provided along with the field name to identify whether to sort ascending or descending, by using values asc or desc , respectively. For example, orderby=name desc would sort the returned results by the name values, descending. If no value is specified, there is no sorting of results. Response The response includes a status code and a response body. Response body A collection of zero or more SdsStreams. Example response body: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Id\":\"Simple\", \"TypeId\":\"Simple\" }, { \"Id\":\"Simple with Secondary\", \"TypeId\":\"Simple\", \"Indexes\":[ { \"SdsTypePropertyId\":\"Measurement\" } ] }, { \"Id\":\"Compound\", \"TypeId\":\"Compound\" }, ] Get Stream Type Returns the type definition that is associated with a given stream. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Type api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Type Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. Response The response includes a status code and a response body. Response body The requested SdsType. Get or Create Stream Creates the specified stream. If a stream with a matching identifier already exists, SDS compares the existing stream with the stream that was sent. If the streams are identical, a Found (302) error is returned with the Location header set to the URI where the stream may be retrieved using a Get function. If the streams do not match, a Conflict (409) error is returned. For a matching stream (Found), clients that are capable of performing a redirect that includes the authorization header can automatically redirect to retrieve the stream. However, most clients, including the .NET HttpClient, consider redirecting with the authorization token to be a security vulnerability. When a client performs a redirect and strips the authorization header, SDS cannot authorize the request and returns Unauthorized (401). For this reason, it is recommended that when using clients that do not redirect with the authorization header, you should disable automatic redirect. Request POST api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId} api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. The stream identifier must match the identifier in content. Request body The request content is the serialized SdsStream. Response The response includes a status code and a response body. Response body The newly created SdsStream. Create or Update Stream Creates the specified stream. If a stream with the same Id already exists, the definition of the stream is updated. The following changes are permitted: Name Description Indexes InterpolationMode ExtrapolationMode PropertyOverrides Note that modifying Indexes will result in re-indexing all of the stream\u0027s data for each additional secondary index. For more information on secondary indexes, see Indexes . Unpermitted changes result in an error. Request PUT api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId} api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. Request body The request content is the serialized SdsStream. Response The response includes a status code. Update Stream Type Updates a stream???s type. The type is modified to match the specified stream view. Defined Indexes and PropertyOverrides are removed when updating a stream type. Request PUT api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Type?streamViewId={streamViewId} api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Type?streamViewId={streamViewId} Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. string streamViewId The stream view identifier. Request body The request content is the serialized SdsStream. Response The response includes a status code. Response body On failure, the content contains a message describing the issue. Delete Stream Deletes a stream. Request DELETE api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId} api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. Response The response includes a status code."
                                                },
    "V1/SDS/Search/Search_operators_1-0.html":  {
                                                    "href":  "V1/SDS/Search/Search_operators_1-0.html",
                                                    "title":  "Search operators",
                                                    "keywords":  "Search operators Specify search operators in the query string to return more specific search results. Operators Description AND AND operator. For example, cat AND dog searches for streams containing both \"cat\" and \"dog\". AND must be in all caps. OR OR operator. For example, cat OR dog searches for streams containing either \"cat\" or \"dog\" or both. OR must be in all caps. NOT NOT operator. For example, cat NOT dog searches for streams that have the \"cat\" term or do not have \"dog\". NOT must be in all caps. * Wildcard operator. For example, cat* searches for streams that have a term that starts with \"cat\", ignoring case. : Field-scoped query. For example, id:stream* will search for streams where the id field starts with \"stream\", but will not search on other fields like name or description . Note: Field names are camel case and are case sensitive. ( ) Precedence operator. For example, motel AND (wifi OR luxury) searches for streams containing motel and either wifi or luxury (or both). Note: You can use the wildcard * only once for each search term, except for the case of a Contains type query clause. In that case, two wildcards are allowed: one as prefix and one as suffix; for example, *Tank* is valid, but *Ta*nk , Ta*nk* , and *Ta*nk* are not supported. The wildcard * only works when specifying a single search term. For example, you can search for Tank* , *Tank , Ta*nk but not Tank Meter* . : Operator Set the fields to search using the following syntax: fieldname:fieldvalue Request The following example shows the \u0027:\u0027 operator. GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams?query=name:pump api v1 Tenants default Namespaces {namespaceId} Streams?query=name:pump name:pressure * Operator Use the \u0027*\u0027 character as a wildcard to specify an incomplete string. Query string Matches field value Does not match field value log* log logger analog *log analog alog logg *log* analog alogger lop l*g log logg lop Supported Not Supported * *log l*g log* *log* *l*g* *l*g l*g* Request The following example shows the \u0027*\u0027 operator. GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams?query=log* api v1 Tenants default Namespaces {namespaceId} Streams?query=log* Other operator examples Query string Matches field value Does not match field value mud AND log log mud mud log mud log mud OR log log mud mud log mud AND (NOT log) mud mud log mud AND (log OR pump*) mud log mud pumps mud bath name:stream* AND (description:pressure OR description:pump) The name starts with \"stream\" and the description includes either term \"pressure\" or term \"pump\""
                                                },
    "V1/SDS/Read data/Reading_Data_API_1-0.html":  {
                                                       "href":  "V1/SDS/Read data/Reading_Data_API_1-0.html",
                                                       "title":  "Read data API",
                                                       "keywords":  "Read data API The following example API calls show different methods for reading data. Example type, stream, and data Many of the API methods described below contain example requests and responses in JSON to highlight usage and specific behaviors. The following type, stream, and data are used in the examples: Example type SimpleType is an SdsType with a single index. This type is defined in Python and Javascript: Python class State(Enum): Ok = 0 Warning = 1 Alarm = 2 class SimpleType(object): Time = property(getTime, setTime) def getTime(self): return self.__time def setTime(self, time): self.__time = time State = property(getState, setState) def getState(self): return self.__state def setState(self, state): self.__state = state Measurement = property(getValue, setValue) def getValue(self): return self.__measurement def setValue(self, measurement): self.__measurement = measurement JavaScript var State = { Ok: 0, Warning: 1, Alarm: 2, } var SimpleType = function () { this.Time = null; this.State = null; this.Value = null; } Example stream Simple is an SdsStream of type SimpleType . Example data Simple has stored values as follows: 11/23/2017 11 23 2017 12:00:00 PM: Ok 0 11/23/2017 11 23 2017 1:00:00 PM: Ok 10 11/23/2017 11 23 2017 2:00:00 PM: Ok 20 11/23/2017 11 23 2017 3:00:00 PM: Ok 30 11/23/2017 11 23 2017 4:00:00 PM: Ok 40 All times are represented at offset 0, GMT. Get First Value Returns the first value in the stream. If no values exist in the stream, null is returned. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/First api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data First Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. Response The response includes a status code and a response body containing a serialized event. Get Last Value Returns the last value in the stream. If no values exist in the stream, null is returned. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/Last api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Last Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. Response The response includes a status code and a response body containing a serialized event. Find Distinct Value Returns a stored event based on the specified index and searchMode . Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data ?index={index}\u0026searchMode={searchMode} Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. string index The index. string searchMode The SdsSearchMode ; the default is exact . Response The response includes a status code and a response body containing a serialized collection with one event. Depending on the request index and searchMode , it is possible to have an empty collection returned. Example GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?index=2017-11-23T13:00:00Z\u0026searchMode=Next The request has an index that matches the index of an existing event, but since a SdsSearchMode of next was specified, the response contains the next event in the stream after the specified index: Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 } ] Example GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?index=2017-11-23T13:30:00Z\u0026searchMode=Next The request specifies an index that does not match an index of an existing event. The next event in the stream is retrieved. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 } ] Get Values Returns a collection of stored values at indexes based on request parameters. SDS supports three ways of specifying which stored events to return: Filtered : A filtered request accepts a filter expression. Range : A range request accepts a start index and a count. Window : A window request accepts a start index and end index. This request has an optional continuation token for large collections of events. Filtered Returns a collection of stored values as determined by a filter . The filter limits results by applying an expression against event fields. For more information about filter expressions, see Filter expressions . Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data ?filter={filter} Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. string filter The filter expression (see Filter expressions ). Response The response includes a status code and a response body containing a serialized collection of events. Example GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?filter=Measurement gt 10 The events in the stream with Measurement greater than 10 are returned. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T14:00:00Z\", \"Measurement\": 20 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"Measurement\": 30 }, { \"Time\": \"2017-11-23T16:00:00Z\", \"Measurement\": 40 } ] Note: State is not included in the JSON as its value is the default value. Range Returns a collection of stored values as determined by a startIndex and count . Additional optional parameters specify the direction of the range, how to handle events near or at the start index, whether to skip a certain number of events at the start of the range, and how to filter the data. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data ?startIndex={startIndex}\u0026count={count}[\u0026skip={skip}\u0026reversed={reversed} \u0026boundaryType={boundaryType}\u0026filter={filter}] Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. string startIndex Index identifying the beginning of the series of events to return. int count The number of events to return. int skip Optional value specifying the number of events to skip at the beginning of the result. bool reversed Optional specification of the direction of the request. By default, range requests move forward from startIndex, collecting events after startIndex from the stream. A reversed request will collect events before startIndex from the stream. SdsBoundaryType boundaryType Optional SdsBoundaryType specifies the handling of events at or near startIndex. string filter Optional filter expression. Response The response includes a status code and a response body containing a serialized collection of events. Example GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-11-23T13:00:00Z\u0026count=100 This request will return a response with up to 100 events starting at 13:00 and extending forward toward the end of the stream: Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T13:00:00Z\", \"Measurement\": 10 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"Measurement\": 20 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"Measurement\": 30 }, { \"Time\": \"2017-11-23T16:00:00Z\", \"Measurement\": 40 } ] Note: State is not included in the JSON as its value is the default value. Example To reverse the direction of the request, set reversed to true. The following request will return up to 100 events starting at 13:00 and extending back toward the start of the stream: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-11-23T13:00:00Z\u0026count=100\u0026reversed=true Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T13:00:00Z\", \"Measurement\": 10 }, { \"Time\": \"2017-11-23T12:00:00Z\" } ] Note: State is not included in the JSON as its value is the default value. Further, Measurement is not included in the second, 12:00:00, event as zero is the default value for numbers. The following request specifies a boundary type of Outside for a reversed-direction range request. The response will contain up to 100 events. The boundary type Outside indicates that up to one event outside the boundary will be included in the response. For a reverse direction range request, this means one event forward of the specified start index. In a default direction range request, it would mean one event before the specified start index. GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-11-23T13:00:00Z\u0026count=100\u0026reversed=true\u0026boundaryType=2 Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 }, { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 10 }, { \"Time\": \"2017-11-23T12:00:00Z\", \"State\": 0, \"Measurement\": 0 } ] The event outside of the index is the next event or the event at 14:00 because the request operates in reverse. Adding a filter to the request means only events that meet the filter criteria are returned: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-11-23T13:00:00Z\u0026count=100\u0026reversed=true\u0026boundaryType=2\u0026filter=Measurement gt 10 Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 } ] Window Returns a collection of stored events based on the specified startIndex and endIndex . For handling events at and near the boundaries of the window, a single SdsBoundaryType that applies to both the start and end indexes can be passed with the request, or separate boundary types may be passed for the start and end individually. Paging is supported for window requests with a large number of events. To retrieve the next page of values, include the continuationToken from the results of the previous request. For the first request, specify a null or empty string for the continuationToken . Requests GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data? api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data? ?startIndex={startIndex}\u0026endIndex={endIndex} GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data? api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data? ?startIndex={startIndex}\u0026endIndex={endIndex}\u0026boundaryType={boundaryType} GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data? api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data? ?startIndex={startIndex}\u0026startBoundaryType={startBoundaryType} \u0026endIndex={endIndex}\u0026endBoundaryType={endBoundaryType} GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data? api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data? ?startIndex={startIndex}\u0026endIndex={endIndex} \u0026count={count}\u0026continuationToken={continuationToken} GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data? api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data? ?startIndex={startIndex}\u0026startBoundaryType={startBoundaryType} \u0026endIndex={endIndex}\u0026endBoundaryType={endBoundaryType}\u0026filter={filter}\u0026count={count} \u0026continuationToken={continuationToken} Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. string startIndex Index bounding the beginning of the series of events to return. string endIndex Index bounding the end of the series of events to return. int count Optional maximum number of events to return. If count is specified, a continuationToken must also be specified. SdsBoundaryType boundaryType Optional SdsBoundaryType specifies handling of events at or near the start and end indexes. SdsBoundaryType startBoundaryType Optional SdsBoundaryType specifies the first value in the result in relation to the start index. If startBoundaryType is specified, endBoundaryType must be specified. SdsBoundaryType endBoundaryType Optional SdsBoundaryType specifies the last value in the result in relation to the end index. If startBoundaryType is specified, endBoundaryType must be specified. string filter Optional filter expression (see Filter expressions ). string continuationToken Optional token used to retrieve the next page of data. If count is specified, a continuationToken must also be specified. Response The response includes a status code and a response body containing a serialized collection of events. A continuation token can be returned if specified in the request. Example The following requests all stored events between 12:30 and 15:30: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-11-23T12:30:00Z\u0026endIndex=2017-11-23T15:30:00Z The response will contain the event stored at the specified index: Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T13:00:00Z\", \"Measurement\": 10 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"Measurement\": 20 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"Measurement\": 30 } ] Note: State is not included in the JSON as its value is the default value. Example When the request is modified to specify a boundary type of Outside, the value before 13:30 and the value after 15:30 are included: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-11-23T12:30:00Z\u0026endIndex=2017-11-23T15:30:00Z \u0026boundaryType=2 Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T12:00:00Z\" }, { \"Time\": \"2017-11-23T13:00:00Z\", \"Measurement\": 10 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"Measurement\": 20 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"Measurement\": 30 }, { \"Time\": \"2017-11-23T16:00:00Z\", \"Measurement\": 40 } ] Note: State is not included in the JSON as its value is the default value. Further, Measurement is not included in the second, 12:00:00, event as zero is the default value for numbers. If instead a start boundary of Inside, only values inside the start boundary (after 13:30) are included in the result. With an end boundary of Outside one value outside the end index (after 15:30) is included: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-11-23T12:30:00Z\u0026\u0026startBoundaryType=1 \u0026endIndex=2017-11-23T15:30:00Z\u0026endBoundaryType=2 Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 10 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 30 }, { \"Time\": \"2017-11-23T16:00:00Z\", \"State\": 0, \"Measurement\": 40 } ] To page the results of the request, a continuation token may be specified. This requests the first page of the first two stored events between start index and end index by indicating count is 2 and continuationToken is an empty string: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-11-23T12:30:00Z\u0026endIndex=2017-11-23T15:30:00Z \u0026count=2\u0026continuationToken= Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"Results\": [ { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 10 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 } ], \"ContinuationToken\": \"2017-11-23T14:00:00.0000000Z\" } This request uses the continuation token from the previous page to request the next page of stored events: GET api/v1/Tenants/default}/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default} Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-11-23T12:30:00Z\u0026endIndex=2017-11-23T15:30:00Z \u0026count=2\u0026continuationToken=2017-11-23T14:00:00Z Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"Results\": [ { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 30 } ], \"ContinuationToken\": null } In this case, the results contain the final event. The returned continuation token is null. Get Interpolated Values Returns a collection of values based on request parameters. The stream\u0027s read characteristics determine how events are calculated for indexes at which no stored event exists. Interpolation is not supported for streams with compound indexes. SDS supports two ways of specifying which interpolated events to return: Index Collection : One or more indexes can be passed to the request to retrieve events at specific indexes. Interval : An interval can be specified with a start index, end index, and count. This will return the specified count of events evenly spaced from start index to end index. Index Collection Returns events at the specified indexes. If no stored event exists at a specified index, the stream\u0027s read characteristics determine how the returned event is calculated. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/ api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data  Interpolated?index={index}[\u0026index={index}...] Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. string index One or more indexes. Response The response includes a status code and a response body containing a serialized collection of events. Depending on the specified indexes and read characteristics of the stream, it is possible to have less events returned than specified indexes. An empty collection can also be returned. Example Consider a stream of type Simple with the default InterpolationMode of Continuous and ExtrapolationMode of All . In the following request, the specified index matches an existing stored event: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data/ api v1 Tenants default Namespaces {namespaceId} Streams Simple Data  Interpolated?index=2017-11-23T13:00:00Z The response will contain the event stored at the specified index. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 10 } ] The following request specifies an index for which no stored event exists: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data/ api v1 Tenants default Namespaces {namespaceId} Streams Simple Data  Interpolated?index=2017-11-23T13:30:00Z Because the index is a valid type for interpolation and the stream has an InterpolationMode of Continuous , this request receives a response with an event interpolated at the specified index: Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T13:30:00Z\", \"State\": 0, \"Measurement\": 15 } ] Consider a stream of type Simple with an InterpolationMode of Discrete and ExtrapolationMode of All . In the following request, the specified indexes only match two existing stored events: GET api/v1/Tenants/default}/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default} Namespaces {namespaceId} Streams Simple Data Interpolated?index=2017-11-23T12:30:00Z\u0026index=2017-11-23T13:00:00Z\u0026index=2017-11-23T14:00:00Z For this request, the response contains events for two of the three specified indexes. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 10 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 } ] Interval Returns events at evenly spaced intervals based on the specified start index, end index, and count. If no stored event exists at an index interval, the stream\u0027s read characteristics determine how the returned event is calculated. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/ api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data  Interpolated?startIndex={startIndex}\u0026endIndex={endIndex}\u0026count={count} Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. string startIndex The index defining the beginning of the window. string endIndex The index defining the end of the window. int count The number of events to return. Read characteristics of the stream determine how the events are constructed. Response The response includes a status code and a response body containing a serialized collection of events. Depending on the read characteristics and input parameters, it is possible for a collection to be returned with less events than specified in the count. For a stream, named Simple, of type Simple for the following request: GET api/v1/Tenants/default}/Namespaces/{namespaceId}/Streams/Simple/Data/ api v1 Tenants default} Namespaces {namespaceId} Streams Simple Data  Interpolated?startIndex=2017-11-23T13:00:00Z\u0026endIndex=2017-11-23T15:00:00Z\u0026count=3 The start and end fall exactly on event indexes, and the number of events from start to end match the count of three (3). Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 10 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 30 } ] Get Summaries Returns summary intervals between a specified start and end index. Index types that cannot be interpolated do not support summary requests. Strings are an example of indexes that cannot be interpolated. Summaries are not supported for streams with compound indexes. Interpolating between two indexes that consist of multiple properties is not defined and results in non-determinant behavior. Summary values supported by SdsSummaryType enum: Summary Enumeration value Count 1 Minimum 2 Maximum 4 Range 8 Mean 16 StandardDeviation 64 Total 128 Skewness 256 Kurtosis 512 WeightedMean 1024 WeightedStandardDeviation 2048 WeightedPopulationStandardDeviatio 4096 Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/ api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data  Summaries?startIndex={startIndex}\u0026endIndex={endIndex}\u0026count={count}\u0026filter={filter} Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. string startIndex The start index for the intervals. string endIndex The end index for the intervals. int count The number of intervals requested. string filter Optional filter expression (see Filter expressions ). string streamViewId Optional stream view identifier. Response The response includes a status code and a response body containing a serialized collection of SdsIntervals. Each SdsInterval has a start, end, and collection of summary values. Property Details Start The start of the interval End The end of the interval Summaries The summary values for the interval, keyed by summary type. The nested dictionary contains property name keys and summary calculation result values. Example The following request calculates two summary intervals between the startIndex and endIndex : GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data/ api v1 Tenants default Namespaces {namespaceId} Streams Simple Data  Summaries?startIndex=2017-11-23T12:00:00Z\u0026endIndex=2017-11-23T16:00:00Z\u0026count=2 Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Start\": { \"Time\": \"2017-11-23T12:00:00Z\", \"State\": 0, \"Measurement\": 0 }, \"End\": { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 }, \"Summaries\": { \"Count\": { \"Measurement\": 2 }, \"Minimum\": { \"Measurement\": 0 }, \"Maximum\": { \"Measurement\": 20 }, \"Range\": { \"Measurement\": 20 }, \"Total\": { \"Measurement\": 20 }, \"Mean\": { \"Measurement\": 10 }, \"StandardDeviation\": { \"Measurement\": 7.0710678118654755 }, \"PopulationStandardDeviation\": { \"Measurement\": 5 }, \"WeightedMean\": { \"Measurement\": 10 }, \"WeightedStandardDeviation\": { \"Measurement\": 7.0710678118654755 }, \"WeightedPopulationStandardDeviation\": { \"Measurement\": 5 }, \"Skewness\": { \"Measurement\": 0 }, \"Kurtosis\": { \"Measurement\": -2 } } }, { \"Start\": { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 }, \"End\": { \"Time\": \"2017-11-23T16:00:00Z\", \"State\": 0, \"Measurement\": 40 }, \"Summaries\": { \"Count\": { \"Measurement\": 2 }, \"Minimum\": { \"Measurement\": 20 }, \"Maximum\": { \"Measurement\": 40 }, \"Range\": { \"Measurement\": 20 }, \"Total\": { \"Measurement\": 60 }, \"Mean\": { \"Measurement\": 30 }, \"StandardDeviation\": { \"Measurement\": 7.0710678118654755 }, \"PopulationStandardDeviation\": { \"Measurement\": 5 }, \"WeightedMean\": { \"Measurement\": 30 }, \"WeightedStandardDeviation\": { \"Measurement\": 7.0710678118654755 }, \"WeightedPopulationStandardDeviation\": { \"Measurement\": 5 }, \"Skewness\": { \"Measurement\": 0 }, \"Kurtosis\": { \"Measurement\": -2 } } } ] Get Sampled Values Returns data sampled by intervals between a specified start and end index. Sampling is driven by a specified property or properties of the stream\u0027s SdsType. Property types that cannot be interpolated do not support sampling requests. Strings are an example of a property that cannot be interpolated. For more information, see Interpolation. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/ api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data  Sampled?startIndex={startIndex}\u0026endIndex={endIndex}\u0026intervals={intervals}\u0026sampleBy={sampleBy} \u0026boundaryType={boundaryType}\u0026startBoundaryType={startBoundaryType} \u0026endBoundaryType={endBoundaryType}\u0026filter={filter}\u0026streamViewId={streamViewId} Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. string startIndex The start index for the intervals. string endIndex The end index for the intervals. int intervals The number of intervals requested. string sampleBy Property or properties to use when sampling. SdsBoundaryType boundaryType Optional SdsBoundaryType specifies the handling of events at or near the startIndex and endIndex. SdsBoundaryType startBoundaryType Optional SdsBoundaryType specifies the handling of events at or near the startIndex. SdsBoundaryType endBoundaryType Optional SdsBoundaryType specifies the handling of events at or near the endIndex. string filter Optional filter expression (see Filter expressions ). Response The response includes a status code and a response body containing a serialized collection of events. Example The following request returns two sample intervals between the startIndex and endIndex : GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data/ api v1 Tenants default Namespaces {namespaceId} Streams Simple Data  Sampled?startIndex=2019-01-01T00:00:00Z\u0026endIndex=2019-01-02T00:00:00Z\u0026intervals=2\u0026sampleBy=Measurement Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2019-01-01T00:00:01Z\", \"State\": 1, \"Measurement\": 1 }, { \"Time\": \"2019-01-01T00:11:50Z\", \"State\": 2, \"Measurement\": 0.00006028870675578446 }, { \"Time\": \"2019-01-01T11:55:33Z\", \"Measurement\": 6.277981349066863 }, { \"Time\": \"2019-01-01T12:00:00Z\", \"Measurement\": 3.101013140344655 }, { \"Time\": \"2019-01-01T12:00:01Z\", \"State\": 1, \"Measurement\": 4.101013140344655 }, { \"Time\": \"2019-01-01T12:01:50Z\", \"State\": 2, \"Measurement\": 0.0036776111121028521 }, { \"Time\": \"2019-01-01T23:57:23Z\", \"State\": 2, \"Measurement\": 6.2816589601789659 }, { \"Time\": \"2019-01-02T00:00:00Z\", \"Measurement\": 6.20202628068931 } ] Note: State is not included in the JSON when its value is the default value. Join Values Returns data from multiple streams, which are joined based on the request specifications. The streams must be of the same SdsType. SDS supports the following types of joins: SdsJoinMode Enumeration value Operation Inner 0 Results include the stored events with common indexes across specified streams. Outer 1 Results include the stored events for all indexes across all streams. Interpolated 2 Results include events for each index across all streams for the request index boundaries. Some events may be interpolated. MergeLeft 3 Results include events for each index across all streams selecting events at the indexes based on left to right order of the streams. MergeRight 4 Results include events for each index across all streams selecting events at the indexes based on right to left order of the streams. SDS supports two types of join requests: GET : The stream, joinMode, start index, and end index are specified in the request URI path. POST : Only the SdsJoinMode is specified in the URI. The streams and read specification for each stream are specified in the body of the request. GET Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Bulk/Streams/Data/Joins api v1 Tenants default Namespaces {namespaceId} Bulk Streams Data Joins ?streams={streams}\u0026joinMode={joinMode} \u0026startIndex={startIndex}\u0026endIndex={endIndex} Parameters string namespaceId The namespace; either default or diagnostics. string streams Commas separated list of stream identifiers. SdsJoinMode joinMode Type of join, that is inner, outer, and so on. string startIndex Index identifying the beginning of the series of events to return. string endIndex Index identifying the end of the series of events to return. Response The response includes a status code and a response body containing multiple serialized events. See examples for specifics. Examples To join multiple streams, for example Simple1 and Simple2, assume that Simple1 presents the following data: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T11:00:00Z\", \"State\": 0, \"Measurement\": 10 }, { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 20 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 30 }, { \"Time\": \"2017-11-23T16:00:00Z\", \"State\": 0, \"Measurement\": 40 } ] And assume that Simple2 presents the following data: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T12:00:00Z\", \"State\": 0, \"Measurement\": 50 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 60 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 70 }, { \"Time\": \"2017-11-23T17:00:00Z\", \"State\": 0, \"Measurement\": 80 } ] The following are responses for various Joins request options: Inner join example GET api/v1/Tenants/default/Namespaces/{namespaceId}/Bulk/Streams/Data/Joins api v1 Tenants default Namespaces {namespaceId} Bulk Streams Data Joins ?streams=Simple1,Simple2\u0026joinMode=inner \u0026startIndex=0001-01-01T00:00:00.0000000\u0026endIndex=9999-12-31T23:59:59.9999999 Response Measurements from both streams with common indexes. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ [ { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 30 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 60 } ] ] Outer join example GET api/v1/Tenants/default/Namespaces/{namespaceId}/Bulk/Streams/Data/Joins api v1 Tenants default Namespaces {namespaceId} Bulk Streams Data Joins ?streams=Simple1,Simple2\u0026joinMode=outer \u0026startIndex=0001-01-01T00:00:00.0000000\u0026endIndex=9999-12-31T23:59:59.9999999 Response All Measurements from both Streams, with default values at indexes where a Stream does not have a value. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ [ { \"Time\": \"2017-11-23T11:00:00Z\", \"State\": 0, \"Measurement\": 10 }, null ], [ null, { \"Time\": \"2017-11-23T12:00:00Z\", \"State\": 0, \"Measurement\": 50 } ], [ { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 20 }, null ], [ { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 30 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 60 } ], [ null, { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 70 } ], [ { \"Time\": \"2017-11-23T16:00:00Z\", \"State\": 0, \"Measurement\": 40 }, null ], [ null, { \"Time\": \"2017-11-23T17:00:00Z\", \"State\": 0, \"Measurement\": 80 } ] ] Interpolated join example GET api/v1/Tenants/default/Namespaces/{namespaceId}/Bulk/Streams/Data/Joins api v1 Tenants default Namespaces {namespaceId} Bulk Streams Data Joins ?streams=Simple1,Simple2\u0026joinMode=interpolated \u0026startIndex=0001-01-01T00:00:00.0000000\u0026endIndex=9999-12-31T23:59:59.9999999 Response All measurements from both Streams with missing values interpolated. If the missing values are between valid measurements within a stream, they are interpolated. If the missing values are outside of the boundary values, they are extrapolated. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ [ { \"Time\": \"2017-11-23T11:00:00Z\", \"State\": 0, \"Measurement\": 10 }, { \"Time\": \"2017-11-23T11:00:00Z\", \"State\": 0, \"Measurement\": 50 } ], [ { \"Time\": \"2017-11-23T12:00:00Z\", \"State\": 0, \"Measurement\": 15 }, { \"Time\": \"2017-11-23T12:00:00Z\", \"State\": 0, \"Measurement\": 50 } ], [ { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 20 }, { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 55 } ], [ { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 30 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 60 } ], [ { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 35 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 70 } ], [ { \"Time\": \"2017-11-23T16:00:00Z\", \"State\": 0, \"Measurement\": 40 }, { \"Time\": \"2017-11-23T16:00:00Z\", \"State\": 0, \"Measurement\": 75 } ], [ { \"Time\": \"2017-11-23T17:00:00Z\", \"State\": 0, \"Measurement\": 40 }, { \"Time\": \"2017-11-23T17:00:00Z\", \"State\": 0, \"Measurement\": 80 } ] ] MergeLeft join example GET api/v1/Tenants/default/Namespaces/{namespaceId}/Bulk/Streams/Data/Joins api v1 Tenants default Namespaces {namespaceId} Bulk Streams Data Joins ?streams=Simple1,Simple2\u0026joinMode=mergeleft \u0026startIndex=0001-01-01T00:00:00.0000000\u0026endIndex=9999-12-31T23:59:59.9999999 Response This is similar to OuterJoin , but the value at each index is the first available value at that index when iterating the given list of streams from left to right. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T11:00:00Z\", \"State\": 0, \"Measurement\": 10 }, { \"Time\": \"2017-11-23T12:00:00Z\", \"State\": 0, \"Measurement\": 50 }, { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 20 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 30 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 70 }, { \"Time\": \"2017-11-23T16:00:00Z\", \"State\": 0, \"Measurement\": 40 }, { \"Time\": \"2017-11-23T17:00:00Z\", \"State\": 0, \"Measurement\": 80 } ] MergeRight join example GET api/v1/Tenants/default/Namespaces/{namespaceId}/Bulk/Streams/Data/Joins api v1 Tenants default Namespaces {namespaceId} Bulk Streams Data Joins ?streams=Simple1,Simple2\u0026joinMode=mergeright \u0026startIndex=0001-01-01T00:00:00.0000000\u0026endIndex=9999-12-31T23:59:59.9999999 Response This is similar to OuterJoin , but the value at each index is the first available value at that index when iterating the given list of streams from right to left. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T11:00:00Z\", \"State\": 0, \"Measurement\": 10 }, { \"Time\": \"2017-11-23T12:00:00Z\", \"State\": 0, \"Measurement\": 50 }, { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 20 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 60 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 70 }, { \"Time\": \"2017-11-23T16:00:00Z\", \"State\": 0, \"Measurement\": 40 }, { \"Time\": \"2017-11-23T17:00:00Z\", \"State\": 0, \"Measurement\": 80 } ] POST request POST api/v1/Tenants/default/Namespaces/{namespaceId}/Bulk/Streams/Data/Joins api v1 Tenants default Namespaces {namespaceId} Bulk Streams Data Joins ?joinMode={joinMode} Parameters string namespaceId The namespace; either default or diagnostics. SdsJoinMode joinMode Type of join, that is inner, outer, and so on. Request body Read options specific to each stream. Response The response includes a status code and a response body containing multiple serialized events. Consider the following outer join request: POST api/v1/Tenants/default/Namespaces/{namespaceId}/Bulk/Streams/Data/Joins api v1 Tenants default Namespaces {namespaceId} Bulk Streams Data Joins ?joinMode=outer where in the request body, different start indexes and end indexes are specified per stream: [ { \"StreamId\": \"Simple1\", \"Options\": { \"StartIndex\": \"2017-11-23T11:00:00Z\", \"EndIndex\": \"2017-11-23T14:00:00Z\", \"StartBoundaryType\": \"Exact\", \"EndBoundaryType\": \"Exact\", \"Count\": 100, \"Filter\": \"\" } }, { \"StreamId\": \"Simple2\", \"Options\": { \"StartIndex\": \"2017-11-23T15:00:00Z\", \"EndIndex\": \"2017-11-23T17:00:00Z\", \"StartBoundaryType\": \"Exact\", \"EndBoundaryType\": \"Exact\", \"Count\": 100, \"Filter\": \"\" } } ] Only events within the stream\u0027s specified index boundaries are considered for the outer join operation. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ [ { \"Time\": \"2017-11-23T11:00:00Z\", \"State\": 0, \"Measurement\": 10 }, null ], [ { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 20 }, null ], [ { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 30 }, null ], [ null, { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 70 } ], [ null, { \"Time\": \"2017-11-23T17:00:00Z\", \"State\": 0, \"Measurement\": 80 } ] ] Note: Not all the values from streams were included since they are restricted by individual queries for each Stream."
                                                   },
    "V1/SDS/Units_of_Measure_1-0.html":  {
                                             "href":  "V1/SDS/Units_of_Measure_1-0.html",
                                             "title":  "Units of measure",
                                             "keywords":  "Units of measure The Sequential Data Store (SDS) provides a collection of built-in units of measure (Uom). These units of measure can be associated with SdsStreams and SdsTypes to provide unit information for stream data that model measurable quantities. If data has unit information associated with it, SDS supports unit conversions when retrieving data. For more information, see Read data . Since a unit of measurement (such as meter) defines the magnitude of a quantity (such as Length), SDS represents this through two objects: SdsUom and SdsUomQuantity. SdsUom An SdsUom represents a single unit of measure, such as \u0027meter\u0027. The following table shows the required and optional SdsUom fields. Property Type Optionality Description Example Id String Required Unique identifier for the unit of measure. meters per second Abbreviation String Optional Abbreviation for the unit of measure. m/s m s Name String Optional Full name for the unit of measure. Meters per second DisplayName String Optional Friendly display name for the unit of measure. meters per second QuantityId String Required The identifier for the quantity that this unit of measure quantifies. Velocity ConversionFactor Double Required Used for unit conversions. When a value of this unit is multiplied by the ConversionFactor and then incremented by the ConversionOffset, the value in terms of the base unit of the corresponding quantity is returned. 1.0 ConversionOffset Double Required Used for unit conversions. See details for ConversionFactor. 0.0 SdsUomQuantity An SdsUomQuantity represents a single measurable quantity, such as length. The following table shows the required and optional SdsUomQuantity fields. Property Type Optionality Description Example Id String Required Unique identifier for the quantity. Velocity Name String Optional Full name for the quantity. Velocity BaseUom SdsUom Required The base unit of measure for this quantity. All other Uoms measuring this quantity will have ConversionFactors and ConversionOffsets relative to the BaseUom. SdsUom representing \"meters per second\" Dimensions short[] Optional Reserved for internal use. Represents the seven base SI dimensions: Length, Mass, Time, Electric Current, Thermodynamic Temperature, Amount of Substance, and Luminous Density. [1,0,-1,0,0,0,0]"
                                         },
    "V1/SDS/SequentialDataStore_1-0.html":  {
                                                "href":  "V1/SDS/SequentialDataStore_1-0.html",
                                                "title":  "SDS reference",
                                                "keywords":  "SDS reference The Sequential Data Store (SDS) is a cloud-based streaming data storage that is optimized for storing sequential data, usually time-series, but can store anything that is indexed by an ordered sequence. Use SDS to store, retrieve, and analyze data. An SdsType (used interchangeably with type throughout documentation) defines the shape of a single measured event or object. A type gives structure to the data. For example, if you\u0027re measuring three things (longitute, latitude, speed) from a device at the same time, then those three properties need to be included in the type. An SdsStream (used interchangeably with stream throughout documentation) is a collection of ordered events, or a series of events, where each event is an instance of the type. You create and write data to streams using a simple REST (REpresentational State Transfer) API (Application Programming Interface). The streams can be used to store simple or complex data types to suit your application needs. You can define simple or complex indexes to arrange and relate your data. An assortment of methods with customizable behaviors are available to read data and easily obtain needed information. Edge Data Store includes the Sequential Data Store (SDS) REST APIs to read and write data stored locally on the Edge Data Store device. SDS is the same technology used in OCS for storing data, so the usage of the REST APIs is very similar to OCS for reading and writing data. All data from all sources on the Edge Data Store (Modbus TCP, OPC UA, OMF, SDS) can be read using the SDS REST APIs on the local device, in the default tenant and the default namespace. In addition, the default tenant has a diagnostics namespace where diagnostic data are written by the Edge Data Store and installed components that can be read to monitor the health of a running system using the SDS REST APIs. The SDS instance running in EDS is an advanced storage engine that is also used in OCS. While it works very well for storing OMF compatible data in EDS, it can also be used for advanced scenarios where data stored in SDS cannot be converted to OMF. All data egress from EDS to both OCS and the PI System uses OMF, so for streams that will be egressed to the PI System or OCS, it is recommended that they have only a single time-based index. Multiple values are supported in a single stream, but for successful egress there is a limitation of a single time-based index only."
                                            },
    "V1/SDS/Search_1-0.html":  {
                                   "href":  "V1/SDS/Search_1-0.html",
                                   "title":  "Search in SDS",
                                   "keywords":  "Search in SDS Search text and fields across the Sequential Data Store to locate data. Search functionality for SdsStreams, SdsTypes, and SdsStreamViews is exposed through the REST API. The query syntax and the request parameters are the same; only the searchable properties are different. Use the REST API to search SdsStreams, SdsTypes, and SdsStreamViews by specifying the optional query parameter, as shown in the following examples: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams?query={query}\u0026skip={skip}\u0026count={count} api v1 Tenants default Namespaces {namespaceId} Streams?query={query}\u0026skip={skip}\u0026count={count} GET api/v1/Tenants/default/Namespaces/{namespaceId}/Types?query={query}\u0026skip={skip}\u0026count={count} api v1 Tenants default Namespaces {namespaceId} Types?query={query}\u0026skip={skip}\u0026count={count} GET api/v1/Tenants/default/Namespaces/{namespaceId}/StreamViews?query={query}\u0026skip={skip}\u0026count={count} api v1 Tenants default Namespaces {namespaceId} StreamViews?query={query}\u0026skip={skip}\u0026count={count} Search properties for SdsStreams The searchable properties for SdsStreams are shown in the following table. Property Searchable Id Yes TypeId Yes Name Yes Description Yes Indexes No InterpolationMode No ExtrapolationMode No PropertyOverrides No The Stream fields valid for search are identified in the fields table located on the Streams page. Search properties for SdsTypes Searchable properties for SdsTypes are shown in the following table. Property Searchable Id Yes Name Yes Description Yes SdsTypeCode No InterpolationMode No ExtrapolationMode No Properties Yes, with limitations The Type fields valid for search are identified in the fields table located on the Types page. The Properties field is searchable with limitations because each SdsTypeProperty of a given SdsType has its name and Id included in the Properties field. This includes nested SdsTypes of the given SdsType. Therefore, the searching of properties will distinguish SdsTypes by their respective lists of relevant SdsTypeProperty Ids and names. Search properties for SdsStreamViews The searchable properties for SdsStreamViews are shown in the following table. Property Searchable Id Yes Name Yes Description Yes SourceTypeId Yes TargetTypeId Yes Properties Yes, with limitations The Stream View fields valid for search are identified in the fields table located on the Stream Views page. The Properties field is searchable with limitations because SdsStreamViewProperty objects are not searchable. Only the SdsStreamViewProperty\u0027s SdsStreamView is searchable by Id, SourceTypeId, and TargetTypeId, which are used to return the top-level SdsStreamView object. This includes nested SdsStreamViewProperties. Search operation By default, the search operation compares all searchable fields of the search objects to the query parameter specified. When a match is found, the searchable object is included in the search results. For example, if a namespace contains the following streams: streamId Name Description stream1 tempA The temperature from DeviceA stream2 pressureA The pressure from DeviceA stream3 calcA calculation from DeviceA values Using the stream data above, the following table shows the results of a call to get streams with different Query values: QueryString Streams returned temperature Only stream1 returned. calc* Only stream3 returned. DeviceA* All three streams returned. humidity* No streams returned. Additional search parameters Additional search parameters are used to manage large numbers of search results or to focus the results of the search. Additional search parameters are: skip count orderby The skip and count parameters determine which items are returned when a large number of them match the query criteria. count indicates the maximum number of items returned. The maximum value of the count parameter is 1000. skip indicates the number of matched items to skip over before returning matching items. Use the skip parameter when more items match the search criteria than can be returned in a single call. The orderby parameter returns the search result in sorted order and is supported for searching both streams and types. By default, the orderby parameter sorts results in ascending order. Specify desc after the orderby field value to change to descending order. It can be used in conjunction with query , skip , and count parameters. The following examples show various ways to use the orderby parameter. GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams?query=name:pump api v1 Tenants default Namespaces {namespaceId} Streams?query=name:pump name:pressure\u0026orderby=name GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams?query=name:pump api v1 Tenants default Namespaces {namespaceId} Streams?query=name:pump name:pressure\u0026orderby=id asc GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams?query=name:pump api v1 Tenants default Namespaces {namespaceId} Streams?query=name:pump name:pressure\u0026orderby=name desc GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams?query=name:pump api v1 Tenants default Namespaces {namespaceId} Streams?query=name:pump name:pressure\u0026orderby=name desc\u0026skip=10\u0026count=20"
                               },
    "V1/SDS/SDS_Views_1-0.html":  {
                                      "href":  "V1/SDS/SDS_Views_1-0.html",
                                      "title":  "Stream views",
                                      "keywords":  "Stream views SdsStreamViews (or stream views) provide flexibility in the use of SdsTypes. While you cannot actually change the properties of SdsTypes themselves, use the stream views feature to create a view of a selected SdsStream that appears as if you had changed the SdsType on which it is based. Create a stream view by choosing a source and target type then a set of mappings between properties of those two types. Using a stream view to leverage existing SdsType properties is preferable to creating a new SdsType, because the SdsStream that is based on the SdsType continues to function with its previously archived stream data intact. See the impact of the stream view on a stream either in an ad hoc manner through a GET method or by assigning the stream view to a stream with a PUT method. An SdsStreamView provides a way to map stream data requests from one data type to another. You can apply a stream view to any read or GET operation. SdsStreamView is used to specify the mapping between source and target types. SDS attempts to map properties from the source to the destination. When the mapping is straightforward, such as when the properties are in the same position and of the same data type, or when the properties have the same name, SDS will map the properties automatically. When SDS is unable to determine how to map a source property, the property is removed. If SDS encounters a target property that it cannot map to, the property is added and configured with a default value. To map a property that SDS cannot map automatically, define an SdsStreamViewProperty and add it to the SdsStreamView???s Properties collection. The following table shows the SdsStreamView fields. Fields that are not included are reserved for internal SDS use. For more information on search limitations, see Search in SDS . Property Type Optionality Searchable Details Id String Required Yes Identifier for referencing the stream view. Name String Optional Yes Friendly name. Description String Optional Yes Description text. SourceTypeId String Required Yes Identifier of the SdsType of the SdsStream. TargetTypeId String Required Yes Identifier of the SdsType to convert events to. Properties IList\u003cSdsStreamViewProperty\u003e Optional Yes, with limitations Property level mapping. Rules for the stream view identifier (SdsStreamView.Id) The type identifier, SdsStreamView.ID, has the following requirements: Is not case sensitive. Can contain spaces. Cannot contain forward slash (\"/\"). (\" \"). Contains a maximum of 100 characters. Properties /   SdsStreamViewProperty The SdsStreamView Properties collection provides detailed instructions for mapping of event properties. Each SdsStreamViewProperty in the properties collection defines the mapping of an event???s property. SdsStreamView properties are required only when property mapping is not straightforward. Additionally, if you do not want a type property mapped, it is not necessary to create an SdsStreamView property for it. The following table shows the required and optional SdsStreamViewProperty fields. Property Type Optionality Details SourceId String Required Identifier of the SdsTypeProperty from the source SdsType Properties list. TargetId String Required Identifier of the SdsTypeProperty from the target SdsType Properties list. SdsStreamView SdsStreamView Optional Additional mapping instructions for derived types. The SdsStreamView field supports nested properties. SdsStreamViewMap When an SdsStreamView is added, SDS defines a plan mappingand stores it as an SdsStreamViewMap. The SdsStreamViewMap provides a detailed property-by-property definition of the mapping. The following table shows the SdsStreamViewMap fields. The SdsStreamViewMap cannot be written to SDS, it can only be retrieved from SDS, so required and optional have no meaning. Property Type Optionality Details SourceTypeId String Required Identifier of the SdsType of the SdsStream. TargetTypeId String Required Identifier of the SdsType to convert events to. Properties IList\u003cSdsStreamViewMapProperty\u003e Optional Property level mapping. Properties /   SdsStreamViewMapProperty The SdsStreamViewMapProperty is similar an SdsStreamViewProperty but adds a mode detailing one or more actions taken on the property. The following table shows the SdsStreamViewMapProperty fields. The SdsStreamViewMap cannot be written to SDS; it can only be retrieved from SDS, so required and optional have no meaning. Property Type Details SourceTypeId String Identifier of the SdsType of the SdsStream. TargetTypeId String Identifier of the SdsType to convert events to. Mode SdsStreamViewMode Aggregate of actions applied to the properties. SdsStreamViewModes are combined via binary arithmetic. SdsStreamViewMap SdsStreamViewMap Mapping for derived types. The available SdsStreamViewModes are shown in the following table. Name Value Description None 0x0000 No action. FieldAdd 0x0001 Add a property matching the specified SdsTypeProperty. FieldRemove 0x0002 Remove the property matching the specified SdsTypeProperty. FieldRename 0x0004 Rename the property matching the source SdsTypeProperty to the target SdsTypeProperty. FieldMove 0x0008 Move the property from the location in the source to the location in the target. FieldConversion 0x0016 Converts the source property to the target type. InvalidFieldConversion 0x0032 Cannot perform the specified mapping. Changing stream type Stream views can be used to change the type defining a stream. You cannot modify the SdsType; types are immutable. But you can map a stream from its current type to a new type. To update a stream\u0027s type, define an SdsStreamView and PUT the stream view to the following: PUT api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Type?streamViewId={streamViewId} api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Type?streamViewId={streamViewId} For details, see Update Stream Type . Working with SdsStreamViews When working with stream views, either invoke HTTP directly or use some of the sample code. Both Python and JavaScript samples have SdsStreamView definitions. The JSON for a simple mapping between a source type with identifier Sample and a target type with identifier Sample1 would appear as follows. { \"Id\":\"StreamView\", \"Name\":\"StreamView\", \"SourceTypeId\":\"Simple\", \"TargetTypeId\":\"Simple1\" } The SdsStreamViewMap would appear as follows. { \"SourceTypeId\":\"Simple\", \"TargetTypeId\":\"Simple1\", \"Properties\":[ { \"SourceId\":\"Time\", \"TargetId\":\"Time\" }, { \"SourceId\":\"State\", \"TargetId\":\"State\" }, { \"SourceId\":\"Measurement\", \"TargetId\":\"Value\", \"Mode\":4 } ] }"
                                  },
    "V1/OpcUa/OPCUADataSelectionConfiguration_1-0.html":  {
                                                              "href":  "V1/OpcUa/OPCUADataSelectionConfiguration_1-0.html",
                                                              "title":  "Data selection configuration",
                                                              "keywords":  "Data selection configuration After configuring the data source, create a data selection configuration file to specify the data for the OPC UA EDS adapter instance to collect from the data source. When you add a data source, the OPC UA EDS adapter browses the OPC UA server address space and exports the available OPC UA variables into a JSON file for data selection. If RootNodeIds are specified in the data source configuration, only those nodeIds are browsed. Data is collected automatically based upon user demands. OPC UA data from OPC UA variables is read through subscriptions (unsolicited reads). You can either have the data selection configuration file generated for you or you can create it manually yourself. Configure OPC UA data selection using a generated file A default OPC UA data selection file will be created if there is no OPC UA data selection configuration, but a valid OPC UA data source exists. Note: To avoid resource-intensive browse operations, OSIsoft recommends that you manually create a data selection file instead of generating the default data selection file. Complete the following steps to generate the default data selection file and use it to configure data selection: Add an OPC UA EDS adapter instance with a unique ComponentId either manually or during the EDS installation. For details, see Edge Data Store configuration . Configure a valid OPC UA data source. For details, see Data source configuration . Once you complete these steps, a default OPC UA data selection configuration file is generated in the configuration directory with the file name based on the ComponentId. The following are example locations of the file created using the adapter instance created during installation, which is OpcUa1: Windows: %programdata%\\OSIsoft\\EdgeDataStore\\Configuration\\OpcUa1_DataSelection.json Linux: /usr/share/OSIsoft/EdgeDataStore/Configuration/OpcUa1_DataSelection.json  usr share OSIsoft EdgeDataStore Configuration OpcUa1_DataSelection.json Copy the file to a different directory and open it using any text editor. It will look similar to the following example: [ { \"Selected\": false, \"Name\": \"Cold Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.ColdSideInletTemperature\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Cold Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.ColdSideOutletTemperature\", \"StreamId\": null } ] To ingress a stream to Edge Data Store, change the value of the Selected key from false to true . All streams in the auto generated data selection file are initially set to false . Save the the file. Run the following curl script from the directory where the file is located, updating the file name and destination in the script if needed: curl -d \"@OpcUa1_DataSelection.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/OpcUa1/Dataselection http:  localhost:5590 api v1 configuration OpcUa1 Dataselection Configure OPC UA data selection by manually creating the file Note: OPC UA data selection configurations cannot be modified manually. Use the REST endpoints to add or edit the configuration. Complete the following steps to configure the OPC UA data selection: Using any text editor, create a file that contains an OPC UA data selection in JSON form. For content structure, see OPC UA data selection example . Update the parameters as needed. For a table of all available parameters, see Parameters for OPC UA data selection . Save the file to the device with Edge Data Store installed with the name DataSelection.config.json . Use any tool capable of making HTTP requests to execute a POST command with the contents of that file to the following endpoint: http://localhost:\u003cport_number\u003e/api/v1/configuration/\u003cEDS http:  localhost:\u003cport_number\u003e api v1 configuration \u003cEDS adapterId\u003e/DataSelection/ adapterId\u003e DataSelection  The following example shows the HTTPS request using curl, which must be run from the same directory where the file is located, and uses the adapter instance created during installation, which is OpcUa1: curl -d \"@DataSelection.config.json\" -H \"Content-Type: application/json\" application json\" \"http://localhost:5590/api/v1/configuration/OpcUa1/DataSelection\" \"http:  localhost:5590 api v1 configuration OpcUa1 DataSelection\" Parameters for OPC UA data selection The following parameters can be used to configure OPC UA data selection: Parameter Required Type Nullable Description Selected Optional Boolean No Use this field to select a measurement to be collected. To select an item, set to true. To remove an item and not collect its data, leave the field empty or set to false. If not configured, the default value is false. Name Required string Yes The friendly name of the data item collected from the data source. The field is populated with the DisplayName value from the OPC UA server when the data selection configuration is populated by the adapter. NodeId Required string Yes The NodeId of the variable. StreamID Optional string Yes The custom stream ID used to create the streams. If not specified, the OPC UA EDS adapter will generate a default stream ID based on the measurement configuration. A properly configured custom stream ID follows these rules: Is not case-sensitive. Can contain spaces. Cannot start with two underscores (\"__\"). Can contain a maximum of 100 characters. Cannot use the following characters: /   : ? # [ ] @ ! $ \u0026 \u0027 ( ) \\ * + , ; = % \u003c \u003e | Cannot start or end with a period. Cannot contain consecutive periods. Cannot consist of only periods. OPC UA data selection example The following is an example of valid OPC UA data selection configuration: [ { \"Selected\": true, \"Name\": \"Random1\", \"NodeId\": \"ns=5;s=Random1\", \"StreamId\": \"CustomStreamName\" }, { \"Selected\": false, \"Name\": \"Sawtooth1\", \"NodeId\": \"ns=5;s=Sawtooth1\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Sinusoid1\", \"NodeId\": \"ns=5;s=Sinusoid1\", \"StreamId\": null } ]"
                                                          },
    "V1/OMF/OMF_Messages_1-0.html":  {
                                         "href":  "V1/OMF/OMF_Messages_1-0.html",
                                         "title":  "OMF messages",
                                         "keywords":  "OMF messages The OSIsoft Message Format (OMF) specification is generic in that it does not specify a particular back-end system. This topic is a companion to the OMF specification which describes how OMF is interpreted by Edge Data Store. When creating an OMF application for EDS, you also need to consider the final destination of the data and review the associated documentation to determine what is supported. Headers Message headers allow you to pass additional information with the message. The message header is where you specify the action for the message, such as CREATE. For a description of each of the headers, see the OMF specification . The omfversion header must match the version of the OMF spec used to construct the message. EDS suuports versions 1.0 and 1.1 of the OMF specification. Message types OMF message types fall into three categories: Type, Container, and Data, which are described below. Each message type creates a different type of data and contains keywords that define characteristics of the data. Most of the message types are used to create the structure of the data and give it meaning. Data messages contain time-series data for which the PI System is known. The message types and the data they create are described in detail in this section. For details about the keywords supported by OCS, see the OCS topic, Use OSIsoft Message Format with OSIsoft Cloud Service . All messages should only be sent from the OMF application one time, but resending the same definition again does not cause an error. Type messages An OMF type message describes the format of the data to be stored. A type message is interpreted by OSIsoft Cloud Services as an SdsType in the Sequential Data Store. Because SdsTypes are immutable, update operations are not supported. Create an OMF type The first step in OMF data ingress is to create an OMF type that describes the format of the data to be stored. In this example, the data to be written is a timestamp and a numeric value. Create an OMF JSON file that defines the type as follows: [{ \"id\": \"MyCustomType\", \"classification\": \"dynamic\", \"type\": \"object\", \"properties\": { \"Timestamp\": { \"type\": \"string\", \"format\": \"date-time\", \"isindex\": true }, \"Value\": { \"type\": \"number\", \"format\": \"float32\" } } }] The value is indexed by a timestamp, and the numeric value that will be stored is a 32-bit floating point value. To create the OMF type in Edge Storage, store the JSON file with the name OmfCreateType.json on the local device. Run the following curl command: curl -d \"@OmfCreateType.json\" -H \"Content-Type: application/json\" application json\" -H \"producertoken: x \" -H \"omfversion: 1.1\" -H \"action: create\" -H \"messageformat: json\" -H \"messagetype: type\" -X POST http://localhost:5590/api/v1/tenants/default/namespaces/default/omf/ http:  localhost:5590 api v1 tenants default namespaces default omf  When this command completes successfully, an OMF type with the same name is created on the server. Any number of containers can be created from the type, as long as they use a timestamp as an index and have a 32-bit floating point value. The create type message needs to be sent before container and data messages. Container messages An OMF container message uses an OMF type as a template to create a way to collect and group data events. A container message is interpreted as an SdsStream in the Sequential Data Store. Create an OMF container The next step in writing OMF data is to create an OMF container. Create an OMF JSON file that defines the container as follows: [{ \"id\": \"MyCustomContainer\", \"typeid\": \"MyCustomType\" }] This container references the OMF type that was created earlier, and an error will occur if the type does not exist when the container is created. To create the OMF container in Edge Storage, store the JSON file with the name OmfCreateContainer.json on the local device. To create the SDS stream to store data defined by the type, run the following curl command: curl -d \"@OmfCreateContainer.json\" -H \"Content-Type: application/json\" application json\" -H \"producertoken: x \" -H \"omfversion: 1.1\" -H \"action: create\" -H \"messageformat: json\" -H \"messagetype: container\" -X POST http://localhost:5590/api/v1/tenants/default/namespaces/default/omf/ http:  localhost:5590 api v1 tenants default namespaces default omf  Data messages An OMF data message sends actual data events, like time-series data, to be stored. A data message is mapped to generic SDS values in the Sequential Data Store. Write data events to the OMF container Once a type and container are defined, complete the following steps to write data to the container: Create an OMF JSON file to define data events to be stored in the SdsStreams created in the previous steps. For best performance, batch OMF messages together, as in the following example: [{ \"containerid\": \"MyCustomContainer\", \"values\": [{ \"Timestamp\": \"2019-07-16T15:18:24.9870136Z\", \"Value\": 12345.6789 }, { \"Timestamp\": \"2019-07-16T15:18:25.9870136Z\", \"Value\": 12346.6789 } ] }] To write the data to EDS, store the JSON file with the name OmfCreateDataEvents.json on the local device. To write data values to the SDS stream, run the following curl command: curl -d \"@OmfCreateDataEvents.json\" -H \"Content-Type: application/json\" application json\" -H \"producertoken: x \" -H \"omfversion: 1.1\" -H \"action: create\" -H \"messageformat: json\" -H \"messagetype: data\" -X POST http://localhost:5590/api/v1/tenants/default/namespaces/default/omf/ http:  localhost:5590 api v1 tenants default namespaces default omf "
                                     },
    "V1/OMF/OMFOverview_1-0.html":  {
                                        "href":  "V1/OMF/OMFOverview_1-0.html",
                                        "title":  "OSIsoft Message Format",
                                        "keywords":  "OSIsoft Message Format Create a custom application using OSIsoft Message Format (OMF) to send data to EDS from sources that cannot use Modbus or OPC UA protocols. The following diagram depicts the data flow from an OMF data collection application into EDS: The OMF application collects data from a data source and sends it to the Edge Data Store endpoint. The EDS endpoint sends the data to the storage component where it is held until it can be egressed to permanent storage in PI Server or OSIsoft Cloud Services. The OMF application must run on the same device as Edge Data Store and no authentication is needed. OMF endpoint The route to the OMF endpoint to the Edge Storage component is shown below. Replace \u003cport_number\u003e with the port configured for your EDS system: Method: POST Endpoint: http://localhost:\u003cport_number\u003e/api/v1/tenants/default/namespaces/default/omf http:  localhost:\u003cport_number\u003e api v1 tenants default namespaces default omf This endpoint can only be accessed locally, so the OMF application must run on the same device as EDS. Supported functionality Edge Data Store supports OMF versions 1.0 and OMF version 1.1 for data ingress. For details on the difference versions of OMF, see the OMF specification, available here: OSIsoft Message Format . The OMF ingress functionality is the same technology that is used in OSIsoft Cloud Services (OCS) and writing an OMF application for EDS is very similar to writing an OMF application for OCS. The OMF endpoint for the Edge Storage component only supports the create action; it does not support the update action. If a create data message is sent with the same time index, the values will be replaced at that index value. Dynamic messages are supported, but static messages (usually used for creating PI AF assets) are not supported by EDS. Any static OMF messages sent to the EDS OMF REST endpoint will be ignored. For efficiency reasons, OSIsoft recommends batching OMF messages that are sent to the EDS endpoint. Sending single messages or a small number of messages to the OMF endpoint can be successful, but it is inefficient. When a single message or a small number of messages are sent at a time, the HTTP overhead of creating the request and processing the response on a small device requires more system resources than the processing of the OMF message itself. While a large number of OMF messages per second can be processed by EDS platforms, OSIsoft recommends keeping the number of HTTP calls per second low to increase efficiency. HTTPS status codes Edge Data Store returns the following status codes to provide feedback when an OMF ingress message is received. If an error occurs because of an issue with the server (408 Request Timeout or 503 Service Unavailable), the application can retry the request. It is up to the OMF application developer to determine how many times to retry a request. Status Code Description Common Causes 204 No Content The OMF message was successfully processed, but there is no additional information to return. 400 Bad Request The OMF message was malformed or not understood. The client should not retry sending the message without modifications. The body or headers of the OMF message were incorrect. Verify the validity of the request contents and headers. 408 Request Timeout The server did not reply to a request within the time that the client was prepared to wait. The client may repeat the request without modifications at any later time. Server busy or over-loaded with other requests. 409 Conflict The request could not be completed due to a conflict with the current state of the server. The information in the OMF message contradicts the data currently stored in EDS. 413 Payload Too Large Payload size exceeds OMF body size limit. The body of an OMF message has a maximum size of 192KB. A request with a body size exceeding the maximum will be rejected with this error code. 500 Internal Server Error The server encountered an unexpected condition. Review EDS logs for more insight. 503 Service Unavailable The server is currently unavailable, retry later. The EDS server is performing maintenance on one or more streams."
                                    },
    "V1/Installation/Uninstall Edge Data Store_1-0.html":  {
                                                               "href":  "V1/Installation/Uninstall Edge Data Store_1-0.html",
                                                               "title":  "Uninstall Edge Data Store",
                                                               "keywords":  "Uninstall Edge Data Store Uninstall Edge Data Store to remove the program files from a device. The data files, configuration files, and log files can also be removed. Uninstall from Windows Perform the following steps to remove EDS from a Windows device: To remove the EDS program files from a Windows device, use the Windows Control Panel uninstall application process. The configuration, data, and log files are not removed by the uninstall process. Optional: To remove all data stored in the Edge Storage component, all configuration files, and all log files, delete the directory C:\\ProgramData\\OSIsoft\\EdgeDataStore . Uninstall from Linux Perform the following steps to remove EDS from a Linux device: To remove EDS software from a Linux device, open a terminal window and run the following command: sudo apt remove osisoft.edgedatastore The configuration, data, and log files are not removed by the uninstall process. Optional: To remove all data stored in the Edge Storage component, all configuration files, and all log files, delete the directory /usr/share/OSIsoft/EdgeDataStore/  usr share OSIsoft EdgeDataStore  . Alternatively, run the following command: sudo rm -r /usr/share/OSIsoft/EdgeDataStore/  usr share OSIsoft EdgeDataStore "
                                                           },
    "V1/Edge_Data_Store_1-0.html":  {
                                        "href":  "V1/Edge_Data_Store_1-0.html",
                                        "title":  "Edge Data Store",
                                        "keywords":  "Edge Data Store Edge Data Store (EDS) is a lightweight data collection and storage application designed to capture data at the edge of networks for historical storage and analysis. It runs on small, rugged devices or embedded in existing industrial hardware, and is designed to be resilient and require minimal installation and administration. While not a replacement for a PI System or OSIsoft Cloud Services (OCS), EDS augments the PI System and OCS by collecting and storing data in situations where deploying a full system is impractical. The following diagram shows conceptually how EDS captures data and sends to permanent storage: EDS collects data using any of the following methods: Built-in OPC UA connectivity Built-in Modbus TCP connectivity Custom application using OSIsoft Message Format (OMF) Custom application using REST API Once collected, the data is stored locally in configurable data storage within EDS, until it can be sent to permanent storage in a PI System or in OSIsoft Cloud Services through periodic egress. The data can also be read from local storage by custom applications using REST APIs. Edge Data Store architecture EDS runs on both Linux and Windows platforms and is comprised of separate components that each perform a specific function within EDS. The following diagram shows Edge Data Store architecture with all of its components and how the data flow through those components: EDS components are shown in grey within the Edge Data Store in the diagram: Modbus TCP EDS adapter ??? Collects data from Modbus TCP devices and writes it to data storage OPC UA EDS adapter ??? Collects data from OPC UA devices and writes it to data storage Data Storage ??? Stores data locally until it can be egressed Data egress ??? Sends data from storage to PI Server or OSIsoft Cloud Services Health ??? Records health information of components and sends it to PI Server or OSIsoft Cloud Services Blue boxes in the diagram show ways to interact with EDS from the local device: OMF REST ??? Use OSIsoft Message Format to write data to the data storage component programmatically SDS REST APIs ??? Use SDS REST APIs to read data from and write data to the data storage component programmatically Configuration ??? Use REST or the EdgeCmd tool to configure EDS as a whole or each component individually and to view the current configuration EDS requires an endpoint to connect to REST APIs on the local device, which is shown outlined in blue in the diagram. By default, the endpoint uses port 5590; however, it can be configured to use another port. Orange arrows show data flowing into EDS and blue arrows show data flowing out of EDS. For detailed information about configuring each component of EDS, see Configuration"
                                    },
    "README.html":  {
                        "href":  "README.html",
                        "title":  "Edge-Data-Store-Docs",
                        "keywords":  "Edge-Data-Store-Docs Configuration tools Edge Data Store and adapters can be configured with either the EdgeCmd utility, OSIsoft\u0027s proprietary tool for configuring the Edge Data Store and adapters, or a commonly-used REST tool. EdgeCmd utility The EdgeCmd utility enables EDS and adapter configuration on both Linux and Windows operating systems. For more information on using the EdgeCmd utility, see EdgeCmd utility . REST tools The following tools can be used to make REST calls. curl curl is a command line tool used to make HTTP calls and is supported on both Windows and Linux operating systems. curl is easily scripted using Bash or PowerShell on either Linux or Windows, and can be used to perform EDS administrative and programming tasks. curl commands are used in configuration and management examples throughout this document. Postman Postman is an effective REST tool for systems with GUI components. Edge Data Store is supported on platforms that lack this capability. It is particularly useful for learning more about Edge Data Store REST APIs. C#, Python, Go Edge Data Store is designed to use platform-independent programming, and any modern programming language can be used to make REST calls to administer and write programs for Edge Data Store. Since the administrative and programming interfaces use REST, you can write applications that both manage Edge Data Store and read and write data. For example, an application can access the Diagnostics namespace locally to monitor and act upon the local system state. System Tools Use Windows tools like PuTTY and WinSCP to facilitate working across platforms, such as to copy files and remotely access Linux command lines."
                    },
    "zArchive/Schemas/System_HealthEndpoints_schema.html":  {
                                                                "href":  "zArchive/Schemas/System_HealthEndpoints_schema.html",
                                                                "title":  "Sample OMF health endpoint configuration",
                                                                "keywords":  "Sample OMF health endpoint configuration The OMF health endpoint configuration schema specifies how to formally describe the OMF health endpoint parameters. [{ \"endpoint\": \"https://\u003cpi \"https:  \u003cpi web api server\u003e/piwebapi/omf/\", server\u003e piwebapi omf \", \"UserName\": \"\u003cusername\u003e\", \"Password\": \"\u003cpassword\u003e\", \"buffering\": 0, \"maxBufferSizeMB\": 0 }, { \"Endpoint\": \"https://\u003cOCS \"https:  \u003cOCS OMF endpoint\u003e\", \"ClientId\": \"\u003cclientid\u003e\", \"ClientSecret\": \"\u003cclientsecret\u003e\", \"buffering\": 0, \"maxBufferSizeMB\": 0 } ] OMF health endpoint configuration properties Property Type Required Nullable Defined by Buffering reference #/definitions/BufferType # definitions BufferType Optional No OmfHealthEndpointConfiguration (this schema) ClientId string Optional Yes OmfHealthEndpointConfiguration (this schema) ClientSecret string Optional Yes OmfHealthEndpointConfiguration (this schema) Endpoint string Optional Yes OmfHealthEndpointConfiguration (this schema) Id string Optional Yes OmfHealthEndpointConfiguration (this schema) MaxBufferSizeMB integer Optional No OmfHealthEndpointConfiguration (this schema) Password string Optional Yes OmfHealthEndpointConfiguration (this schema) UserName string Optional Yes OmfHealthEndpointConfiguration (this schema) ValidateEndpointCertificate boolean Optional No OmfHealthEndpointConfiguration (this schema) Note: All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required Buffering reference #/definitions/BufferType # definitions BufferType Optional ClientId string Optional ClientSecret string Optional Endpoint string Optional Id string Optional MaxBufferSizeMB integer Optional Password string Optional UserName string Optional ValidateEndpointCertificate boolean Optional"
                                                            },
    "zArchive/Schemas/System_Components_schema.html":  {
                                                           "href":  "zArchive/Schemas/System_Components_schema.html",
                                                           "title":  "Sample Edge Data Store components configuration",
                                                           "keywords":  "Sample Edge Data Store components configuration [ { \"ComponentId\": \"OpcUa1\", \"ComponentType\": \"OpcUa\" }, { \"ComponentId\": \"Modbus1\", \"ComponentType\": \"Modbus\" }, { \"ComponentId\": \"Storage\", \"ComponentType\": \"EDS.Component\" } ] Edge Data Store components configuration properties Property Type Required Nullable Group ComponentId string Optional Yes #/definitions/EdgeComponentConfig # definitions EdgeComponentConfig ComponentType string Optional Yes #/definitions/EdgeComponentConfig # definitions EdgeComponentConfig Edge Data Store configuration properties Property Type Required Nullable Defined by ComponentConfigurations reference #/definitions/EdgeComponentConfig # definitions EdgeComponentConfig Optional Yes EdgeDataStoreConfig (this schema) Note: All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required ComponentConfigurations reference #/definitions/EdgeComponentConfig # definitions EdgeComponentConfig Optional"
                                                       },
    "V1/Support/Edge Data Store support_1-0.html":  {
                                                        "href":  "V1/Support/Edge Data Store support_1-0.html",
                                                        "title":  "Edge Data Store support",
                                                        "keywords":  "Edge Data Store support Documentation feedback If you have questions, comments, or other feedback about the Edge Data Store documentation, send an email to documentation@osisoft.com . Technical support and other resources For technical assistance, contact OSIsoft Technical Support at +1 510-297-5828 or through the OSIsoft Customer Portal Contact Us page . The Contact Us page offers additional contact options for customers outside of the United States. When you contact OSIsoft Technical Support, be prepared to provide this information: Product name, version, and build numbers Details about your computer platform (CPU type, operating system, and version number) Time that the difficulty started Log files at that time Details of any environment changes prior to the start of the issue Summary of the issue, including any relevant log files during the time the issue occurred To ask questions of others who use OSIsoft software, join the OSIsoft user community, PI Square . Members of the community can request advice and share ideas about the PI System. The PI Developers Club space within PI Square offers resources to help you with the programming and integration of OSIsoft products."
                                                    },
    "V1/Security/SecurityOverview_1-0.html":  {
                                                  "href":  "V1/Security/SecurityOverview_1-0.html",
                                                  "title":  "Security",
                                                  "keywords":  "Security Consider the following when determining Edge Data Store security practices. REST APIs EDS supports REST APIs for configuration, data reading (through SDS), and data writing (through OMF and SDS). EDS provides only localhost access to REST APIs, which means any code that reads or writes to the REST APIs must reside on the computer or device on which EDS is running. REST access is through HTTP. The default port is 5590. The port number can be changed during installation, or during configuration after installation. URLs must be of the form http:// http:   localhost:{port}/ localhost:{port}  or http:// http:   127.0.0.1:{port}/. 127.0.0.1:{port} . Note: Do not use the host\u0027s name or IP Address in the URL. Note: Docker users must use the \"host\" networking mode for the container. For information about using EDS with Docker, see Install Edge Data Store using Docker . Data egress Use HTTPS to write data to OSIsoft Cloud Services or OSIsoft PI Web API; writing to either of these destinations is not limited to the local machine. EDS adapters The Modbus TCP EDS adapter and the OPC UA EDS adapter access remote data sources through binary protocols. Secure storage Sensitive information such as passwords and client secrets are saved in configuration files in an encrypted form. Only the EDS runtime can properly store and retrieve these protected data items. Note: Do not manually edit configuration files. Altering encrypted values will cause failures. Unencrypted values for sensitive information are only available when you provide them to the system through the REST API, such as with initial configuration or update. From that point forward, the unencrypted values are not available, either in the configuration files or through the REST API. The REST API will only return a placeholder string for such values. Use caution when submitting sensitive data items. For example, remove any temporary file containing unencrypted credentials used to submit configuration to the REST API from the system. Service and file system security The installer creates a specific user account that the Edge Data Store service runs under. This account is only used for running the service. For example, it cannot be used for interactive sessions. Do not configure this service account; modifying the service configuration in this respect could cause system failure. The EDS binary files, configuration files, and data files are configured by the installer and runtime to allow appropriate access by the service account. Do not modify the permission and ownership assignments for these files as failures could occur. Consider a third party encryption-at-rest technique for your data storage. This security measure protects your data in the case the device storage is physically stolen, lost, or otherwise falls into the wrong hands. On Linux, EDS is compatible with whole disk encryption systems such as LUKS or partial encryption systems such as eCryptfs . On Windows, EDS is compatible with whole disk encryption solutions such as BitLocker and Windows EFS ."
                                              },
    "V1/Overview/VisualizationQuickStart_1-0.html":  {
                                                         "href":  "V1/Overview/VisualizationQuickStart_1-0.html",
                                                         "title":  "Edge Data Store visualization quick start",
                                                         "keywords":  "Edge Data Store visualization quick start This topic provides a quick start for displaying data from the EDS storage component on the local device where Edge Data Store is installed. The following example should run on any device supported by Edge Data Store, and iterates through all streams in the default namespace, continually displaying the latest values to the screen. using System; using System.Collections.Generic; using System.Net.Http; using Newtonsoft.Json; namespace EdgeDataScroller { class EdgeStream { public string Id { get; set; } } class DataScroller { static HttpClient _client = new HttpClient(); private static Dictionary\u003cstring, Dictionary\u003cstring, object\u003e\u003e GetDataForNamespace(string ns) { Dictionary\u003cstring, Dictionary\u003cstring, object\u003e\u003e outputs = new Dictionary\u003cstring, Dictionary\u003cstring, object\u003e\u003e(); string uri = string.Format(\"http://localhost:5590/api/v1/tenants/default/namespaces/{0}/streams\", string.Format(\"http:  localhost:5590 api v1 tenants default namespaces {0} streams\", ns); string json = _client.GetStringAsync(uri).Result; List\u003cEdgeStream\u003e streams = JsonConvert.DeserializeObject\u003cList\u003cEdgeStream\u003e\u003e(json); foreach (var stream in streams) { string lastValueUri = string.Format(\"http://localhost:5590/api/v1/tenants/default/namespaces/{0}/streams/{1}/Data/Last\", string.Format(\"http:  localhost:5590 api v1 tenants default namespaces {0} streams {1} Data Last\", ns, stream.Id.Trim()); string lastValueJson = _client.GetStringAsync(lastValueUri).Result; Dictionary\u003cstring, object\u003e values = JsonConvert.DeserializeObject\u003cDictionary\u003cstring, object\u003e\u003e(lastValueJson); outputs.Add(stream.Id.Trim(), values); } return outputs; } static void DisplayData(List\u003cstring\u003e namespaces, TimeSpan interval) { Dictionary\u003cstring, Dictionary\u003cstring, Dictionary\u003cstring, object\u003e\u003e\u003e outputs = new Dictionary\u003cstring, Dictionary\u003cstring, Dictionary\u003cstring, object\u003e\u003e\u003e(); Console.WriteLine(\"Data Displayed at \" + DateTime.UtcNow.ToString(\"o\")); foreach (string ns in namespaces) { outputs.Add(ns, GetDataForNamespace(ns)); } foreach (string ns in outputs.Keys) { foreach (string stream in outputs[ns].Keys) { if (null == outputs[ns][stream]) { Console.WriteLine(\"No values for \" + stream); continue; } foreach (string field in outputs[ns][stream].Keys) { object obj = outputs[ns][stream][field]; string value = obj.ToString(); if (obj is DateTime) { value = ((DateTime)obj).ToString(\"o\"); } Console.WriteLine($\"{ns}.{stream}.{field} = {value}\"); } } Console.WriteLine(\"****\"); } Console.WriteLine(string.Empty); System.Threading.Thread.Sleep(interval); } static void Main(string[] args) { List\u003cstring\u003e namespaces = new List\u003cstring\u003e(); namespaces.Add(\"default\"); TimeSpan interval = TimeSpan.FromSeconds(5.0); if (null != args \u0026\u0026 args.Length \u003e 0) { string choice = args[0].Trim().ToLowerInvariant(); if (choice == \"all\") { namespaces.Add(\"diagnostics\"); } if (choice == \"diagnostics\") { namespaces.Clear(); namespaces.Add(\"diagnostics\"); } if (args.Length \u003e 1) { string newInterval = args[1].Trim(); double newValue = -1.0; if (double.TryParse(newInterval, out newValue)) { interval = TimeSpan.FromSeconds(newValue); } } } while (true) DisplayData(namespaces, interval); } } }"
                                                     },
    "V1/Overview/Quick start guides_1-0.html":  {
                                                    "href":  "V1/Overview/Quick start guides_1-0.html",
                                                    "title":  "Quick start guides",
                                                    "keywords":  "Quick start guides The quick start guides in this section provide basic instructions to get started with Edge Data Store components and utilities. Refer to the respective configuration sections for detailed instructions on each EDS component or utility. The examples in each quick start guide use curl, a commonly available tool on both Windows and Linux. You can use the same operations with any programming language or tool that supports making REST calls or configure EDS components with the EdgeCmd utility. If available on your device, use a browser to complete data retrieval steps (GET commands) to validate successful configurations. All quick start guide examples assume EDS has been installed and is accessible through a REST API using the default installed port (5590)."
                                                },
    "V1/Overview/EdgeSystemOverview_1-0.html":  {
                                                    "href":  "V1/Overview/EdgeSystemOverview_1-0.html",
                                                    "title":  "Edge Data Store",
                                                    "keywords":  "Edge Data Store Edge Data Store (EDS) is an embedded data server that runs on Linux and Windows. EDS provides a lightweight data collection and storage application designed to enable the capturing of data for historical storage and analysis at the edge of networks. A storage component based on sequential data storage technology is provided. You can configure and administer EDS through REST programming, configuration, administrative interfaces, and the EdgeCmd command line tool. EDS complements existing OSIsoft products, and is designed for small devices. You can install and run it on 64-bit Intel/AMD Intel AMD compatible and 32-bit ARM v7/v8 v7 v8 compatible chips. While not a replacement for a PI System, EDS augments the PI System by providing historical data access in situations where deploying a full PI System is impractical. EDS provides native capability, via its Egress functionality, to send data to a PI System or to OSIsoft Cloud Services for long term historical storage and analysis. EDS provides the following capabilities: OMF data ingress Edge connectivity through Modbus TCP and OPC UA Configurable data storage Data egress to PI Web API and OCS REST API to enable custom applications for visualization and analytics on Edge Data Store on either Linux, Windows, or both in a variety of programming languages Edge Data Store architecture The following diagram depicts the relationships of architectural components to one another in the Edge Data Store: Edge Data Store data flow Edge Data Store can egress data to both PI Data Archive and OSIsoft Cloud Services. For more information, see PI egress quick start and OCS egress quick start . The following diagram depicts the flow of data in Edge Data Store: Edge Data Store components The following diagram depicts the relationship of key functions to relevant components of the Edge Data Store: Data ingress to Edge Data Store Edge Data Store can ingress data in a number of ways. There are two built-in adapters: EDS Modbus TCP and EDS OPC UA . Data can also be ingressed using OSIsoft Message Format (OMF) and the Sequential Data Store SDS REST APIs. The following diagram depicts an OMF data ingress scenario in the Edge Data Store: During installation of Edge Data Store, you can choose to install either an EDS Modbus TCP adapter or an EDS OPC UA adapter, or both. The EDS Modbus and EDS OPC UA adapters require configuration of data source and data selection before they can collect data in Edge Data Store. You can use OMF data ingress once Edge Data Store is installed, with no further configuration steps. Edge Data Store is composed of components, and is designed to allow additional EDS adapters at a later point. Local data read and write access You can access all data in Edge Data Store by using the Sequential Data Store REST API. You can use this data for local applications that perform analytics or visualization. For more information, see SDS quick start . Example EDS visualization application The following diagram depicts the flow of data from a customer visualization application into Edge Data Store, via either OMF or SDS REST calls: Example EDS analytics application The following diagram depicts the flow of data from a customer analytics application into Edge Data Store, via either OMF or SDS REST calls:"
                                                },
    "V1/Overview/CommandLineQuickStartWindows_1-0.html":  {
                                                              "href":  "V1/Overview/CommandLineQuickStartWindows_1-0.html",
                                                              "title":  "Command line quick start - Windows",
                                                              "keywords":  "Command line quick start - Windows The EdgeCmd utility is OSIsoft\u0027s proprietary tool for configuring Edge Data Store from a command line. EdgeCmd must be installed on the device with Edge Data Store. For instructions on installing EdgeCmd, see the EdgeCmd utility help . Complete the following steps to access EdgeCmd on Windows: Open a command prompt. Type the following command and press Enter: edgecmd Help The EdgeCmd utility launches, displaying the introductory material followed by a command prompt: ************************************************************************************************************************ Welcome to OSIsoft Edge Data Store configuration utility. Utility version: 1.0.0.148 ************************************************************************************************************************ --------------------------------------------------------------------------------------------------------- Command-line options =\u003e \u0027Configuration\u0027, \u0027Help\u0027 --------------------------------------------------------------------------------------------------------- Please enter ID of a component you would like to configure or to get component specific help output. Example: .\\edgecmd.exe Help ComponentId .\\edgecmd.exe Configuration ComponentId To get set of components registered to the Edge Data Store please run: .\\edgecmd.exe Configuration System Components To configure the system, please use \u0027System\u0027 as the ComponentId. Example of getting System help output: .\\edgecmd.exe Help System Example of configuring System Logging level: .\\edgecmd.exe Configuration System logging LogLevel=Warning C:\\Users\\John\u003e"
                                                          },
    "V1/Logging/ComponentLogging_1-0.html":  {
                                                 "href":  "V1/Logging/ComponentLogging_1-0.html",
                                                 "title":  "Component-level logging configuration",
                                                 "keywords":  "Component-level logging configuration Component-level logging collects information about how the components of Edge Data Store are performing. Each message in the log displays the message severity level, timestamp, and the message itself. By default, EDS captures Information, Warning, and Error messages in the message log. Note: The individual logging files of EDS and the components are the following: Edge Data Store: System_Logging.json Storage: Storage_Logging.json OSIsoft Adapter for OPC UA: OpcUa1_Logging.json OSIsoft Adapter for Modbus TCP: Modbus1_Logging.json If you have more than one OSIsoft Adapter of the same kind configured, the default file name will incrementally change, for example OpcUa2_Logging.json Configure logging To adjust the message logging behavior, complete the following: Using any text editor, open the componentId_Logging.json file that you want. Change the values as needed, so it looks similar to the Logging example . Use any tool capable of making HTTP requests to execute a POST command with the contents of that file to the respective endpoint. Note: Replace \u003cComponentId\u003e with the ComponentId of the adapter instance or Storage component, for example OpcUa1 . Example using curl (run this command from the same directory where the file is located): curl -i -d \"@componentId_Logging.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/\u003cComponentId\u003e/Logging http:  localhost:5590 api v1 configuration \u003cComponentId\u003e Logging Note: The other endpoints are the following: Edge Data Store: http://localhost:5590/api/v1/configuration/System/Logging http:  localhost:5590 api v1 configuration System Logging Storage: http://localhost:5590/api/v1/configuration/Storage/Logging http:  localhost:5590 api v1 configuration Storage Logging OSIsoft Adapter for OPC UA: http://localhost:5590/api/v1/configuration/OpcUa1/Logging http:  localhost:5590 api v1 configuration OpcUa1 Logging OSIsoft Adapter for Modbus TCP: http://localhost:5590/api/v1/configuration/Modbus1/Logging http:  localhost:5590 api v1 configuration Modbus1 Logging Log levels The logLevel sets the minimum severity for messages to be included in the logs. Messages with a severity below the level set are not included. The log levels in their increasing order of severity are as follows: Trace, Debug, Information, Warning, Error, Critical. Table: General guidelines for setting the log level. Level Description Trace Logs that contain the most detailed messages. These messages may contain sensitive application data like actual received values and should not be enabled in a production environment. Debug Logs that can be used to troubleshoot data flow issues by recording metrics and detailed flow related information. Information Logs that track the general flow of the application. Any non-repetitive general information (like version information relating to the software at startup, what external services are being used, data source connection string, number of measurements, egress URL, change of state \"Starting\", \"Stopping\", or configuration) can be useful for diagnosing potential application errors. Warning Logs that highlight an abnormal or unexpected event in the application flow, but does not otherwise cause the application execution to stop. Warning messages can indicate an unconfigured data source state, that a communication with backup failover instance has been lost, an insecure communication channel in use, or any other event that could require attention, but that does not impact data flow. Error Logs that highlight when the current flow of execution is stopped due to a failure. These should indicate a failure in the current activity, not an application-wide failure. This can indicate an invalid configuration, unavailable external endpoint, internal flow error, and so on. Critical Logs that describe an unrecoverable application or system crash, or a catastrophic failure that requires immediate attention. This can indicate application wide failures like beta timeout expired, unable to start self-hosted endpoint, unable to access vital resource (for example, Data Protection key file), and so on. Parameters for logging The following parameters are available for configuring logging. Parameter Required Type Nullable Description LogFileCountLimit Optional integer Yes The maximum number of log files that the service will create for the component. It must be a positive integer. LogFileSizeLimitBytes Optional integer Yes The maximum size in bytes of log files that the service will create for the component. It must be a positive integer. LogLevel Optional reference No The log level settings that you want. The following options are available: Verbose - Captures all messages: Verbose, Debug, Information, Warning and Error Debug - Captures most messages: Debug, Information, Warning and Error Information - Captures most messages: Information, Warning and Error Warning - Captures only Warning and Error messages Error - Captures Error messages only Logging example { \"LogLevel\": \"Information\", \"LogFileSizeLimitBytes\": 34636833, \"LogFileCountLimit\": 31 }"
                                             },
    "V1/Configuration/System port configuration_1-0.html":  {
                                                                "href":  "V1/Configuration/System port configuration_1-0.html",
                                                                "title":  "System port configuration",
                                                                "keywords":  "System port configuration The System_Port.json file specifies the port on which Edge Data Store is listening for REST API calls. The same port is used for configuration and for writing data to OMF and SDS. The default port is 5590. Valid ports are in the range of 1024-65535. Configure system port Before changing the port, ensure that no other service or application on the device running EDS is using that port because only one application or service can use a port. If you change the port number through the REST API, you must restart EDS. Using any text editor, create a JSON file based on the following example and enter the new port number: { \"Port\": 5590 } Save the JSON file with the name EdgePort.json Run the following script: curl -i -d \"@EdgePort.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/system/port http:  localhost:5590 api v1 configuration system port Note: The port number in the script must be the current port number, not the new port number in the file. After the REST command completes, restart EDS for the change to take effect. Parameters for system port The following parameters is used to specify the system port. Parameter Required Type Nullable Description Port Required integer No The TCP port to bind EDS to. (Range [1024,65535]) Example: 5590"
                                                            },
    "V1/Feedback_1-0.html":  {
                                 "href":  "V1/Feedback_1-0.html",
                                 "title":  "Technical support and feedback",
                                 "keywords":  "Technical support and feedback OSIsoft provides several ways to report issues and provide feedback on Edge Data Store. Technical support For technical assistance with Edge Data Store, contact OSIsoft Technical Support through the OSIsoft Customer Portal . The Technical Support team will respond to resolve your issue. Remote access to your facilities may be necessary during the session. Note: You must have an account set up in the OSIsoft Customer Portal before you can open a support case. If you do not have a portal account, see How to Get a Login to OSIsoft Customer Portal . Alternatively, call OSIsoft Technical Support at +1 510-297-5828. When contacting OSIsoft Technical Support, provide the following information to enable timely resolution of your issue: Product name, version, and build numbers Details about your computer platform (CPU type, operating system, and version number) Date and time the issue started Log files during the time the issue occurred Details of any environment changes prior to the start of the issue Summary of the issue Product feedback To submit product feedback, including enhancement requests, visit the Edge Data Store feedback page . The OSIsoft product team will review and address feedback for potential inclusion in future product updates. Documentation feedback To submit documentation feedback, send an email to documentation@osisoft.com and include the following information: Documentation topic URL Details of the issue The OSIsoft technical documentation team will review and address your feedback in future documentation updates."
                             },
    "V1/Troubleshooting/DisasterRecovery_1-0.html":  {
                                                         "href":  "V1/Troubleshooting/DisasterRecovery_1-0.html",
                                                         "title":  "Disaster recovery",
                                                         "keywords":  "Disaster recovery If a device with Edge Data Store installed fails, use the following procedures to recover data from the failed device and restore it to a new device. The disaster recovery process is similar for both Windows and Linux systems and includes the following steps: Back up the EDS data from the failed device to another location Install EDS on a new device. For instructions, see Install Edge Data Store . Move the backed-up data to the new device Restore the backed-up data files to the new device Reenter credentials Windows recovery Use the following procedures to recover EDS data from a Windows device. Create a backup of EDS data from the failed device Prerequisite: Administrative access on the device is needed to successfully restore on Windows system. To create a backup of data from the failed device, perform the following steps: If your device is still able to boot, verify that Edge Data Store service has stopped. Use the Windows Task Manager to stop the Edge Data Store service. Locate the storage and configuration files. Note: Windows storage and configuration files are stored in the following locations: C:\\ProgramData\\OSIsoft\\EdgeDataStore\\Configuration C:\\ProgramData\\OSIsoft\\EdgeDataStore\\Storage The ProgramData folder is typically hidden; to view it, go to the View tab in Windows Explorer and select the Hidden Items check box. Create a zip or tar file containing the storage and configuration directories, and move it to a USB device or other safe location. File transfer can be done with WinSCP, SFTP, or external device. Delete default storage and configuration folders When EDS is installed on the new device, the new system has a default configuration. Perform the following steps to delete the default storage and configuration folders on the new device: Use the Windows Task Manager to stop the Edge Data Store service. Once the service has stopped, navigate to the C:\\ProgramData\\OSIsoft\\EdgeDataStore directory, and delete the default storage and configuration folders from the new device. Restore backed up data files To restore the data files on the new device, perform the following steps: Copy or unzip the backup storage and configuration files into the C:\\ProgramData\\OSIsoft\\EdgeDataStore directory. Note: The C: drive may not be the default drive letter of your system. Refer to My Computer, This PC, or open a command prompt to verify the default drive letter. Use the Windows Task Manager to restart the Edge Data Store service. Reenter credentials All credentials are encrypted for security purposes, so they cannot be copied or transferred. After the the storage and configuration files are copied to the new system, and the service has started, perform the following steps to enter credentials: Reenter the credentials for the operating system using API calls. After updating, restart the Edge Data Store service. The new EDS device runs as the previous device, and contains all the data up to the point when the previous device failed. Linux recovery Use the following procedures to recover EDS data from a Linux device. Create a backup of EDS data from the failed device To create a backup of data from the failed device, perform the following steps: Prerequisite: Root access on the Linux device is required. If your device is still able to boot, open a terminal window and verify that Edge Data Store service has stopped using the following command: sudo systemctl stop osisoft.edgedatastore Locate the storage and configuration files. Note: Linux storage and configuration files are stored in the following locations: /usr/share/OSIsoft/EdgeDataStore/Configuration  usr share OSIsoft EdgeDataStore Configuration /usr/share/OSIsoft/EdgeDataStore/Storage  usr share OSIsoft EdgeDataStore Storage Create a zip or tar file containing the storage and configuration directories, and move it to a USB device or other safe location. Use WinSCP, SFTP, or the external device to transfer the file. Note: Using the cp command may result in a change in file ownership to the current user. Move the files to the new device When EDS is installed on the new device, the new system has a default configuration. Perform the following steps to copy the backed up storage and configuration folders to the new device: Open a terminal window and stop the Edge Data Store service using the following command: sudo systemctl stop osisoft.edgedatastore Once the service has stopped, navigate to the /usr/share/OSIsoft/EdgeDataStore  usr share OSIsoft EdgeDataStore directory and extract the zip or tar file in that directory using WinSCP, SFTP, or external device. Restore backed up data files To restore the data files on the new device, perform the following steps: Delete the default storage and configuration folders from the /usr/share/OSIsoft/EdgeDataStore  usr share OSIsoft EdgeDataStore directory. Copy or unzip the backup storage and configuration files into the EdgeDataStore directory. If the ownership of the two directories does not match, update it to edgedatastore for the user and group. Start the Edge Data Store service with the following command: sudo systemctl start osisoft.edgedatastore Verify that EDS is running with the following command: sudo systemctl status osisoft.edgedatastore Note: Default directory permissions are set to 755, and each subsequent file is 644. If you do not use tar it is possible to have permission issues with the recovery files. Tar matches via string name rather than the account ID/UID. ID UID. Reenter credentials All credentials are encrypted for security purposes, so they cannot be copied or transferred. After the the storage and configuration files are copied to the new system, and the service has started, perform the following steps to enter credentials: Re-enter the credentials for the operating system using API calls. After updating, restart the Edge Data Store service. The new EDS device runs as the previous device, and contains all the data up to the point when the previous device failed."
                                                     },
    "V1/SDS/Types/SDS_Type_reusability_1-0.html":  {
                                                       "href":  "V1/SDS/Types/SDS_Type_reusability_1-0.html",
                                                       "title":  "SdsType reusability",
                                                       "keywords":  "SdsType reusability An SdsType can also refer other SdsTypes by using their identifiers, which enables type reusability. For example, if there is a common index and value property for a group of types that may have additional properties, a base type can be created with those properties. { \"Id\": \"Simple\", \"Name\": \"Simple\", \"SdsTypeCode\": 1, \"Properties\": [ { \"Id\": \"Time\", \"Name\": \"Time\", \"IsKey\": true, \"SdsType\": { \"SdsTypeCode\": 16 } }, { \"Id\": \"Measurement\", \"Name\": \"Measurement\", \"SdsType\": { \"SdsTypeCode\": 14 } } ] } If a new type should be created with additional properties to the ones above, add a reference to the base type by specifying the base type\u0027s Id. { \"Id\": \"Complex\", \"Name\": \"Complex\", \"SdsTypeCode\": 1, \"BaseType\":{ \"Id\":\"Simple\" }, \"Properties\": [ { \"Id\": \"Depth\", \"Name\": \"Depth\", \"SdsType\": { \"SdsTypeCode\": 14 } } ] } The new type may also include the full type definition of the reference type instead of specifying only the Id. For example: { \"Id\": \"Complex\", \"Name\": \"Complex\", \"SdsTypeCode\": 1, \"BaseType\":{ \"Id\": \"Simple\", \"Name\": \"Simple\", \"SdsTypeCode\": 1, \"Properties\": [ { \"Id\": \"Time\", \"Name\": \"Time\", \"IsKey\": true, \"SdsType\": { \"SdsTypeCode\": 16 } }, { \"Id\": \"Measurement\", \"Name\": \"Measurement\", \"SdsType\": { \"SdsTypeCode\": 14 } } ] }, \"Properties\": [ { \"Id\": \"Depth\", \"Name\": \"Depth\", \"SdsType\": { \"SdsTypeCode\": 14 } } ] } If the full definition is sent, the referenced types (base type \"Simple\" in the example above) should match the actual type initially created. If the full definition is sent and the referenced types do not exist, SDS creates them automatically. Further type creations can reference them as demonstrated above. Note: When trying to get types back from SDS, the results will also include types that were automatically created by SDS. Base types and properties of type Object, Enum, and user-defined collections such as Array, List, and Dictionary will be treated as referenced types. Note that streams cannot be created using these referenced types. If a stream of particular type is to be created, the type should contain at least one property with a valid index type as described in Indexes . The index property may also be in the base type as shown in the example above."
                                                   },
    "V1/SDS/Indexes/Indexes_examples_1-0.html":  {
                                                     "href":  "V1/SDS/Indexes/Indexes_examples_1-0.html",
                                                     "title":  "Index examples",
                                                     "keywords":  "Index examples The following examples show how to build an SdsType representation using the provided sample classes in Python and Java Script. Sample classes The following sample classes are used in the Example SdsType section below. Python class State(Enum): Ok = 0 Warning = 1 Alarm = 2 class Simple(object): Time = property(getTime, setTime) def getTime(self): return self.__time def setTime(self, time): self.__time = time State = property(getState, setState) def getState(self): return self.__state def setState(self, state): self.__state = state Measurement = property(getValue, setValue) def getValue(self): return self.__measurement def setValue(self, measurement): self.__measurement = measurement JavaScript var State = { Ok: 0, Warning: 1, Alarm: 2 } var Simple = function () { this.Time = null; this.State = null; this.Value = null; } Example SdsType The following code is used to build an SdsType representation of the sample class above: Python # Create the properties # Time is the primary key time = SdsTypeProperty() time.Id = \"Time\" time.Name = \"Time\" time.IsKey = True time.SdsType = SdsType() time.SdsType.Id = \"DateTime\" time.SdsType.Name = \"DateTime\" time.SdsType.SdsTypeCode = SdsTypeCode.DateTime # State is not a pre-defined type. An SdsType must be defined to represent the enum stateTypePropertyOk = SdsTypeProperty() stateTypePropertyOk.Id = \"Ok\" stateTypePropertyOk.Measurement = State.Ok stateTypePropertyWarning = SdsTypeProperty() stateTypePropertyWarning.Id = \"Warning\" stateTypePropertyWarning.Measurement = State.Warning stateTypePropertyAlarm = SdsTypeProperty() stateTypePropertyAlarm.Id = \"Alarm\" stateTypePropertyAlarm.Measurement = State.Alarm stateType = SdsType() stateType.Id = \"State\" stateType.Name = \"State\" stateType.Properties = [ stateTypePropertyOk, stateTypePropertyWarning,\\ stateTypePropertyAlarm ] state = SdsTypeProperty() state.Id = \"State\" state.Name = \"State\" state.SdsType = stateType # Measurement property is a simple non-indexed, pre-defined type measurement = SdsTypeProperty() measurement.Id = \"Measurement\" measurement.Name = \"Measurement\" measurement.SdsType = SdsType() measurement.SdsType.Id = \"Double\" measurement.SdsType.Name = \"Double\" # Create the Simple SdsType simple = SdsType() simple.Id = str(uuid.uuid4()) simple.Name = \"Simple\" simple.Description = \"Basic sample type\" simple.SdsTypeCode = SdsTypeCode.Object simple.Properties = [ time, state, measurement ] JavaScript //    Time is the primary key var timeProperty = new SdsObjects.SdsTypeProperty({ \"Id\": \"Time\", \"IsKey\": true, \"SdsType\": new SdsObjects.SdsType({ \"Id\": \"dateType\", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.DateTime }) }); //    State is not a pre-defined type. A SdsType must be defined to represent the enum var stateTypePropertyOk = new SdsObjects.SdsTypeProperty({ \"Id\": \"Ok\", \"Value\": State.Ok }); var stateTypePropertyWarning = new SdsObjects.SdsTypeProperty({ \"Id\": \"Warning\", \"Value\": State.Warning }); var stateTypePropertyAlarm = new SdsObjects.SdsTypeProperty({ \"Id\": \"Alarm\", \"Value\": State.Alarm }); var stateType = new SdsObjects.SdsType({ \"Id\": \"State\", \"Name\": \"State\", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.Int32Enum, \"Properties\": [stateTypePropertyOk, stateTypePropertyWarning, stateTypePropertyAlarm, stateTypePropertyRed] }); //    Value property is a simple non-indexed, pre-defined type var valueProperty = new SdsObjects.SdsTypeProperty({ \"Id\": \"Value\", \"SdsType\": new SdsObjects.SdsType({ \"Id\": \"doubleType\", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.Double }) }); //    Create the Simple SdsType var simpleType = new SdsObjects.SdsType({ \"Id\": \"Simple\", \"Name\": \"Simple\", \"Description\": \"This is a simple Sds type\", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.Object, \"Properties\": [timeProperty, stateProperty, valueProperty] }); The Time property is identified as the Key by defining its SdsTypeProperty as follows: Python # Time is the primary key time = SdsTypeProperty() time.Id = \"Time\" time.Name = \"Time\" time.IsKey = True time.SdsType = SdsType() time.SdsType.Id = \"DateTime\" time.SdsType.Name = \"DateTime\" time.SdsType.SdsTypeCode = SdsTypeCode.DateTime JavaScript //    Time is the primary key var timeProperty = new SdsObjects.SdsTypeProperty({ \"Id\": \"Time\", \"IsKey\": true, \"SdsType\": new SdsObjects.SdsType({ \"Id\": \"dateType\", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.DateTime }) }); Note: The time.IsKey field is set to true. To read data using the key, define a start index and an end index. For DateTime, use ISO 8601 representation of dates and times. To query for a window of values between January 1, 2020 and February 1, 2020, define indexes as \"2020-01-01T08:00:00.000Z\" and \"2020-02-01T08:00:00.000Z\", respectively. For additional information, see Reading data ."
                                                 },
    "zArchive/Schemas/Modbus_DataSource_schema.html":  {
                                                           "href":  "zArchive/Schemas/Modbus_DataSource_schema.html",
                                                           "title":  "Sample Modbus TCP data source configuration",
                                                           "keywords":  "Sample Modbus TCP data source configuration { \"IpAddress\": \"\u003cModbus IP Address\u003e\", \"Port\": \u003cPort - usually 502\u003e, \"ConnectTimeout\": 15000, \"ReconnectInterval\": 5000, \"RequestTimeout\": 9000, \"DelayBetweenRequests\": 0, \"MaxResponseDataLength\": 250 } DataSourceConfiguration properties Property Type Required Nullable Defined by ConnectTimeout integer Optional No DataSourceConfiguration (this schema) DelayBetweenRequests integer Optional No DataSourceConfiguration (this schema) IpAddress string Optional Yes DataSourceConfiguration (this schema) MaxResponseDataLength integer Optional No DataSourceConfiguration (this schema) Port integer Optional No DataSourceConfiguration (this schema) ReconnectInterval integer Optional No DataSourceConfiguration (this schema) RequestTimeout integer Optional No DataSourceConfiguration (this schema) StreamIdPrefix string Optional Yes DataSourceConfiguration (this schema) Note: All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required ConnectTimeout integer Optional DelayBetweenRequests integer Optional IpAddress string Optional MaxResponseDataLength integer Optional Port integer Optional ReconnectInterval integer Optional RequestTimeout integer Optional StreamIdPrefix string Optional"
                                                       },
    "zArchive/Schemas/Modbus_DataSelection_schema.html":  {
                                                              "href":  "zArchive/Schemas/Modbus_DataSelection_schema.html",
                                                              "title":  "Sample Modbus TCP data selection configuration",
                                                              "keywords":  "Sample Modbus TCP data selection configuration [{ \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 1, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 2, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 3, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 4, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 5, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 } ] Modbus TCP data selection configuration properties Property Type Required Nullable Defined by BitMap string Optional Yes DataSelectionConfiguration (this schema) ConversionFactor number Optional Yes DataSelectionConfiguration (this schema) ConversionOffset number Optional Yes DataSelectionConfiguration (this schema) DataTypeCode integer Optional No DataSelectionConfiguration (this schema) Name string Optional Yes DataSelectionConfiguration (this schema) RegisterOffset integer Optional No DataSelectionConfiguration (this schema) RegisterType reference #/definitions/ModbusRegisterType # definitions ModbusRegisterType Optional No DataSelectionConfiguration (this schema) ScanRate integer Optional No DataSelectionConfiguration (this schema) Selected boolean Optional No DataSelectionConfiguration (this schema) StreamId string Optional Yes DataSelectionConfiguration (this schema) UnitId integer Optional No DataSelectionConfiguration (this schema) Note: All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required BitMap string Optional ConversionFactor number Optional ConversionOffset number Optional DataTypeCode integer Optional Name string Optional RegisterOffset integer Optional RegisterType Optional ScanRate integer Optional Selected boolean Optional StreamId string Optional UnitId integer Optional"
                                                          },
    "zArchive/Schemas/EdgeSystem_schema.html":  {
                                                    "href":  "zArchive/Schemas/EdgeSystem_schema.html",
                                                    "title":  "Sample Edge Data Store configuration",
                                                    "keywords":  "Sample Edge Data Store configuration The Edge Data Store configuration schema specifies how to formally describe the system parameters (logging, components, health endpoints, port). \"System\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"Components\": [{ \"componentId\": \"OpcUa1\", \"componentType\": \"OpcUa\" }, { \"componentId\": \"Modbus1\", \"componentType\": \"Modbus\" }, { \"componentId\": \"Storage\", \"componentType\": \"EDS.Component\" } ], \"HealthEndpoints\": [], \"Port\": { \"port\": 5590 } } Edge Data Store configuration properties Property Type Required Nullable Defined by Storage StorageConfiguration Optional Yes StorageConfiguration System SystemConfiguration Optional Yes SystemConfiguration {ComponentName} {ComponentConfiguration} Optional Yes {ComponentConfiguration}"
                                                },
    "V1/SDS/Read data/Filter_Expressions_1-0.html":  {
                                                         "href":  "V1/SDS/Read data/Filter_Expressions_1-0.html",
                                                         "title":  "Filter expressions",
                                                         "keywords":  "Filter expressions Apply filter expressions to any read that returns multiple values, including Get Values , Get Range Values , Get Window Values , and Get Intervals to further control the results of the read. The filter expression is applied to the collection events conditionally filtering events that do not meet the filter conditions. SdsTypeCodes The following types are supported for use within a filter expression: Boolean Byte Char DateTime DateTimeOffset Decimal Double Guid Int16 Int32 Int64 Sbyte Single String Timespan UInt16 UInt32 Uint64 The following types are not supported for use within a filter expression: Array IEnumerable IDictionary IList SdsType SdsTypeProperty Nullable Types Logical operators The following logical operators are supported for use within a filter expression: Operator Description eq Equal to ne Not equal ge Greater than or equal to le Less than or equal to lt Less than gt Greater than ( ) Parenthesis can be used to affect the order of the operation or Or logical operator and And logical operator not Not logical operator - Negation Logical operator examples For the following examples, assume that the SDS Type event includes a field named Value of type double : Value eq 1.0 Value ne 15.6 Value ge 5.0 Value le 8.0 Value gt 5.0 Value lt 4.0 Value gt 2.0 and Value lt 9.0 Value gt 6.0 or Value lt 2.0 not (Value eq 1.0) Math functions The following math functions are supported for use within a filter expression: Function Description add Addition sub Subtraction mul Multiplication div Division mod Modulo round Rounds to the nearest numeric component without a decimal, with the midpoint rounded away from 0. For example, 0.5 rounds to 1; -0.5 rounds to -1) floor Rounds down to the nearest numeric component without a decimal ceiling Rounds up to the nearest numeric component without a decimal Math function examples For the following examples, assume that the SDS Type event includes a field named Value of type double : Value eq (6.0 add 3.0) Value eq (6.0 sub 3.0) Value eq (6.0 mul 3.0) Value eq (6.0 div 3.0) Value eq (7.0 mod 3.0) round(Value) eq 16 floor(Value) eq 15 ceiling(Value) eq 16 String functions String operations are case sensitive. The character index in a string is 0-based. The following string functions are supported for use within a filter expression: Function Description endswith Compare the character at the end of the input string startswith Compare the character at the start of the input string length Examines the string length indexof Examines the character starting at a given index substring Examine characters within another string at a specific location contains Search for characters anywhere in another string tolower Convert characters to lowercase toupper Convert characters to uppercase trim Remove whitespace from front and end of a string concat Concatenate strings together replace Replace one set of characters with another String function examples For the following examples, assume that the SDS Type event includes a field named sValue of type string : Example Result endswith(sValue, \u0027XYZ\u0027) True if sValue ends with the characters ???XYZ??? startswith(sValue, \u0027Val\u0027 True if sValue starts with the characters ???Val??? length(sValue) eq 11 True if sValue is 11 characters indexof(sValue, \u0027ab\u0027) eq 4 True if the 5th and 6th characters are ???ab??? contains(sValue, \u0027ab\u0027) True if characters ???ab??? are found anywhere in sValue substring(sValue, 10) eq \u0027a b\u0027 True if ???a b??? is found in sValue at index 10 tolower(sValue) eq \u0027val5\u0027 Change sValue to lowercase and compare to ???val5??? toupper(sValue) eq \u0027ABC\u0027 Change sValue to uppercase and compare to ???ABC??? trim(sValue) eq \u0027vall22\u0027 Trim whitespace from front and end of sValue and compare to ???val22??? concat(sValue,\u0027xyz\u0027) eq \u0027dataValue_7xyz\u0027 Add characters to sValue and compare to ???dataValue_7xyz??? replace(sValue,\u0027L\u0027,\u0027D\u0027) eq \u0027Dog1\u0027 Replace any ???L??? in sValue with ???D??? and compare to ???Dog1??? DateTime functions The following DateTime functions are supported for use within a filter expression: Function Description year Get year value from DateTime month Get month value from DateTime day Get day value from DateTime hour Get hour value from DateTime minute Get minute value from DateTime second Get second value from DateTime DateTime function examples For the following examples, assume that the SDS Type event includes a field named TimeId of type DateTime : year(TimeId) eq 2015 month(TimeId) eq 11 day(TimeId) eq 3 hour(TimeId) eq 1 minute(TimeId) eq 5 second(TimeId) eq 3 TimeSpan functions The following TimeSpan functions are supported for use within a filter expression: Function Description years Get year value from TimeSpan days Get day value from TimeSpan hours Get hour value from TimeSpan minutes Get minute value from TimeSpan seconds Get second value from TimeSpan TimeSpan function examples For the following examples, assume that the SDS Type event includes a field named TimeSpanValue of type TimeSpan : years(TimeSpanValue) eq 1 days(TimeSpanValue) eq 22 hours(TimeSpanValue) eq 1 minutes(TimeSpanValue) eq 1 seconds(TimeSpanValue) eq 2"
                                                     },
    "V1/SDS/Read data/Enums_1-0.html":  {
                                            "href":  "V1/SDS/Read data/Enums_1-0.html",
                                            "title":  "Enums",
                                            "keywords":  "Enums Enums, or enumerated types, are variable types that have a limited set of possible values. The SDS read APIs support the following enums: SdsBoundaryType SdsSearchMode SdsBoundaryType The SdsBoundaryType enum defines how data on the boundary of queries is handled: around the start index for range value queries, and around the start and end index for window values. The following are valid SdsBoundaryType values: Boundary Enumeration value Operation Exact 0 Results include the event at the specified index boundary if a stored event exists at that index. Inside 1 Results include only events within the index boundaries. Outside 2 Results include up to one event that falls immediately outside of the specified index boundary. ExactOrCalculated 3 Results include the event at the specified index boundary. If no stored event exists at that index, one is calculated based on the index type and interpolation and extrapolation settings. SdsSearchMode The SdsSearchMode enum defines search behavior when seeking a stored event near a specified index. The following are valid values for SdsSearchMode : Mode Enumeration value Operation Exact 0 If a stored event exists at the specified index, that event is returned. Otherwise, no event is returned. ExactOrNext 1 If a stored event exists at the specified index, that event is returned. Otherwise, the next event in the stream is returned. Next 2 Returns the stored event after the specified index. ExactOrPrevious 3 If a stored event exists at the specified index, that event is returned. Otherwise, the previous event in the stream is returned. Previous 4 Returns the stored event before the specified index."
                                        },
    "V1/SDS/Read data/Data_transformations_1-0.html":  {
                                                           "href":  "V1/SDS/Read data/Data_transformations_1-0.html",
                                                           "title":  "Data transformations",
                                                           "keywords":  "Data transformations SDS supports the following data transformations on read requests: Reading with SdsStreamViews: Changing the shape of the returned data Unit of Measure Conversions: Converting the unit of measure of the data Data transformations are supported for all single stream reads, but transformations have specific endpoints. The following are the base URIs for the transformation endpoints: api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/Transform/First api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Transform First api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/Transform/Last api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Transform Last api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/Transform api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Transform api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/Transform/Interpolated api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Transform Interpolated api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/Transform/Summaries api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Transform Summaries api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/Transform/Sampled api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Transform Sampled Reading with SdsStreamViews When you transform data with an SdsStreamView, the data read is converted to the target type specified in the SdsStreamView. For details on working with stream views, see Stream Views . All stream view transformations are GET HTTP requests. Specify the stream view by appending the stream view identifier to requests to the transformation endpoint. For example, the following request would return the first event in the stream as the target type in the stream view specified by the streamViewId : GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/Transform/First?streamViewId={streamViewId} api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Transform First?streamViewId={streamViewId} All single stream data reads support stream view transformations. When you request data with an SdsStreamView, the read characteristics defined by the target type of the SdsStreamView determine what is returned. The read characteristics are discussed in the code samples. Unit 0f measure conversions SDS supports assigning units of measure (UOM) to stream data. For more information, see Units of measure . If stream data has UOM information associated, SDS supports reading data with unit conversions applied. On each read data request, unit conversions are specified by a user defined collection of SdsStreamPropertyOverride objects in read requests. The SdsStreamPropertyOverride object has the following structure: Property Type Optionality Description SdsTypePropertyId String Required Identifier for an SdsTypeProperty with a UOM assigned. Uom String Required Target unit of measure. InterpolationMode SdsInterpolationMode N/A N A Currently not supported in context of data reads. This is supported in the REST API through HTTP POST calls with a request body containing a collection of SdsStreamPropertyOverride objects. All unit conversions are POST HTTP requests. The unit conversion transformation URI is as follows: POST api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/Transform api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Transform Request body The Request Body contains a collection of SdsStreamPropertyOverride objects. The example request body below requests SDS to convert the Measurement property of the returned data from meter to centimeter. [ { \"SdsTypePropertyId\" : \"Measurement\", \"Uom\" : \"centimeter\" } ] All single stream data reads with streams that have specified UOMs support UOM conversions."
                                                       },
    "V1/Overview/SDSQuickStart_1-0.html":  {
                                               "href":  "V1/Overview/SDSQuickStart_1-0.html",
                                               "title":  "SDS quick start",
                                               "keywords":  "SDS quick start Create a custom application using Sequential Data Store (SDS) REST API to send data to Edge Data Store from sources that cannot use Modbus or OPC UA protocols. The following diagram depicts the data flow from an SDS custom application into EDS: The SDS application collects data from a data source and sends it to the EDS endpoint. The EDS endpoint sends the data to the storage component where it is held until it can be egressed to permanent storage in PI Server or OSIsoft Cloud Services. All data from all sources on EDS (Modbus TCP, OPC UA, OMF, SDS) can be read using the SDS REST APIs on the local device, in the default tenant and the default namespace. To get started using the SDS REST API to ingress data into EDS, create an SDS type and stream and then write data events to the SDS stream. Use the Sequential Data Store (SDS) REST API to read the data back from EDS. Create an SDS type Complete the following steps to create an SDS type that describes the format of the data to be stored in a container: Create a JSON file using the example below: { \"Id\": \"Simple\", \"Name\": \"Simple\", \"SdsTypeCode\": 1, \"Properties\": [ { \"Id\": \"Time\", \"Name\": \"Time\", \"IsKey\": true, \"SdsType\": { \"SdsTypeCode\": 16 } }, { \"Id\": \"Measurement\", \"Name\": \"Measurement\", \"SdsType\": { \"SdsTypeCode\": 14 } } ] } Note: The data to be written is a timestamp and numeric value. It is indexed by a timestamp, and the numeric value that will be stored is a 64-bit floating point value. Save the JSON file the name SDSCreateType.json . Run the following curl script from the directory where the file is located: curl -d \"@SDSCreateType.json\" -H \"Content-Type: application/json\" application json\" -X POST http://localhost:5590/api/v1/tenants/default/namespaces/default/types/Simple http:  localhost:5590 api v1 tenants default namespaces default types Simple When this script completes successfully, an SDS type with the same name is created on the server. You can create any number of containers from a single type, as long as they use a timestamp as an index and a 64-bit floating point value. The Type definition needs to be sent first before you send data with a custom application. It does not cause an error to resend the same definition at a later time. Create an SDS stream Complete the following steps to create an SDS stream: Create a JSON file using the example below: { \"Id\": \"Simple\", \"Name\": \"Simple\", \"TypeId\": \"Simple\" } Note: This stream references the type you created earlier. An error occurs if the type does not exist when the stream is created. As with an SDS type, create a stream once before sending data events. Resending the same definition repeatedly does not cause an error. Save the JSON file with the name SDSCreateStream.json . Run the following curl script from the directory where the file is located: curl -d \"@SDSCreateStream.json\" -H \"Content-Type: application/json\" application json\" -X POST http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/Simple http:  localhost:5590 api v1 tenants default namespaces default streams Simple When this script completes successfully, an SDS stream is created on the server to store data defined by the specified type. Write data events to the SDS stream After you create a type and container, use SDS to write data to a stream. Create a JSON file using the example below: [{ \"Time\": \"2017-11-23T17:00:00Z\", \"Measurement\": 50.0 }, { \"Time\": \"2017-11-23T18:00:00Z\", \"Measurement\": 60.0 }] Note: This example includes two data events that will be stored in the SDS Stream created in the previous steps. For optimal performance, batch SDS values when writing them. Save the JSON file with the name SDSWriteData.json . Run the following curl script from the directory where the file is located: curl -d \"@SDSWriteData.json\" -H \"Content-Type: application/json\" application json\" -X POST http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/Simple/Data http:  localhost:5590 api v1 tenants default namespaces default streams Simple Data When this script completes successfully, two values are written to the SDS stream. Read last data written using SDS Use the SDS REST API to read back the last data event written to the server. Start the curl command line tool. Run the following curl command to return the last value written: curl http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/MyCustomContainer/Data/Last http:  localhost:5590 api v1 tenants default namespaces default streams MyCustomContainer Data Last Sample output: {\"Timestamp\": \"2019-07-16T15:18:25.9870136Z\", \"Value\": 12346.6789} Read a range of data events written using SDS Use the SDS REST API to read back the a range of data written to the server. Start the curl command line tool. Run the following curl command to return up to 100 values after the startIndex specified: curl \"http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/MyCustomContainer/Data?startIndex=2017-07-08T13:00:00Z\u0026count=100\" \"http:  localhost:5590 api v1 tenants default namespaces default streams MyCustomContainer Data?startIndex=2017-07-08T13:00:00Z\u0026count=100\" Sample output: [{\"Timestamp\": \"2019-07-16T15:18:24.9870136Z\",\"Value\": 12345.6789}, {\"Timestamp\": \"2019-07-16T15:18:25.9870136Z\", \"Value\": 12346.6789}] Both values that were entered are returned. This command returns up to 100 values after the specified timestamp."
                                           },
    "V1/Overview/OMFQuickStart_1-0.html":  {
                                               "href":  "V1/Overview/OMFQuickStart_1-0.html",
                                               "title":  "OMF quick start",
                                               "keywords":  "OMF quick start Create a custom application using OSIsoft Message Format to send data to Edge Data Store from sources that cannot use Modbus or OPC UA protocols. The following diagram depicts the data flow from an OMF data collection application into EDS: The OMF application collects data from a data source and sends it to the EDS endpoint. The EDS endpoint sends the data to the storage component where it is held until it can be egressed to permanent storage in PI Server or OSIsoft Cloud Services. The OMF application must run on the same device as EDS and no authentication is needed. To get started using OMF messages to ingress data into EDS, create an OMF type and container and then write data events to the container using REST APIs. Use the Sequential Data Store (SDS) REST API to read the data back from EDS. Create an OMF type The first step in OMF data ingress is to create an OMF type that describes the format of the data to be stored in a container. In this example, the data to be written is a timestamp and a numeric value. Create an OMF JSON file that defines the type as follows: [{ \"id\": \"MyCustomType\", \"classification\": \"dynamic\", \"type\": \"object\", \"properties\": { \"Timestamp\": { \"type\": \"string\", \"format\": \"date-time\", \"isindex\": true }, \"Value\": { \"type\": \"number\", \"format\": \"float32\" } } }] The value is indexed by a timestamp, and the numeric value that will be stored is a 32-bit floating point value. To create the OMF type in Edge Storage, store the JSON file with the name OmfCreateType.json on the local device. Run the following curl command: curl -d \"@OmfCreateType.json\" -H \"Content-Type: application/json\" application json\" -H \"producertoken: x \" -H \"omfversion: 1.1\" -H \"action: create\" -H \"messageformat: json\" -H \"messagetype: type\" -X POST http://localhost:5590/api/v1/tenants/default/namespaces/default/omf/ http:  localhost:5590 api v1 tenants default namespaces default omf  When this command completes successfully, an OMF type with the same name is created on the server. Any number of containers can be created from the type, as long as they use a timestamp as an index and have a 32-bit floating point value. The create type message needs to be sent first before container and data messages, but it does not cause an error if the same message is sent at a later time. Create an OMF container The next step in writing OMF data is to create an OMF container. As with an OMF type, the create container message only needs to be sent once before sending data events, but resending the same definition again does not cause an error. Create an OMF JSON file that defines the container as follows: [{ \"id\": \"MyCustomContainer\", \"typeid\": \"MyCustomType\" }] This container references the OMF type that was created earlier, and an error will occur if the type does not exist when the container is created. To create the OMF container in Edge Storage, store the JSON file with the name OmfCreateContainer.json on the local device. To create the SDS stream to store data defined by the type, run the following curl command: curl -d \"@OmfCreateContainer.json\" -H \"Content-Type: application/json\" application json\" -H \"producertoken: x \" -H \"omfversion: 1.1\" -H \"action: create\" -H \"messageformat: json\" -H \"messagetype: container\" -X POST http://localhost:5590/api/v1/tenants/default/namespaces/default/omf/ http:  localhost:5590 api v1 tenants default namespaces default omf  Write data events to the OMF container Once a type and container are defined, complete the following steps to write data to the container: Create an OMF JSON file to define data events to be stored in the SDS Stream created in the previous steps. For best performance, you should batch OMF values together, as in the following example: [{ \"containerid\": \"MyCustomContainer\", \"values\": [{ \"Timestamp\": \"2019-07-16T15:18:24.9870136Z\", \"Value\": 12345.6789 }, { \"Timestamp\": \"2019-07-16T15:18:25.9870136Z\", \"Value\": 12346.6789 } ] }] To write the data to EDS, store the JSON file with the name OmfCreateDataEvents.json on the local device. To write data values to the SDS stream, run the following curl command: curl -d \"@OmfCreateDataEvents.json\" -H \"Content-Type: application/json\" application json\" -H \"producertoken: x \" -H \"omfversion: 1.1\" -H \"action: create\" -H \"messageformat: json\" -H \"messagetype: data\" -X POST http://localhost:5590/api/v1/tenants/default/namespaces/default/omf/ http:  localhost:5590 api v1 tenants default namespaces default omf  Use SDS to read last data written Use the SDS REST API to read back the last data event written to the server. Start the curl command line tool. Run the following curl command to return the last value written: curl http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/MyCustomContainer/Data/Last http:  localhost:5590 api v1 tenants default namespaces default streams MyCustomContainer Data Last Sample output: {\"Timestamp\": \"2019-07-16T15:18:25.9870136Z\", \"Value\": 12346.6789} Use SDS to read a range of data events Use the SDS REST API to read back the a range of data written to the server. Start the curl command line tool. Run the following curl command to return up to 100 values after the startIndex specified: curl \"http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/MyCustomContainer/Data?startIndex=2017-07-08T13:00:00Z\u0026count=100\" \"http:  localhost:5590 api v1 tenants default namespaces default streams MyCustomContainer Data?startIndex=2017-07-08T13:00:00Z\u0026count=100\" Sample output: [{\"Timestamp\": \"2019-07-16T15:18:24.9870136Z\",\"Value\": 12345.6789}, {\"Timestamp\": \"2019-07-16T15:18:25.9870136Z\", \"Value\": 12346.6789}] Both values that were entered are returned. This command returns up to 100 values after the specified timestamp."
                                           },
    "V1/Overview/OCSEgressQuickStart_1-0.html":  {
                                                     "href":  "V1/Overview/OCSEgressQuickStart_1-0.html",
                                                     "title":  "OCS egress quick start",
                                                     "keywords":  "OCS egress quick start Data egress provides a mechanism to transfer data to OSIsoft Cloud Services using OMF messages. To get started sending data stored in Edge Data Store to OCS, create an OMF connection in OCS and configure an egress endpoint with the connection information for OCS. Create an OMF connection in OCS Complete the following steps to create an OMF connection in OCS: In OCS, create a Client . The Client Id and Client Secret are used for the corresponding properties in the egress configuration. In OCS, create an OMF type Connection . The connection should link the client to an existing namespace where the data will be stored. The OMF Endpoint URL for the connection is used as the value for the Endpoint property in the egress configuration. For complete steps, as well as best practices and recommendations, see the OSIsoft Cloud Services documentation . Create a periodic egress configuration Complete the following steps to configure periodic egress to OCS: Create a JSON file containing one or more egress endpoints, by copying the following example into a text editor. [{ \"Id\": \"OCS\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"default\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"ChangeMe\", \"TypePrefix\": \"ChangeMe\", \"Endpoint\": \"https://\u003cyour \"https:  \u003cyour OCS OMF endpoint\u003e\", \"ClientId\": \"\u003cyour OCS ClientId\u003e\", \"ClientSecret\": \"\u003cyour OCS ClientSecret\u003e\", \"UserName\": null, \"Password\": null, \"DebugExpiration\": null, \"ValidateEndpointCertificate\": true, \"TokenEndpoint\": null }] Modify the Endpoint parameter to be the URL of the OCS OMF endpoint. Modify the ClientId and ClientSecret parameters with the authentication information to connect to the OCS OMF endpoint. Note: If uniqueness is required on the destination system, use the StreamPrefix and TypePrefix parameters. If a StreamPrefix is specified, it is used to create a unique stream ID on OCS. This configuration is set up to send all stream data to OCS. To only send specific streams, edit the EgressFilter parameter. For examples of more advanced scenarios, see Data egress configuration . Save the JSON file with the name PeriodicEgressEndpoints.json to any directory on the device where EDS is installed. To configure the Edge Storage component to send data to OCS, run the following curl script from the directory where the JSON file is located. curl -d \"@PeriodicEgressEndpoints.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/storage/PeriodicEgressEndpoints/ http:  localhost:5590 api v1 configuration storage PeriodicEgressEndpoints  When this command completes successfully, data egress to OCS begins."
                                                 },
    "V1/Modbus/SupportedFeaturesModbus_1-0.html":  {
                                                       "href":  "V1/Modbus/SupportedFeaturesModbus_1-0.html",
                                                       "title":  "Supported features",
                                                       "keywords":  "Supported features The Modbus TCP EDS adapter collects data using register types and then converts the registers into data types. It can apply bitmaps and data conversion to values converted from reading the Modbus TCP devices. Register types The Modbus TCP EDS adapter supports 6 register types, corresponding to 4 function codes (1-4). Since one function code can return two types of registers, either 16-bit or 32-bit depending on the device, either the register type or the register type code is required when configuring the data selection for the adapter. The following table lists all the register types supported in the Modbus TCP EDS adapter. Register Type Register Type Code Description Function Code Coil 1 Read Coil Status 1 Discrete 2 Read Discrete Input Status 2 Holding16 3 Read 16-bit Holding Registers 3 Holding32 4 Read 32-bit Holding Registers 3 Input16 6 Read 16-bit Input Registers 4 Input32 7 Read 32-bit Input Registers 4 When reading from function codes 1 and 2 , the adapter expects these to be returned as single bits. For function codes 3 and 4 , the adapter expects 16 bits to be returned from devices that contain 16-bit registers and 32 bits to be returned from devices that contain 32-bit registers. Data types The Modbus TCP EDS adapter converts readings from single or multiple registers into the data types specified by the data type code and populates the value into streams created in the Edge Data Store. The following table lists all data types with their corresponding type codes supported by the Modbus TCP EDS adapter. Data type code Data type name Value type Register type Description 1 Boolean Boolean Bool 0 = false 1 = true 10 Int16 Int16 Bool/16-bit Bool 16-bit Read 1 Modbus TCP register and interpret as a 16-bit integer. Bytes [BA] read from the device are stored as [AB]. 20 UInt16 UInt16 Bool/16-bit Bool 16-bit Read 1 Modbus TCP register and interpret as an unsigned 16-bit integer. Bytes [BA] read from the device are stored as [AB]. 30 Int32 Int32 16-bit/32-bit 16-bit 32-bit Read 32 bits from the Modbus TCP device and interpret as a 32-bit integer. Bytes [DCBA] read from the device are stored as [ABCD]. 31 Int32ByteSwap Int32 16-bit/32-bit 16-bit 32-bit Read 32 bits from the Modbus TCP device and interpret as a 32-bit integer. Bytes [BADC] read from the device are stored as [ABCD]. 100 Float32 Float32 16-bit/32-bit 16-bit 32-bit Read 32 bits from the Modbus TCP device and interpret as a 32-bit float. Bytes [DCBA] read from the device are stored as [ABCD]. 101 Float32ByteSwap Float32 16-bit/32-bit 16-bit 32-bit Read 32 bits from the Modbus TCP device and interpret as a 32-bit float. Bytes [BADC] read from the device are stored as [ABCD]. 110 Float64 Float64 16-bit/32-bit 16-bit 32-bit Read 64 bits from the Modbus TCP device and interpret as a 64-bit float. Bytes [HGFEDCBA] read from the device are stored as [ABCDEFGH]. 111 Float64ByteSwap Float64 16-bit/32-bit 16-bit 32-bit Read 64 bits from the Modbus TCP device and interpret as a 64-bit float. Bytes [BADCFEHG] read from the device are stored as [ABCDEFGH]. 1001 - 1250 String String 16-bit/32-bit 16-bit 32-bit 1001 reads a one-character string, 1002 reads a two-character string, and 1003 reads a three-character string and so on. Bytes [AB] are interpreted as \"AB\". 2001 - 2250 StringByteSwap String 16-bit/32-bit 16-bit 32-bit 2001 reads a one-character string, 2002 reads a two-character string, and 2003 reads a three-character string and so on. Bytes [BA] are interpreted as \"AB\". Apply bitmap The Modbus TCP EDS adapter supports applying bitmaps to the value converted from the readings from the Modbus TCP devices. A bitmap is a series of numbers used to extract and reorder bits from a word register. The format of the bitmap is uuvvwwxxyyzz, where uu, vv, ww, yy, and zz each refer to a single bit. A leading zero is required if the referenced bit is less than 10. The low-order bit is 01 and high-order bit is either 16 or 32. Up to 16 bits can be referenced for a 16-bit word (data types 10 and 20) and up to 32 bits can be referenced for a 32-bit word (data type 30 and 31). For example, the bitmap 0307120802 will map the second bit of the original word to the first bit of the new word, the eighth bit to the second bit, the twelfth bit to the third bit, and so on. The high-order bits of the new word are padded with zeros if they are not specified. Not all data types support applying bitmap. The data types supporting bitmap are: Int16 (Data type code 10) UInt16 (Data type code 20) Int32 (Data type code 30 and 31) Apply data conversion The Modbus TCP EDS adapter supports applying data conversion to the value converted from reading the Modbus TCP devices. A conversion factor and conversion offset can be specified. The conversion factor is used for scaling the value up or down, and the conversion offset is used for shifting the value. The mathematical equation used in conversion is the following: \u003cAfter Conversion\u003e = \u003cBefore Conversion\u003e /   Factor - Offset Not all data types support applying data conversion. Data types that support data conversion are: Int16 (Data type code 10) UInt16 (Data type code 20) Int32 (Data type code 30 and 31) Float32 (Data type code 100 and 101) The value with data conversion applied will always be converted to the 32-bit float type to maintain the precision of the conversion factor and conversion offset."
                                                   },
    "V1/Modbus/PrinciplesOfOperationModbus_1-0.html":  {
                                                           "href":  "V1/Modbus/PrinciplesOfOperationModbus_1-0.html",
                                                           "title":  "Operational overview",
                                                           "keywords":  "Operational overview Once an instance of the Modbus TCP EDS adapter is defined in the system components configuration, it must be configured for it to create streams and collect data. Adapter configuration For an Modbus TCP EDS adapter instance to start data collection, configure the adapter by defining the following: Data source: Provide the connection information for the Modbus data source. Data selection: Specify the Modbus TCP items to which the adapter instance should subscribe for data. Logging: Set up the logging behavior for the adapter instance. For more details, see Data source configuration and Data selection configuration . For more information on how to configure logging, see Component-level logging configuration . Connection The Modbus TCP EDS adapter communicates with the Modbus TCP devices through the TCP/IP TCP IP network by sending request packets that are constructed based on the data selection configurations, and collects the response packets returned by the devices. Stream creation From the parsed data selection configurations, the Modbus TCP EDS adapter creates types, streams, and data based on the information provided. For each measurement in the data selection configuration, a stream is created in EDS to store time series data. Data collection The Modbus TCP EDS adapter collects data from the Modbus TCP devices at the polling rates specified in the configuration. The rates are set in each of the data selection configurations and can range from 0 milliseconds (as fast as possible) up to 1 day per polling. The adapter automatically optimizes the data collection process by grouping the requests to reduce the I/O I O load imposed on the Modbus TCP networks. Streams by Modbus TCP EDS adapter For each data selection configuration, the Modbus TCP EDS adapter creates a stream with two properties. The properties are described in the following table: Property name Data type Description Timestamp String The response time of the stream data from the Modbus TCP device. Value Specified by the data selection The value of the stream data from the Modbus TCP device. Stream ID is a unique identifier for each stream created by the adapter for the selected measurement. If a custom stream ID is specified for the measurement in the data selection configuration, the Modbus TCP EDS adapter will use that stream ID to create the stream. Otherwise, the adapter constructs the stream ID using the following format: \u003cAdapter Component ID\u003e.\u003cUnit ID\u003e.\u003cRegister Type\u003e.\u003cRegister Offset\u003e Note: Naming convention is affected by StreamIdPrefix and ApplyPrefixToStreamID settings in data source configuration. For more information, see Data source configuration . Buffering Because the Modbus TCP EDS adapter sends data directly to EDS, buffering capability is not provided. EDS acts as a buffer before the data is egressed to either a PI Server or OCS. The amount of data stored in EDS is controlled by the following storage parameters: StreamStorageLimitMb StreamStorageTargetMb For more information about configuring data storage in EDS, see Storage runtime configuration ."
                                                       },
    "V1/Diagnostics/Diagnostics_1-0.html":  {
                                                "href":  "V1/Diagnostics/Diagnostics_1-0.html",
                                                "title":  "Diagnostics configuration",
                                                "keywords":  "Diagnostics configuration Edge Data Store and its components produce performance and system data for diagnostic purposes which is stored locally in the Storage component, and may be queried locally or egressed to PI Web API endpoints or the OSIsoft Cloud Services or both. Diagnostic data is always produced and saved; it cannot be disabled. Diagnostic data is stored within the diagnostics namespace in Edge Storage. Local access to this data is available through SDS. For more information, see Read data . Egress diagnostics data through PeriodicEgressEndpoints To egress diagnostics related data, Specify diagnostics as the NamespaceId in the periodic egress endpoint configuration. For details and instructions, see Data egress configuration . Edge Data Store diagnostics The Diagnostics.System dynamic type includes these values which are logged in a stream with the ID System.Diagnostics. This diagnostic stream contains system-level information related to the host platform that Edge Data Store is running on. Type Property Description string timestamp Timestamp of event int ProcessIdentifier Process id of the host process string StartTime When the host process started long WorkingSet Amount of physical memory, in bytes, allocated for the host process double TotalProcessorTime (uom=s) Total processor time for the host process expressed in seconds double TotalUserProcessorTime (uom=s) User processor time for the host process expressed in seconds double TotalPrivilegedProcessorTime (uom=s) Privileged processor time for the host process expressed in seconds int ThreadCount Number of threads in the host process int HandleCount Number of handles opened by the host process double ManagedMemorySize (uom=MB) Number of bytes currently thought to be allocated in managed memory double PrivateMemorySize (uom=MB) Amount of paged memory, in bytes, allocated for the host process double PeakPagedMemorySize (uom=MB) Maximum amount of memory in the virtual memory paging file, in bytes, used by the host process. Note: On Linux platiforms, this value is always reported as 0. double StorageTotalSize (uom=MB) Total size of the storage medium in use by the Edge Data Store double StorageFreeSpace (uom=MB) Free space available EDS adapter diagnostics Each EDS adapter of the Edge Data Store produces its own diagnostics streams. Stream count The Diagnostics.StreamCountEvent dynamic type includes these values, which are logged in a stream with the id {componentid}.StreamCount. The stream count and type count include only types and streams created for sequential data received from a data source. Type Property Description string timestamp Timestamp of event int StreamCount Number of streams created by the adapter instance int TypeCount Number of types created by the adapter instance IO rate The Diagnostics.Adapter.IORate dynamic type includes these values, which are logged in a stream with the id {componentid}.IORate. IO rate includes only sequential data collected from a data source. Type Property Description string timestamp Timestamp of event double IORate 10-minute rolling average of data rate (streams/second) (streams second) Error rate The Diagnostics.Adapter.ErrorRate dynamic type includes these values, and are logged in a stream with the id {componentid}.ErrorRate. Type Property Description string timestamp Timestamp of event double ErrorRate 10-minute rolling average of error rate (streams/second) (streams second) Edge Storage diagnostics The Storage component of Edge Data Store produces the following diagnostics streams. Storage.default.default.Counts The Storage.default.default.Counts stream includes counts of the types, streams, and stream views of the default namespace. Type Property Description string timestamp Timestamp of event integer TypeCount Count of types integer StreamCount Count of streams integer StreamViewCount Count of stream views Storage.default.diagnostics.Counts The Storage.default.default.Counts stream includes counts of the types, streams, and stream views of the diagnostics namespace. Type Property Description string timestamp Timestamp of event integer TypeCount Count of types integer StreamCount Count of streams integer StreamViewCount Count of stream views Storage.Total.Counts The Storage.Totals.Counts stream includes counts of the types, streams, and stream views of all namespaces of the storage component. Type Property Description string timestamp Timestamp of event integer TypeCount Count of types integer StreamCount Count of streams integer StreamViewCount Count of stream views"
                                            },
    "V1/Design/ScalePerformance_1-0.html":  {
                                                "href":  "V1/Design/ScalePerformance_1-0.html",
                                                "title":  "Design considerations",
                                                "keywords":  "Design considerations Before installing Edge Data Store, determine your storage and throughput needs and select devices that meet those needs. Edge Storage role The Edge Storage component is integrated with the EDS and does not replace any existing storage technology produced by OSIsoft. The Edge Storage component is a resilient and reliable data store, but is limited in the duration and scope of the data it retains. By default, the storage component processes data in a FIFO (first in first out) method: as new data comes in and the size of streams exceeds the configured limits, older data is purged. Data that needs to be permanently retained must be egressed to either PI Data Archive (using the PI Web API OMF endpoint) or to OSIsoft Cloud Services, using the OCS OMF ingress endpoint. Edge Storage scale The Edge Storage component provides an appropriate level of storage performance for small devices. For the smallest of these devices, throughput may be limited to tens of events per second. For larger devices with faster processors, memory and storage, this could increase up to 3,000 events per second. The Edge Storage component is designed for small devices in Edge scenarios: if high throughput or large stream counts are required, OSIsoft Cloud Services or PI Data Archive are more appropriate choices. Sizing of Edge devices For EDS, there are three supported tiers of performance: Small Devices: 1 Core CPU, 512 MB RAM. 30 events/second, events second, 200 streams total. Medium Devices: 2 Core CPU, 1 GB RAM. 300 events/second, events second, 2000 streams total. Large Devices: 4 Core CPU, 4 GB RAM, SSD storage. 3000 events/second, events second, 3000 streams total. These performance metrics assume solid state storage, which is commonly used in Edge devices."
                                            },
    "V1/Administration/Retrieve product version information_1-0.html":  {
                                                                            "href":  "V1/Administration/Retrieve product version information_1-0.html",
                                                                            "title":  "Retrieve product version information",
                                                                            "keywords":  "Retrieve product version information The product version information includes the Edge Data Store version number, the .NET Core version, the Core CLR version, and the operating system. This information can be useful for troubleshooting purposes. Complete the following steps to retrieve the product version of EDS: Open a tool capable of making HTTP requests. Run a GET command to the following endpoint, replacing \u003cport_number\u003e with the port specified for EDS: http://localhost:\u003cport_number\u003e/api/v1/diagnostics/productinformation http:  localhost:\u003cport_number\u003e api v1 diagnostics productinformation Example using curl and the default port number: curl -v http://localhost:5590/api/v1/Diagnostics/ProductInformation http:  localhost:5590 api v1 Diagnostics ProductInformation"
                                                                        },
    "V1/Administration/Reset Edge Data Store_1-0.html":  {
                                                             "href":  "V1/Administration/Reset Edge Data Store_1-0.html",
                                                             "title":  "Reset Edge Data Store",
                                                             "keywords":  "Reset Edge Data Store When applied at the system level, the Reset command deletes all event and configuration data and restarts Edge Data Store. Note: All configuration and stored data will be lost as a result of performing this action. Complete the following steps to reset EDS: Start any tool capable of making HTTP requests. Execute a POST command to the following endpoint, replacing \u003cport_number\u003e with the port specified for EDS: http://localhost:\u003cport_number\u003e/api/v1/administration/System/Reset http:  localhost:\u003cport_number\u003e api v1 administration System Reset Example using curl and the default port: curl -d \"\" http://localhost:5590/api/v1/Administration/System/Reset http:  localhost:5590 api v1 Administration System Reset An HTTP status 204 message indicates success."
                                                         },
    "V1/Administration/Administration_1-0.html":  {
                                                      "href":  "V1/Administration/Administration_1-0.html",
                                                      "title":  "Administration",
                                                      "keywords":  "Administration Reset the Edge Data Store application, EDS adapters, and the EDS Storage component with the EDS administration level functions. The examples in the following administration topics use curl, a commonly available tool on both Windows and Linux. The same operations can be performed with the EdgeCmd command line utility or with any programming language or tool that supports making REST calls. For a partial list of REST tools, see Configuration tools . If available on your device, use a browser to complete data retrieval steps (GET commands) to validate successful configurations."
                                                  },
    "V1/SDS/Write data/Response-format-write_1-0.html":  {
                                                             "href":  "V1/SDS/Write data/Response-format-write_1-0.html",
                                                             "title":  "Response format for write APIs",
                                                             "keywords":  "Response format for write APIs The format of the response is specified in the API call. For write APIs, the supported response formats are: JSON - The default response format for SDS, which is used in all examples in this documentation. Default JSON responses do not include any values that are equal to the default value for their type. Verbose JSON - Verbose has no impact on writes because writes return only error messages. To specify verbose JSON return, add the header Accept-Verbosity with a value of verbose to the request. SDS - To specify SDS format, set the Accept header in the request to application/sds application sds ."
                                                         },
    "V1/SDS/Views/SDS_Stream_View_API_1-0.html":  {
                                                      "href":  "V1/SDS/Views/SDS_Stream_View_API_1-0.html",
                                                      "title":  "SdsStreamView API",
                                                      "keywords":  "SdsStreamView API The REST APIs provide programmatic access to read and write SDS data. The APIs in this section interact with SdsStreamViews. For general SdsStreamView information, see Stream views . Get Stream View Returns the stream view corresponding to the specified streamViewId within a given namespace. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/StreamViews/{streamViewId} api v1 Tenants default Namespaces {namespaceId} StreamViews {streamViewId} Parameters string namespaceId The namespace; either default or diagnostics. string streamViewId The stream view identifier. Response The response includes a status code and a response body. Response body The requested SdsStreamView. Example response body: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"Id\":\"StreamView\", \"Name\":\"StreamView\", \"SourceTypeId\":\"Simple\", \"TargetTypeId\":\"Simple3\", \"Properties\":[ { \"SourceId\":\"Time\", \"TargetId\":\"Time\" }, { \"SourceId\":\"State\", \"TargetId\":\"State\" }, { \"SourceId\":\"Measurement\", \"TargetId\":\"Value\" } ] } Get Stream View Map Returns the stream view map corresponding to the specified streamViewId within a given namespace. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/StreamViews/{streamViewId}/Map api v1 Tenants default Namespaces {namespaceId} StreamViews {streamViewId} Map Parameters string namespaceId The namespace; either default or diagnostics. string streamViewId The stream view identifier. Response The response includes a status code and a response body. Response body The requested SdsStreamView. Example response body: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"SourceTypeId\":\"Simple\", \"TargetTypeId\":\"Simple3\", \"Properties\":[ { \"SourceId\":\"Time\", \"TargetId\":\"Time\" }, { \"SourceId\":\"Measurement\", \"TargetId\":\"Value\", \"Mode\":20 }, { \"SourceId\":\"State\", \"Mode\":2 }, { \"TargetId\":\"State\", \"Mode\":1 } ] } Get Stream Views Returns a list of stream views within a given namespace. If specifying the optional search query parameter, the list of stream views returned will match the search criteria. If the search query parameter is not specified, the list will include all stream views in the Namespace. See Search in SDS for information about specifying those respective parameters. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/StreamViews?query={query}\u0026skip={skip}\u0026count={count}\u0026orderby={orderby} api v1 Tenants default Namespaces {namespaceId} StreamViews?query={query}\u0026skip={skip}\u0026count={count}\u0026orderby={orderby} Parameters string namespaceId The namespace; either default or diagnostics. string query An optional parameter representing a string search. For information about specifying the search parameter, see Search in SDS . int skip An optional parameter representing the zero-based offset of the first SdsStreamView to retrieve. If not specified, a default value of 0 is used. int count An optional parameter representing the maximum number of SdsStreamViews to retrieve. If not specified, a default value of 100 is used. string orderby An optional parameter representing sorted order which SdsStreamViews will be returned. A field name is required. The sorting is based on the stored values for the given field (of type string). For example, orderby=name would sort the returned results by the name values (ascending by default). Additionally, a value can be provided along with the field name to identify whether to sort ascending or descending, by using values asc or desc , respectively. For example, orderby=name desc would sort the returned results by the name values, descending. If no value is specified, there is no sorting of results. Response The response includes a status code and a response body. Response body A collection of zero or more SdsStreamViews. Example response body: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Id\":\"StreamView\", \"Name\":\"StreamView\", \"SourceTypeId\":\"Simple\", \"TargetTypeId\":\"Simple3\" }, { \"Id\":\"StreamViewWithProperties\", \"Name\":\"StreamViewWithProperties\", \"SourceTypeId\":\"Simple\", \"TargetTypeId\":\"Simple3\", \"Properties\":[ { \"SourceId\":\"Time\", \"TargetId\":\"Time\" }, { \"SourceId\":\"State\", \"TargetId\":\"State\" }, { \"SourceId\":\"Measurement\", \"TargetId\":\"Value\" } ] } ] Get or Create Stream View If a stream view with a matching identifier already exists, the stream view passed in is compared with the existing stream view. If the stream views are identical, a Found (302) status is returned and the stream view. If the stream views are different, the Conflict (409) error is returned. If no matching identifier is found, the specified stream view is created. Request POST api/v1/Tenants/default/Namespaces/{namespaceId}/StreamViews/{streamViewId} api v1 Tenants default Namespaces {namespaceId} StreamViews {streamViewId} Parameters string namespaceId The namespace; either default or diagnostics. string streamViewId The stream view identifier. The identifier must match the SdsStreamView.Id field. Request body The request content is the serialized SdsStreamView. Response The response includes a status code and a response body. Response body The newly created or matching SdsStreamView. Create or Update Stream View Creates or updates the definition of a stream view. Request PUT api/v1/Tenants/default/Namespaces/{namespaceId}/StreamViews/{streamViewId} api v1 Tenants default Namespaces {namespaceId} StreamViews {streamViewId} Parameters string namespaceId The namespace; either default or diagnostics. string streamViewId The stream view identifier. Request body The request content is the serialized SdsStreamView. Response The response includes a status code and a response body. Response body The newly created or updated SdsStreamView. Delete Stream View Deletes a stream view from the specified tenant and namespace. Request DELETE api/v1/Tenants/default/Namespaces/{namespaceId}/StreamViews/{streamViewId} api v1 Tenants default Namespaces {namespaceId} StreamViews {streamViewId} Parameters string namespaceId The namespace; either default or diagnostics. string streamViewId The stream view identifier. Response The response includes a status code."
                                                  },
    "V1/SDS/UOM/Supported_Uom_Quantities_1-0.html":  {
                                                         "href":  "V1/SDS/UOM/Supported_Uom_Quantities_1-0.html",
                                                         "title":  "Supported quantities",
                                                         "keywords":  "Supported quantities The following table shows supported quantities and their base unit of measures. Supported quantities are read-only. Quantity Id Base Uom Id Angular Velocity radian per second Area square meter Computer Storage byte Density kilogram per cubic meter Dynamic Viscosity pascal second Electric Charge coulomb Electric Current ampere Electric Potential volt Electric Resistance ohm Energy joule Entropy and Heat Capacity joule per kelvin Force newton Frequency hertz Length meter Luminous Intensity candela Mass kilogram Mass Flow Rate kilogram per second Molar Flow Rate mole per second Molecular Weight kilogram per mole Amount of Substance mole Plane Angle radian Power watt Pressure pascal Quantity count Ratio percent Specific Energy joule per kilogram Specific Entropy and Specific Heat Capacity joule per kilogram kelvin Specific Volume cubic meter per kilogram Speed meter per second Temperature kelvin Temperature (Delta) delta kelvin Time second Volume cubic meter Volume Flow Rate cubic meter per second"
                                                     },
    "V1/SDS/SDS_Types_1-0.html":  {
                                      "href":  "V1/SDS/SDS_Types_1-0.html",
                                      "title":  "Types",
                                      "keywords":  "Types An SdsType (used interchangeably with type throughout documentation) defines the shape of a single measured event or object. A type gives structure to the data. For example, if a device measures three things, such as longitude, latitude, and speed, at the same time, then the SdsType should include those three properties. An SdsType defines the structure of an event stored in an SdsStream and how to associate events within the SdsStream. An event is a single unit whose properties have values that relate to the index; that is, each property of an SdsType event is related to the event???s index. Each event is a single unit. SdsTypes can define simple atomic types, such as integers, floats, strings, arrays, and dictionaries, or complex types with nested SdsTypes using the Properties collection of an SdsType. An SdsType used to define an SdsStream must have a key, which is a property, or a combination of properties that constitute an ordered, unique identity. Because the key is ordered, it functions as an index. It is known as the primary index. While a timestamp (DateTime) is a very common key, any data that can be ordered is permitted. Other indexes (secondary indexes), are defined in the SdsStream. For more details on indexes, see Indexes . An SdsType is referenced by its identifier or Id field. SdsType identifiers must be unique within a Namespace. An SdsType can also refer other SdsTypes by using their identifiers. This enables type reusability. Nested types and base types are automatically created as separate types. For further information, see Type reusability . Once an SdsType is created, it is immutable and its definition cannot be changed. If the SdsType definition is incorrect, you must delete and recreate it, and it can only be deleted if no streams, stream views, or types reference it. Only the SdsTypes used to define SdsStreams or SdsStreamViews are required to be added to the Sequential Data Store. SdsTypes that define properties or base types are contained within the parent SdsType do not need to be added to the Data Store separately. SdsTypes define how events are associated and read within an SdsStream. When attempting to read non-existent indexes, indexes that fall between, before or after existing indexes, the results are determined by the interpolation and extrapolation settings of the SdsType. For more information about interpolation and extrapolation, see Read characteristics . The following table shows the SdsType fields. Fields that are not included are reserved for internal SDS use. Property Type Optionality Searchable Details ID String Required Yes Identifier for referencing the type. Name String Optional Yes Friendly name. Description String Optional Yes Description text. SdsTypeCode SdsTypeCode Required No Numeric code identifying the base SdsType. InterpolationMode SdsInterpolationMode Optional No Interpolation setting of the type. Default is Continuous. ExtrapolationMode SdsExtrapolationMode Optional No Extrapolation setting of the type. Default is All. Properties IList\u003cSdsTypeProperty\u003e Required Yes, with limitations List of SdsTypeProperty items. See SdsTypeProperty . For search limitations, see Search in SDS . Rules for the type identifier (SdsType.ID) The type identifier, SdsType.ID, has the following requirements: Is not case sensitive. Can contain spaces. Cannot contain forward slash (\"/\"). (\" \"). Contains a maximum of 100 characters."
                                  },
    "V1/SDS/SDS_Streams_1-0.html":  {
                                        "href":  "V1/SDS/SDS_Streams_1-0.html",
                                        "title":  "Streams",
                                        "keywords":  "Streams SdsStreams are collections of sequentially occurring values indexed by a single property, typically time series data. You define SdsStreams to organize incoming data from another system into the OCS. To define an SdsStream, you must first define an SdsType, which defines the structure of the data you want to stream into a selected namespace. SdsStreams are referenced by their identifier, which is the Id field. SdsStream identifiers must be unique within a namespace. An SdsStream must include a TypeId that references the identifier of an existing SdsType. When an SdsStream contains data, you must use a stream view to update the stream type. The following table shows the SdsStream fields. Fields not listed are reserved for internal SDS use. Property Type Optionality Searchable Details Id String Required Yes An identifier for referencing the stream. TypeId String Required Yes The SdsType identifier of the type to be used for this stream. Name String Optional Yes Friendly name. Description String Optional Yes Description text. Indexes IList\u003cSdsStreamIndex\u003e Optional No Used to define secondary indexes for stream. InterpolationMode SdsInterpolationMode Optional No Interpolation setting of the stream. Default is null. ExtrapolationMode SdsExtrapolationMode Optional No Extrapolation setting of the stream. Default is null. PropertyOverrides IList\u003cSdsStreamPropertyOverride\u003e Optional No Used to define unit of measure and interpolation mode overrides for a stream. Rules for the stream identifier (SdsStream.Id) The stream identifier, SdsStream.Id, has the following requirements: Is not case sensitive. Can contain spaces. Cannot contain forward slash (\"/\"). (\" \"). Contains a maximum of 100 characters. Indexes The key or primary index is defined at the SdsType. Secondary indexes are defined at the SdsStream. Secondary indexes are applied to a single property; there are no compound secondary indexes. Only SdsTypeCodes that can be ordered are supported for use in a secondary index. For more information about indexes, see Indexes . Interpolation and extrapolation The InterpolationMode, ExtrapolationMode, and PropertyOverrides can be used to determine how a specific stream reads data. These read characteristics are inherited from the type if they are not defined at the stream level. For more information about type read characteristics and how these characteristics dictate how events are read, see Types . PropertyOverrides PropertyOverrides are used to override interpolation behavior and unit of measure for individual SdsType Properties for a specific SdsStream. The SdsStreamPropertyOverride object has the following structure: Property Type Optionality Details SdsTypePropertyId String Required SdsTypeProperty identifier. InterpolationMode SdsInterpolationMode Optional Interpolation setting. Default is null. Uom String Optional Unit of measure. The unit of measure can be overridden for any type property defined by the stream type, including primary keys and secondary indexes. For more information about type property units of measure, see Types . Read characteristics of the stream are determined by the type and the PropertyOverrides of the stream. The interpolation mode for non-index properties can be defined and overridden at the stream level. For more information about type read characteristics, see Types . If the SdsType InterpolationMode is Discrete , it cannot be overridden at any level. When InterpolationMode is set to Discrete and an event is not defined for that index, a null value is returned for the entire event."
                                    },
    "V1/SDS/Read_Data_1-0.html":  {
                                      "href":  "V1/SDS/Read_Data_1-0.html",
                                      "title":  "Read data",
                                      "keywords":  "Read data The REST APIs provide programmatic access to read stream data from SDS. The results returned by the APIs are affected by types, stream views, filter expressions, and table format. Single stream reads The following methods for reading a single value are available: Get First Value returns the first value in the stream. Get Last Value returns the last value in the stream. Find Distinct Value returns a value based on a starting index and search criteria. In addition, the following methods support reading multiple values: Get Values retrieves a collection of stored values based on the request parameters. Get Interpolated Values retrieves a collection of stored or calculated values based on the request parameters. Get Summaries retrieves a collection of evenly spaced summary intervals based on a count and specified start and end indexes. Get Sampled Values retrieves a collection of sampled data based on the request parameters. All single stream reads are HTTP GET actions, because reading data involves getting events from streams. The base reading URI from a single stream is as follows: api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. Bulk reads SDS supports reading from multiple streams in one request using the following method: Join Values retrieves a collection of events across multiple streams and joins the results based on the request parameters. Multi-stream reads can be either HTTP GET or HTTP POST actions. The base reading URI for reading from multiple streams is the following: api/v1/Tenants/default/Namespaces/{namespaceId}/Bulk/Streams/Data api v1 Tenants default Namespaces {namespaceId} Bulk Streams Data Parameters string namespaceId The namespace; either default or diagnostics. Indexes and reading data Most read operations take at least one index as a parameter. Indexes may be specified as strings. For additional details about working with indexes, see Indexes ."
                                  },
    "V1/SDS/indexes_1-0.html":  {
                                    "href":  "V1/SDS/indexes_1-0.html",
                                    "title":  "Indexes",
                                    "keywords":  "Indexes Indexes speed up and order the results of searches. A key uniquely identifies a record within a collection of records. In SDS, the key of an SdsType is also an index. The key is often referred to as the primary index , while all other indexes are referred to as secondary indexes or secondaries . An SdsType that is used to define an SdsStream must specify a key. When inserting data into an SdsStream, every key value must be unique. SDS will not store more than a single event for a given key. An event with a particular key may be deleted or updated, but two events with the same key cannot exist. Secondary indexes are defined on SdsStreams and applied to a single property. You can define many secondary indexes and the values do not need to be unique. The following table contains supported index types: Type SdsTypeCode Boolean 3 Byte 6 Char 4 DateTime 16 DateTimeOffset 20 Decimal 15 Double 14 Guid 19 Int16 7 Int32 9 Int64 11 SByte 5 Single 13 String 18 TimeSpan 21 UInt16 8 UInt32 10 UInt64 12"
                                },
    "V1/OpcUa/PrinciplesOfOperationOPCUA_1-0.html":  {
                                                         "href":  "V1/OpcUa/PrinciplesOfOperationOPCUA_1-0.html",
                                                         "title":  "Operational overview",
                                                         "keywords":  "Operational overview The OPC UA EDS adapter conforms to the OPC UA specification for operation. Once an instance of the adapter is defined in the system components configuration, it must be configured for it to create streams and collect data. Adapter configuration For an OPC UA EDS adapter instance to start data collection, configure the adapter by defining the following: Data source: Provide the connection information for the OPC UA data source. Data selection: Specify the OPC UA items to which the adapter instance should subscribe for data. Logging: Set up the logging behavior for the adapter instance. For more information, see Data source configuration and Data selection configuration . For more information on how to configure logging, see Component-level logging configuration . Connection The OPC UA EDS adapter uses the binary opc.tcp protocol to communicate with the OPC UA servers. A secured connection is enabled by default where the X.509-type client and server certificates are exchanged and verified and the connection between the OPC UA EDS adapter and the configured OPC UA server is established. Stream creation The OPC UA EDS adapter creates types upon receiving the value update for a stream. One stream is created in Edge Data Store for every selected OPC UA item in the data selection configuration. Data collection The OPC UA EDS adapter collects time-series data from selected OPC UA dynamic variables through OPC UA subscriptions (unsolicited reads). The adapter supports the Data Access (DA) part of OPC UA specification. Stream properties The OPC UA EDS adapter creates a stream with two properties per selected OPC UA item. The properties are described in the following table: Property name Data type Description Timestamp DateTime Timestamp of the given OPC UA item value update. Value Based on type of incoming OPC UA value Value of the given OPC UA item update. Stream ID is a unique identifier for each stream created by the adapter for a given OPC UA item. If the Custom Stream ID is specified for the OPC UA item in data selection configuration, the OPC UA EDS adapter uses that as a stream ID for the stream. Otherwise, the adapter constructs the stream ID using the following format constructed from the OPC UA item node ID: \u003cAdapter Component ID\u003e.\u003cNamespace\u003e.\u003cIdentifier\u003e Note: The naming convention is affected by StreamIdPrefix and ApplyPrefixToStreamID settings in data source configuration. For more information, see Data source configuration . Export operation The OPC UA EDS adapter is able to export available OPC UA dynamic variables by browsing the OPC UA hierarchies or sub-hierarchies as part of the data source configuration process. For more information, see Data source configuration . Buffering Because the OPC UA EDS adapter sends data directly to EDS, buffering capability is not provided. EDS acts as a buffer before the data is egressed to either a PI Server or OCS. The amount of data stored in EDS is controlled by the following storage parameters: StreamStorageLimitMb StreamStorageTargetMb For more information about configuring data storage in EDS, see Storage runtime configuration ."
                                                     },
    "V1/OpcUa/OpcUaOverview_1-0.html":  {
                                            "href":  "V1/OpcUa/OpcUaOverview_1-0.html",
                                            "title":  "OPC UA EDS adapter",
                                            "keywords":  "OPC UA EDS adapter Overview The OPC UA EDS adapter is a component of Edge Data Store that transfers time-series data from an OPC UA capable device to EDS. OPC Unified Architecture (OPC UA) is a machine to machine communication protocol for industrial automation developed by the OPC Foundation. The OPC UA EDS adapter can connect to any device that uses the OPC UA communication protocol, and uses subscriptions to reduce the amount of data transferred by only reading data changes and events. The following diagram depicts the data flow for a single instance of OPC UA EDS adapter instance: The adapter instance polls the OPC UA device and then collects data from the device. The adapter then sends the data to the storage component where it is held until it can be egressed to permanent storage in PI Server or OSIsoft Cloud Services. The adapter instance can be configured from the device where EDS is installed, and EDS collects health information about the adapter that can be egressed. The OPC UA EDS adapter can connect to multiple devices by defining one instance of the adapter for each device. The EDS installation includes the OPC UA EDS adapter and the option to add a single OPC UA EDS adapter instance. Add additional instances after installation using system components configuration. Once an adapter instance is defined, manually configure it with JSON documents that specify the following: Data source configuration - identifies the device from which the data originates, specifies the security for the connection, and controls how the data streams from that device identified. Each adapter component instance requires a data source configuration. Data selection configuration - specifies what data is collected from the device and how it is identified. Each adapter component instance requires a data selection configuration. With these configurations completed, the OPC UA EDS adapter instance collects data from the specified device and sends it to EDS, where it is stored locally until it can be sent to a PI System or OSIsoft Cloud Services for long-term storage and analysis."
                                        },
    "V1/OpcUa/OPCUADataSourceConfiguration_1-0.html":  {
                                                           "href":  "V1/OpcUa/OPCUADataSourceConfiguration_1-0.html",
                                                           "title":  "Data source configuration",
                                                           "keywords":  "Data source configuration For each instance of the OPC UA EDS adapter defined in system configuration, you must configure the data source from which it will receive data. Configure OPC UA data source Note: OPC UA data source configurations cannot be modified manually. You must use the REST endpoints to add or edit the configuration. Complete the following steps to configure the OPC UA data source: Using any text editor, create a file that contains an OPC UA data source in JSON form. For content structure, see OPC UA data source example . Modify the parameters in the example to match your environment. For a table of all available parameters, see Parameters for OPC UA data source . Save the file to the device with EDS installed using a file name based on the adapter instance name. For example, to use the adapter instance created during installation, which is OpcUa1, name the file OpcUa1Datasource.json . Use any tool capable of making HTTP requests to execute a POST command with the contents of that file to the following endpoint: http://localhost:\u003cport_number\u003e/api/v1/configuration/\u003cEDS_adapterId\u003e/DataSource/ http:  localhost:\u003cport_number\u003e api v1 configuration \u003cEDS_adapterId\u003e DataSource  . The following example shows the HTTPS request using curl, which must be run from the same directory where the file is located, and uses the adapter instance created during installation, which is OpcUa1: curl -d \"@OpcUa1DataSource.config.json\" -H \"Content-Type: application/json\" application json\" \"http://localhost:5590/api/v1/configuration/OpcUa1/DataSource\" \"http:  localhost:5590 api v1 configuration OpcUa1 DataSource\" Note: After completing data source configuration, the next step is to configure data selection. You can either generate a default data selection file or create the data selection file manually. For more information, see Data selection configuration . Export OPC UA dynamic variables The OPC UA EDS adapter is able to export available OPC UA dynamic variables by browsing the OPC UA hierarchies or sub-hierarchies as part of the data source configuration process. To limit browsing, specify a comma-separated collection of nodeIds in data source configuration file using the RootNodeIds parameter. Note: The nodeIds are treated as roots from which the adapter starts the browse operation. The adapter triggers an export operation after a successful connection to the OPC UA server when the data selection file does not exist in configuration directory. Copy the exported data selection JSON file from the directory or retrieve it using a REST API call. Optional: To avoid a potentially long and resource-intensive browse operation, create the data selection file manually. Configure it before you configure the data source or push both in one configuration call together. Parameters for OPC UA data source The following parameters can be used to configure an OPC UA data source: Parameter Required Type Nullable Description EndpointURL Required string Yes The endpoint URL of the OPC UA server. The following is an example of the URL format: opc.tcp://OPCServerHost:Port/OpcUa/SimulationServer opc.tcp:  OPCServerHost:Port OpcUa SimulationServer Note: If you change the EndpointURL on a configured OPC UA EDS adapter instance that has ComponentID_DataSelection.json file exported, remove the ComponentID_DataSelection.json file from the configuration directory to trigger a new browse (export). UseSecureConnection Optional Boolean No When set to true, the OPC UA EDS adapter connects to a secure endpoint using OPC UA certificate exchange operation. The default is true. When set to false, the OPC UA EDS adapter connects to an unsecured endpoint of the server and certificate exchange operation is not required. Note: OSIsoft recommends setting this option to false for testing purposes only. For more information on how to configure security, see Adapter security . UserName Optional string Yes User name for accessing the OPC UA server. Password Optional string Yes Password for accessing the OPC UA server. Note: OSIsoft recommends using REST to configure the data source when the password must be specified. RootNodeIds Optional string Yes List of comma-separated NodeIds of those objects from which the OPC UA EDS adapter browses the OPC UA server address space. This option allows selecting only subsets of the OPC UA address by explicitly listing one or more NodeIds which are used to start the initial browse. For example: ns=5;s=85/0:Simulation, ns=5;s=85 0:Simulation, ns=3;s=DataItems. If not specified, the whole address space will be browsed. IncomingTimestamp Optional string No Specifies whether the incoming timestamp is taken from the source, from the OPC UA server, or created by the OPC UA EDS adapter. Valid values are Source , Server , and Adapter . Source - Default and recommended setting. The timestamp is taken from the source timestamp field. The source is what provides data for the item to the OPC UA server, such as a field device. Server - In case the OPC UA item has an invalid source timestamp field, the Server timestamp can be used. Adapter - The OPC UA EDS adapter generates a timestamp for the item upon receiving it from the OPC UA server. StreamIdPrefix Optional string Yes Specifies the prefix used for Stream IDs. Naming convention is StreamIdPrefixNodeId. Note: An empty string means no prefix is added to the Stream IDs. Null value means ComponentID followed by dot character will be added to the stream IDs (for example, OpcUa1.NodeId). ApplyPrefixToStreamId Optional Boolean No Parameter applied to all data items collected from the data source that have custom stream ID configured. If configured, the adapter will apply the StreamIdPrefix parameter to all the streams with custom ID configured. The property does not affect any streams with default ID configured. OPC UA data source example The following is an example of valid OPC UA data source configuration: { \"EndpointUrl\": \"opc.tcp://IP-Address/TestOPCUAServer\", \"opc.tcp:  IP-Address TestOPCUAServer\", \"UseSecureConnection\": true, \"UserName\": null, \"Password\": null, \"RootNodeIds\": null, \"IncomingTimestamp\": \"Source\", \"StreamIdPrefix\": null }"
                                                       },
    "V1/OpcUa/OpcUaDataSelection_1-0.html":  {
                                                 "href":  "V1/OpcUa/OpcUaDataSelection_1-0.html",
                                                 "title":  "Generate default OPC UA data selection configuration file",
                                                 "keywords":  "Generate default OPC UA data selection configuration file When you add a data source, the OPC UA EDS adapter browses the entire OPC UA server address space and exports the available OPC UA variables into a JSON file for data selection. Data is collected automatically based upon user demands. OPC UA data from OPC UA variables is read through subscriptions (unsolicited reads). A default OPC UA data selection file will be created if there is no OPC UA data selection configuration, but a valid OPC UA data source exists. Note: To avoid possibly expensive browse operations, OSIsoft recommends that you manually create a data selection file instead of generating the default data selection file. For more information, see Data selection configuration . Complete the following steps in order for this default data selection file to be generated: Add an OPC UA EDS adapter with a unique ComponentId. During the installation of Edge Data Store, enabling the OPC UA EDS adapter results in addition of a unique component that also satisfies this condition. Configure a valid OPC UA data source . Once you complete these steps, a default OPC UA data selection configuration file will be generated in the configuration directory for the corresponding platform. The following are example locations of the file created. In this example, it is assumed that the ComponentId of the OPC UA component is the default OpcUa1: Windows: %programdata%\\OSIsoft\\EdgeDataStore\\Configuration\\OpcUa1_DataSelection.json Linux: /usr/share/OSIsoft/EdgeDataStore/Configuration/OpcUa1_DataSelection.json  usr share OSIsoft EdgeDataStore Configuration OpcUa1_DataSelection.json Copy the file to a different directory. The contents of the file will look something like: [ { \"Selected\": false, \"Name\": \"Cold Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.ColdSideInletTemperature\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Cold Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.ColdSideOutletTemperature\", \"StreamId\": null } ] In a text editor, edit the file and change the value of any Selected key from false to true in order to transfer the OPC UA data to be stored in Edge Data Store. In the same directory where you edited the file, run the following curl command: curl -i -d \"@OpcUa1_DataSelection.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/OpcUa1/Dataselection http:  localhost:5590 api v1 configuration OpcUa1 Dataselection"
                                             },
    "V1/Administration/Stop and start an EDS adapter_1-0.html":  {
                                                                     "href":  "V1/Administration/Stop and start an EDS adapter_1-0.html",
                                                                     "title":  "Stop and start an EDS adapter",
                                                                     "keywords":  "Stop and start an EDS adapter By default, when Edge Data Store starts, all currently configured EDS adapter instance are started and remain running until the product shuts down. Stop an EDS adapter Complete the following steps to stop an EDS adapter instance: Open a tool capable of making HTTP requests. Run a POST command to the following endpoint, replacing \u003cadapterId\u003e with the adapter instance to stop and \u003cport_number\u003e with the port specified for EDS: http://localhost:\u003cport_number\u003e/api/v1/administration/\u003cadapterId\u003e/Stop http:  localhost:\u003cport_number\u003e api v1 administration \u003cadapterId\u003e Stop Example Stop the OpcUa1 adapter using curl and the default port: curl -d \"\" http://localhost:5590/api/v1/Administration/OpcUa1/Stop http:  localhost:5590 api v1 Administration OpcUa1 Stop An HTTP status 204 message indicates success. Start an EDS adapter Complete the following steps to start an EDS adapter instance: Open a tool capable of making HTTP requests. Run a POST command to the following endpoint, replacing \u003cadapterId\u003e with the adapter instance to start and \u003cport_number\u003e with the port specified for EDS: http://localhost:\u003cport_number\u003e/api/v1/administration/\u003cadapterId\u003e/Start http:  localhost:\u003cport_number\u003e api v1 administration \u003cadapterId\u003e Start Example Stop the Modbus1 adapter using curl and the default port: curl -d \"\" http://localhost:5590/api/v1/Administration/Modbus1/Start http:  localhost:5590 api v1 Administration Modbus1 Start An HTTP status 204 message indicates success."
                                                                 },
    "V1/Administration/Reset the Storage component_1-0.html":  {
                                                                   "href":  "V1/Administration/Reset the Storage component_1-0.html",
                                                                   "title":  "Reset the Storage component",
                                                                   "keywords":  "Reset the Storage component When applied at the storage component level, the Reset command deletes all event and configuration data related to the Storage component and restarts Edge Data Store. Complete the following steps to reset the Storage component: Open a tool capable of making HTTP requests. Run a POST command to the following endpoint, replacing \u003cport_number\u003e with the port specified for EDS: http://localhost:\u003cport_number\u003e/api/v1/administration/Storage/Reset http:  localhost:\u003cport_number\u003e api v1 administration Storage Reset Example using curl and the default port: curl -d \"\" http://localhost:5590/api/v1/Administration/Storage/Reset http:  localhost:5590 api v1 Administration Storage Reset An HTTP status 204 message indicates success."
                                                               },
    "V1/Administration/ManagementTools_1-0.html":  {
                                                       "href":  "V1/Administration/ManagementTools_1-0.html",
                                                       "title":  "Configuration tools",
                                                       "keywords":  "Configuration tools Edge Data Store and adapters can be configured with either the EdgeCmd utility, OSIsoft\u0027s proprietary tool for configuring EDS and adapters, or commonly-used REST tools. EdgeCmd utility The EdgeCmd utility enables EDS and adapter configuration on both Linux and Windows operating systems. For more information on using the EdgeCmd utility, see the EdgeCmd utility help . REST tools The following tools can be used to make REST calls. curl curl is a command line tool used to make HTTP calls and is supported on both Windows and Linux operating systems. curl can be scripted using Bash or PowerShell on either Linux or Windows, and can be used to perform EDS administrative and programming tasks. curl commands are used in configuration and management examples throughout this documentation. Postman In instances where EDS is installed on a platform with a GUI component, Postman is a useful REST tool for learning more about EDS REST APIs and creating REST calls. C#, Python, Go EDS is designed to use platform-independent programming, and any modern programming language can be used to make REST calls to administer and write programs for EDS. Since the administrative and programming interfaces use REST, applications can manage EDS and read and write data. For example, an application can access the Diagnostics namespace locally to monitor and act upon the local system state. System Tools Use Windows tools like PuTTY and WinSCP to facilitate working across platforms, such as to copy files and remotely access Linux command lines."
                                                   },
    "V1/index.html":  {
                          "href":  "V1/index.html",
                          "title":  "Edge Data Store",
                          "keywords":  "Edge Data Store Edge Data Store (EDS) is a lightweight data collection and storage application designed to capture data at the edge of networks for historical storage and analysis. It runs on small, rugged devices or embedded in existing industrial hardware, and is designed to be resilient and require minimal installation and administration. While not a replacement for a PI System or OSIsoft Cloud Services (OCS), EDS augments the PI System and OCS by collecting and storing data in situations where deploying a full system is impractical. It can collect data that is beyond the reach of automation systems, in unreliable network conditions, and in environments too rough for traditional computers. Edge Data Store can run almost anywhere you can install a sensor, such as beam pumps, mining trucks, wind mills, etc. The following diagram shows conceptually how EDS captures data and sends to permanent storage: EDS collects data using any of the following methods: Built-in OPC UA connectivity Built-in Modbus TCP connectivity Custom application using OSIsoft Message Format (OMF) Custom application using REST API Once collected, the data is stored locally in configurable data storage within EDS, until it can be sent to permanent storage in a PI System or in OSIsoft Cloud Services through periodic egress. The data can also be read from local storage by custom applications using REST APIs. Edge Data Store architecture EDS runs on both Linux and Windows platforms and is comprised of separate components that each perform a specific function within EDS. The following diagram shows Edge Data Store architecture with all of its components and how the data flow through those components: EDS components are shown in grey within the Edge Data Store in the diagram: Modbus TCP EDS adapter ??? Collects data from Modbus TCP devices and writes it to data storage OPC UA EDS adapter ??? Collects data from OPC UA devices and writes it to data storage Data Storage ??? Stores data locally until it can be egressed Data egress ??? Sends data from storage to PI Server or OSIsoft Cloud Services Health ??? Records health information of components and sends it to PI Server or OSIsoft Cloud Services Blue boxes in the diagram show ways to interact with EDS from the local device: OMF REST ??? Use OSIsoft Message Format to write data to the data storage component programmatically SDS REST APIs ??? Use SDS REST APIs to read data from and write data to the data storage component programmatically Configuration ??? Use REST or the EdgeCmd tool to configure EDS as a whole or each component individually and to view the current configuration EDS requires an endpoint to connect to REST APIs on the local device, which is shown outlined in blue in the diagram. By default, the endpoint uses port 5590; however, it can be configured to use another port. Orange arrows show data flowing into EDS and blue arrows show data flowing out of EDS. For detailed information about configuring each component of EDS, see Configuration \u003c!-- # OSIsoft Edge Data Store ======= - [Overview](xref:EdgeDataStoreOverview1-0) - [Design considerations](xref:scalePerformance1-0) - [Security](xref:security1-0) - [Quick start guides](xref:QuickStartGuides1-0) - [OPC UA EDS adapter quick start](xref:opcUaQuickStart1-0) - [Modbus TCP adapter quick start](xref:modbusQuickStart1-0) - [OMF quick start](xref:omfQuickStart1-0) - [OCS egress quick start](xref:ocsEgressQuickStart1-0) - [PI egress quick start](xref:piEgressQuickStart1-0) - [SDS Read/Write Read Write quick start](xref:sdsQuickStart1-0) - [Command line quick start - Linux](xref:commandLineLinuxQuickStart1-0) - [Command line quick start - Windows](xref:commandLineWindowsQuickStart1-0) - [Installation](xref:installationOverview1-0) - [System requirements](xref:SystemRequirements1-0) - [Linux and Windows platform differences](xref:linuxWindows1-0) - [Install Edge Data Store](xref:InstallEdgeDataStore1-0) - [Docker](xref:edgeDocker1-0) - [Verify installation](xref:VerifyInstallation1-0) - [Uninstall Edge Data Store](xref:UninstallEdgeDataStore1-0) - [Configuration](xref:Configuration1-0) - [Configuration tools](xref:ConfigurationTools1-0) - [System configuration](xref:SystemConfiguration1-0) - [System components configuration](xref:SystemComponentsConfiguration1-0) - [System port configuration](xref:SystemPortConfiguration1-0) - [Edge Data Store configuration](xref:EdgeDataStoreConfiguration1-0) - [Data ingress configuration](xref:EDSDataIngress1-0) - [OPC UA EDS adapter](xref:opcUaOverview1-0) - [Supported features](xref:SupportedFeaturesOPCUA1-0) - [Principles of operation](xref:PrinciplesOfOperationOPCUA1-0) - [Data source configuration](xref:OPCUADataSourceConfiguration1-0) - [Data selection configuration](xref:OPCUADataSelectionConfiguration1-0) - [Adapter security](xref:OPCUAAdapterSecurityConfiguration1-0) - [Modbus TCP EDS adapter](xref:modbusOverview1-0) - [Supported features](xref:SupportedFeaturesModbus1-0) - [Principles of operation](xref:PrinciplesOfOperationModbus1-0) - [Data source configuration](xref:ModbusTCPDataSourceConfiguration1-0) - [Data selection configuration](xref:ModbusTCPDataSelectionConfiguration1-0) - [OSIsoft Message Format (OMF)](xref:omfOverview1-0) - [Storage](xref:storage1-0) - [Storage runtime configuration](xref:storageruntime1-0) - [Data egress configuration](xref:egress1-0) - [Prepare egress destinations](xref:PrepareEgressDestinations1-0) - [Egress execution details](xref:EgressExecutionDetails1-0) - [Diagnostics configuration](xref:EdgeDataStoreDiagnostics1-0) - [Health endpoints configuration](xref:HealthEndpointsConfiguration1-0) - [Logging configuration](xref:LoggingConfig1-0) - [Administration](xref:EdgeDataStoreAdministration1-0) - [Retrieve product version information](xref:RetrieveProductVersionInformation1-0) - [Reset Edge Data Store](xref:ResetEdgeDataStore1-0) - [Reset the Storage component](xref:ResetTheStorageComponent1-0) - [Stop and start an EDS adapter](xref:StopAndStartAnEDSAdapter1-0) - [Troubleshoot Edge Data Store](xref:troubleShooting1-0) - [Disaster recovery](xref:disasterRecovery1-0) - [Reference](xref:Reference1-0) - [Sequential Data Store (SDS)](xref:sdsOverview1-0) - [Types](xref:sdsTypes1-0) - [Streams](xref:sdsStreams1-0) - [Stream views](xref:sdsStreamViews1-0) - [Indexes](xref:sdsIndexes1-0) - [Writing data](xref:sdsWritingData1-0) - [API calls for writing data](xref:sdsWritingDataApi1-0) - [Reading Data](xref:sdsReadingData1-0) - [API calls for reading data](xref:sdsReadingDataApi1-0) - [Filter expressions](xref:sdsFilterExpressions1-0) - [Table format](xref:sdsTableFormat1-0) - [Units of measure](xref:unitsOfMeasure1-0) - [Compression](xref:sdsCompression1-0) - [Searching](xref:sdsSearching1-0) - [EdgeCmd commands](xref:EdgecmdCommands1-0) - [Release notes](xref:releaseNotes1-0) - [Technical support and feedback](xref:Feedback1-0) --\u003e"
                      },
    "V1/Modbus/ModbusTCPDataSourceConfiguration_1-0.html":  {
                                                                "href":  "V1/Modbus/ModbusTCPDataSourceConfiguration_1-0.html",
                                                                "title":  "Data source configuration",
                                                                "keywords":  "Data source configuration For each instance of the Modbus TCP EDS adapter defined in system configuration, you must configure the data source from which it will poll data. Configure Modbus TCP data source Note: Modbus TCP data source configurations cannot be modified manually. You must use the REST endpoints to add or edit the configuration. Complete the following steps to configure the Modbus TCP data source: Using any text editor, create a file that contains a Modbus TCP data source in JSON form. For content structure, see Modbus TCP data source examples . Modify the parameters in the example to match your environment. For a table of all available parameters, see Parameters for Modbus TCP data source . Save the file to the device with EDS installed using a file name based on the adapter instance name. For example, to use the adapter instance created during installation, which is Modbus1, name the file Modbus1Datasource.json . Use any tool capable of making HTTP requests to execute a POST command with the contents of that file to the following endpoint: http://localhost:\u003cport_number\u003e/api/v1/configuration/\u003cEDS http:  localhost:\u003cport_number\u003e api v1 configuration \u003cEDS adapterId\u003e/DataSource/ adapterId\u003e DataSource  . The following example shows the HTTPS request using curl, which must be run from the same directory where the file is located, and uses the adapter instance created during installation, which is Modbus1: curl -v -d \"@Modbus1DataSource.config.json\" -H \"Content-Type: application/json\" application json\" \"http://localhost:5590/api/v1/configuration/Modbus1/DataSource\" \"http:  localhost:5590 api v1 configuration Modbus1 DataSource\" Parameters for Modbus TCP data source The following parameters are available for configuring a Modbus TCP data source. Parameter Required Type Nullable Description IpAddress Required string Yes The IP address of the device from which the data is to be collected using the Modbus TCP protocol. Host name is not supported. Port Optional number No The TCP port of the target device that listens for and responds to Modbus TCP requests. The value ranges from 0 to 65535. If not configured, the default TCP port is 502 (which is the default port for Modbus TCP protocol). StreamIdPrefix Optional number Yes Parameter applied to all data items collected from the data source. If not configured, the default value is the ID of the Modbus TCP EDS adapter. The custom StreamIdPrefix has the highest priority. ApplyPrefixToStreamId Optional Boolean No Parameter applied to all data items collected from the data source that have custom stream ID configured. If configured, the adapter will apply the StreamIdPrefix property to all the streams with custom ID configured. The property does not affect any streams with default ID configured ConnectTimeout Optional number No Parameter to specify the time (in milliseconds) to wait when Modbus TCP EDS adapter is trying to connect to the data source. The value ranges from 1000 ms to 30000 ms. The default value is 5000 ms. ReconnectInterval Optional number No Parameter to specify the time (in milliseconds) to wait before retrying to connect to the data source when the data source is offline. The value ranges from 100 ms to 30000 ms. The default value is 1000 ms. RequestTimeout Optional number No Parameter to specify the time (in milliseconds) that Modbus TCP EDS adapter waits for a pending request before marking it as timeout and dropping the request. The default value is 10000 ms. The value must be a positive integer, there is no value range. DelayBetweenRequests Optional number No Parameter to specify the minimum time (in milliseconds) between two successive requests sent to the data source. The value ranges from 0 ms to 1000 ms. The default value is 0 ms. MaxResponseDataLength Optional number No Parameter to limit the maximum length (in bytes) of data that can be read within one transaction. This feature is provided to support devices that limit the number of bytes that can be returned. If there is no device limitation, the request length should be the maximum length of 250 bytes. The value ranges from 2 to 250. The default value is 250 ms. Modbus TCP data source examples The following are examples of valid Modbus TCP data source configurations. Minimum data source configuration: { \"IpAddress\": \"127.0.0.2\" } Maximum data source configuration: { \"IpAddress\": \"127.0.0.4\", \"Port\": 502, \"StreamIdPrefix\": \"my.prefix\", \"ApplyPrefixToStreamId\": true, \"ConnectTimeout\": 5000, \"ReconnectInterval\": 1000, \"RequestTimeout\": 10000, \"DelayBetweenRequests\": 500, \"MaxResponseDataLength\": 125 }"
                                                            },
    "V1/Modbus/ModbusTCPDataSelectionConfiguration_1-0.html":  {
                                                                   "href":  "V1/Modbus/ModbusTCPDataSelectionConfiguration_1-0.html",
                                                                   "title":  "Data selection configuration",
                                                                   "keywords":  "Data selection configuration Once a data source is configured for a Modbus TCP instance, create a data selection configuration file to specify the data for the Modbus TCP EDS adapter instance to collect from the data source. Configure Modbus TCP data selection Complete the following to configure Modbus TCP data selection: Using any text editor, create a file that contains a Modbus TCP data selection in JSON form. For content structure, see Modbus TCP data selection examples . Update the parameters as needed. For a table of all available parameters, see Parameters for Modbus TCP data selection . Save the file to the device with EDS installed with the name DataSelection.config.json . Use any tool capable of making HTTP requests to execute a POST command with the contents of that file to the following endpoint: http://localhost:\u003cport_number\u003e/api/v1/configuration/\u003cEDS http:  localhost:\u003cport_number\u003e api v1 configuration \u003cEDS adapterId\u003e/DataSelection/ adapterId\u003e DataSelection  . The following example shows the HTTPS request using curl, which must be run from the same directory where the file is located, and uses the adapter instance created during installation, which is Modbus1: curl -v -d \"@DataSelection.config.json\" -H \"Content-Type: application/json\" application json\" \"http://localhost:5590/api/v1/configuration/Modbus1/DataSelection\" \"http:  localhost:5590 api v1 configuration Modbus1 DataSelection\" To see the streams that have been created in EDS storage for the data specified in the configuration, run the following curl script: curl http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/ http:  localhost:5590 api v1 tenants default namespaces default streams  Parameters for Modbus TCP data selection The following parameters are available for configuring Modbus TCP data selection. Parameter Required Type Nullable Description Id Optional string Yes Used to update an existing measurement. The ID automatically updates when there are changes to the measurement and will follow the format of \u003cUnitId \u003e. \u003cRegisterType \u003e. \u003cRegisterOffset \u003e. Selected Optional Boolean No Used to select or clear a measurement. To select an item, set to true. To remove an item, leave the field empty or set to false. If not configured, the default value is true. Name Optional string Yes The optional friendly name of the data item collected from the data source. If not configured, the default value will be the stream ID. UnitId Required number No Modbus TCP slave device unit ID. This must be a value between 0 and 247, inclusively. RegisterType Required number or string No Modbus TCP register type. Supported types are Coil, Discrete, Input16, Input32, Holding16 and Holding32. Input16 and Holding16 are used to read registers that have a size of 16 bits. For registers that have a size of 32 bits, use the Input32 and Holding32 register types. To represent the types, type the register type ID or the exact name: 1 or Coil (Read Coil Status) 2 or Discrete (Read Discrete Input Status) 3 or Holding16 (Read 16-bit Holding Registers) 4 or Holding32 (Read 32-bit Holding Registers) 6 or Input16 (Read 16-bit Input Registers) 7 or Input32 (Read 32-bit Input Registers) RegisterOffset Required number No The 0 relative offset to the starting register for this measurement. For example, if the Holding registers start at base register 40001, the offset to this register is 0. For 40002, the offset to this register is 1. DataTypeCode Required number No Represents the data type that Modbus TCP EDS adapter will read starting at the register specified by the offset. Supported data types are: 1 = Boolean 10 = Int16 20 = UInt16 30 = Int32 31 = Int32ByteSwap 100 = Float32 101 = Float32ByteSwap 110 = Float64 111 = Float64ByteSwap 1001 - 1250 = String 2001 - 2250 = StringByteSwap ScanRate Required number No Defines how often this measurement is read from the device in milliseconds. Acceptable values are from 0 to 86400000. If 0 ms is specified, Modbus TCP EDS adapter will scan for data as fast as possible. BitMap Optional string Yes Bitmap used to extract and reorder bits from a word register. The format of the bitmap is uuvvwwxxyyzz, where uu, vv, ww, yy, and zz each refer to a single bit. A leading zero is required if the referenced bit is less than 10. The low-order bit is 01 and high-order bit is either 16 or 32. Up to 16 bits can be referenced for a 16-bit word (data types 10 and 20) and up to 32 bits can be referenced for a 32-bit word (data type 30 and 31). The bitmap 0307120802 will map the second bit of the original word to the first bit of the new word, the eighth bit to the second bit, the twelfth bit to the third bit, and so on. The high-order bits of the new word are padded with zeros if they are not specified. ConversionFactor Optional number Yes Used to scale the raw response received from the Modbus TCP device. If this is specified, regardless of the specified data type, the value will be promoted to a float32 (single) when stored. [Result = (Value /   Conversion Factor)] ConversionOffset Optional number Yes Used to apply an offset to the response received from the Modbus TCP device. If this is specified, regardless of the specified data type, the value will be promoted to a float32 (single) when stored. [Result = (Value - Conversion Offset)] StreamID Optional string Yes The custom stream ID that will be used to create the streams. If not specified, the Modbus TCP EDS adapter will generate a default stream ID based on the measurement configuration. A properly configured custom stream ID follows these rules: Is not case-sensitive. Can contain spaces. Cannot start with two underscores (\"__\"). Can contain a maximum of 100 characters. Cannot use the following characters: /   : ? # [ ] @ ! $ \u0026 \u0027 ( ) \\ * + , ; = % \u003c \u003e | Cannot start or end with a period. Cannot contain consecutive periods. Cannot consist of only periods. Each JSON object in the file represents a measurement. Add additional JSON objects in the file for each measurement to collect. Modify the fields in each object to configure the measurement parameters. Modbus TCP data selection examples The following are examples of valid Modbus TCP data selection configurations. Minimum data selection configuration: [ { \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 122, \"DataTypeCode\": 20, \"ScanRate\": 1000 } ] Maximum data selection configuration: [ { \"Id\": \"DataItem1\", \"Selected\": true, \"Name\": \"MyDataItem\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 123, \"DataTypeCode\": 20, \"ScanRate\": 300, \"StreamId\": \"stream.1\", \"BitMap\": \"020301\", \"ConversionFactor\": 12.3, \"ConversionOffset\": 14.5 } ]"
                                                               },
    "V1/Modbus/ModbusOverview_1-0.html":  {
                                              "href":  "V1/Modbus/ModbusOverview_1-0.html",
                                              "title":  "Modbus TCP EDS adapter",
                                              "keywords":  "Modbus TCP EDS adapter Overview The Modbus TCP EDS adapter is a component of Edge Data Store that transfers time-series data from a device to EDS. Modbus TCP is a commonly available communication protocol used for connecting and transmitting information between industrial electronic devices. The Modbus TCP EDS adapter can communicate with any device conforming to the Modbus TCP/IP TCP IP protocol through a gateway or router; devices and routers do not need to be on the same subnet as Edge Data Store. The following diagram depicts the data flow of a single instance of Modbus TCP EDS adapter: The adapter instance requests data from the Modbus TCP device and then the device sends its data. The adapter sends the collected data to the storage component where it is held until it can be egressed to permanent storage in PI Server or OSIsoft Cloud Services. The adapter instance can be configured from the device where EDS is installed, and EDS collects health information about the adapter that can be egressed. The Modbus TCP EDS adapter can connect to multiple devices by defining one instance of the adapter for each device. The EDS installation includes the Modbus TCP EDS adapter and the option to add a single Modbus TCP EDS adapter instance. Add additional instances after installation using system components configuration. Once an adapter instance is defined, manually configure it with JSON documents that specify the following: Data source configuration - identifies the device from which the data originates, specifies the security for the connection, and controls how the data streams from that device identified. Each adapter component instance requires a data source configuration. Data selection configuration - specifies what data is collected from the device and how it is identified. Each adapter component instance requires a data selection configuration. With these configurations completed, the Modbus TCP EDS adapter polls devices to capture data, at the rate specified in the configuration and sends it to EDS, where it is stored locally until it can be sent to a PI System or OSIsoft Cloud Services for long-term storage and analysis."
                                          },
    "V1/Installation/Install Edge Data Store_1-0.html":  {
                                                             "href":  "V1/Installation/Install Edge Data Store_1-0.html",
                                                             "title":  "Install Edge Data Store",
                                                             "keywords":  "Install Edge Data Store Install Edge Data Store using an install kit, as described in this section, or using Docker containers. For more information on using Docker, see Install Edge Data Store using Docker . For a list of supported platforms and processors, see System requirements . The installation includes the OPC UA EDS adapter, the Modbus TCP EDS adapter, and the Sequential Data Store (SDS) storage. An OPC UA EDS adapter instance and a Modbus TCP EDS adapter instance can each be added during the installation. Additional instances can be added for each adapter after installation. For more information, see Data ingress configuration . The port assignment can be changed either during or after installation. For more information on how to change the port number after installation, see System port configuration . Windows (Windows 10 x64) You must have administrative privileges on the device to install EDS. Run the installation file directly to step through a wizard, or use the command line to run the installation, including silent installation. For instructions on verifying the EDS installation, see Verify installation . Download the install file Complete the following steps to download the Windows installation file: Download the Windows EdgeDataStore.msi file from the OSIsoft Customer portal (https://customers.osisoft.com/s/products) (https:  customers.osisoft.com s products) . **Note:** Customer login credentials are required to access the portal. Copy the EdgeDataStore.msi file to the file system of the device. Run the installation wizard Complete the following steps to install EDS on Windows using the installation wizard: To start the installer, double-click the EdgeDataStore.msi file in Windows Explorer. In the OSIsoft Edge Data Store Setup window, click Next . Optional: Change the installation folder and port number (default port is 5590). Note: OSIsoft recommends you use the default installation path. Valid values for the port number are in the range of 1024 to 65535 and only an unused port number should be entered. Optional: Add a system component for a Modbus TCP EDS adapter instance, an OPC UA EDS adapter instance, or both. Note: The Modus TCP EDS adapter and the OPC UA EDS adapter are both installed, regardless of whether system components are added. Additional system components can be added for each adapter after installation. Click Next \u003e Install . Click Finish . Run the installation from a command line Complete the following steps to install EDS on Windows from the command line: Open a command window, by running as an administrator, and change the working directory to the location of the EdgeDataStore.msi file. Enter the msiexec command and specify parameters to run the installation, using the following example as a guide. Msiexec /quiet  quiet /i  i EdgeDataStore.msi PORT=\"\u003cnumber\u003e\" INSTALLFOLDER=\"\u003cfile_path\u003e\" WIXUI_ENABLEMODBUS=\"1\" WIXUI_ENABLEOPCUA=\"1\" Parameters: /quiet  quiet ??? The installation runs in silent mode. /i  i ??? This is the install flag. PORT ??? Specify a port other than the default of 5590. If the \"quiet\" or \"no ui\" flag for msiexec is specified and the PORT value on the command line is not valid, the install will proceed with the default 5590 value. INSTALLFOLDER ??? Specify an alternate location for the binary components other than the default location of \"%PROGRAMFILES%\\OSISoft\\EdgeDataStore\". OSIsoft recommends you use the default installation path. WIXUI_ENABLEMODBUS ??? Add a system component to create a Modbus TCP EDS adapter instance. The value must be 1 for the component to be added. WIXUI_ENABLEOPCUA - Add a system component to create a OPC UA EDS adapter instance. The value must be 1, for the component to be added. Note: If you do not use a parameter, the default value for the parameter is used. Property names must be in all capital letters, for example, PORT. Linux You must have administrative privileges to install the software, for example root or sudo privilege, and the Linux OS must be up to date for the install to succeed. For instructions on how to verify the Edge Data Store installation, see Verify installation . Note: For devices using Ubuntu 20.04 or higher, install the libicu63 package prior to installing Edge Data Store. Download the distribution file Complete the following steps to download the appropriate file for your device: Download the Linux distribution file from the OSIsoft Customer portal (https://customers.osisoft.com/s/products) (https:  customers.osisoft.com s products) . **Note:** Customer login credentials are required to access the portal. Copy the Linux distribution file to the file system of the device. Install on a Linux device Complete the following steps to install EDS on Linux: Open a terminal window and change the working directory to the location of the distribution file. Run the apt install command for the distribution file appropriate to your operating system and processor. Debian 9 or later (Intel/AMD (Intel AMD 64-bit processors) sudo apt install ./EdgeDataStore_linux-x64.deb . EdgeDataStore_linux-x64.deb Debian 9 or later (ARM32, Raspberry PI 2,3,4: Raspbian, BeagleBone) sudo apt install ./EdgeDataStore_linux-arm.deb . EdgeDataStore_linux-arm.deb Debian 9 or later (Raspberry PI 3,4: Ubuntu ARM64 Server, Google Coral Dev Board, Nvidia Nano Jetson) sudo apt install ./EdgeDataStore_linux-arm64.deb . EdgeDataStore_linux-arm64.deb A validation check for prerequisites is performed. If the install fails, run the following commands from the terminal window and try the install again: sudo apt update sudo apt upgrade Optional: Change the port number (default port is 5590) and press Enter. Note: If you specify an invalid value for the port, the install will proceed with the default value of 5590. Optional: Add a system component for a Modbus TCP EDS adapter instance, an OPC UA EDS adapter instance, or both, and press Enter. Note: The Modus TCP EDS adapter and the OPC UA EDS adapter are both installed, regardless of whether system components are added. Additional system components can be added for each adapter after installation. Silent install on a Linux device Complete the following steps to perform a silent install EDS on Linux with all default options: Open a terminal window and change the working directory to the location of the distribution file. Run the apt-get install command for the distribution file appropriate to your operating system and processor. sudo apt-get install -q -y ./Edgeinstallfile.deb . Edgeinstallfile.deb \u003c /dev/null  dev null Parameters: -q ??? Specifies a silent install. -y ??? Responds Yes to installing prerequisites. Edgeinstallfile.deb ??? The name of the distribution file. \u003c /dev/null  dev null ??? All defaults are used in the installation. Silent install on a Linux device with specified parameters Complete the following steps to perform a silent install EDS on Linux using a parameter file to customize the installation: Create a file called silent.ini with the following parameters on separate lines: \u003cport_number\u003e \u003cY/N\u003e \u003cY N\u003e - Specifies whether to create a Modbus TCP EDS component. \u003cY/N\u003e \u003cY N\u003e - Specifies whether to create an OPCUA EDS component. For example: ``` 4567 Y N ``` Open a terminal window and change the working directory to the location of the distribution file. Run the apt-get install command for the distribution file appropriate to your operating system and processor. sudo apt-get install -q -y ./Edgeinstallfile.deb . Edgeinstallfile.deb \u003c silent.ini Parameters: -q ??? Specifies a silent install. -y ??? Responds Yes to installing prerequisites. Edgeinstallfile.deb ??? The name of the distribution file. \u003c silent.ini ??? The file with the installation properties."
                                                         },
    "V1/Egress/Prepare egress destinations_1-0.html":  {
                                                           "href":  "V1/Egress/Prepare egress destinations_1-0.html",
                                                           "title":  "Prepare egress destinations",
                                                           "keywords":  "Prepare egress destinations OCS and PI Server destinations may require additional configuration to receive OMF messages. OCS To prepare OCS to receive OMF messages from EDS, create an OMF connection in OCS. Creating an OMF connection results in an available OMF endpoint that can be used by the EDS egress mechanism. Complete the following steps to create an OMF connection: Create a Client . The Client Id and Client Secret will be used for the corresponding properties in the egress configuration. Create an OMF type Connection . The connection should link the created client to an existing namespace where the data will be stored. The OMF Endpoint URL for the connection will be used as the egress configuration Endpoint property. PI Server To prepare a PI Server to receive OMF messages from EDS, a PI Web API OMF endpoint must be available. Complete the following steps: Install PI Web API and enable the OSIsoft Message Format (OMF) Services feature. During configuration, choose an AF database and PI Data Archive where metadata and data will be stored. The account used in an egress configuration needs permissions to create AF elements, element templates, and PI points. Configure PI Web API to use Basic authentication. For complete steps, as well as best practices and recommendations, see the PI Web API User Guide on Live Library. Note: The certificate used by PI Web API must be trusted by the device running EDS, otherwise the egress configuration ValidateEndpointCertificate property needs to be set to false (this can be the case with a self-signed certificate but should only be used for testing purposes). Note: To continue to send OMF egress messages to the PI Web API endpoint after upgrading PI Web API, restart the EDS service."
                                                       },
    "V1/Egress/Egress_1-0.html":  {
                                      "href":  "V1/Egress/Egress_1-0.html",
                                      "title":  "Data egress configuration",
                                      "keywords":  "Data egress configuration Edge Data Store provides an egress mechanism to copy and transfer data through OMF to OSIsoft Cloud Services or a PI Server. For each egress destination, the destination needs to be prepared and an endpoint needs to be configured. Prepare egress destinations to ensure that OCS or PI Server are properly configured to receive OMF messages and record information needed to create a connection to the destination. Configure an egress endpoint to specify the connection information for a destination and the details of the data transfer. Each endpoint is independent of all other egress endpoints, and more than one endpoint for the same destination is allowed. Note: Only streams with a single, timeseries-based index can be egressed. For more information, see Egress execution details . Edge Data Store supports one tenant and two namespaces . The EDS tenant name is default , and the two namespaces are default and diagnostics . The default namespace is where adapter and OMF data is written. The diagnostics namespace is where performance and system information is written, which can be used locally or egressed to a remote PI server or OCS for monitoring. A separate egress definition is required for each namespace from which you want to egress data."
                                  },
    "V1/Egress/Configure data egress_1-0.html":  {
                                                     "href":  "V1/Egress/Configure data egress_1-0.html",
                                                     "title":  "Configure data egress",
                                                     "keywords":  "Configure data egress Once the OCS or PI Server destinations are prepared to receive OMF messages, configure data egress endpoints to create the connection to the destination and specify the details of the data transfer. Note: You cannot add egress configurations manually because some parameters are stored to disk encrypted. You must use the REST endpoints to add/edit add edit egress configuration. For additional endpoints, see REST URLs . Warning: If a periodic egress endpoint is deleted/removed deleted removed and then recreated with backfilling set to true, duplicate data will appear on any stream that was previously egressed successfully. New streams will not see duplicate data. Create egress endpoints Complete the following procedure to create new egress endpoints: Create a JSON file containing one or more egress endpoints. For content structure, see the following Examples . Update the parameters as needed. For a table of all available parameters, see Parameters . Save the JSON file with the name PeriodicEgressEndpoints.json to any directory on the device where Edge Data Store is installed. Use any tool capable of making HTTP requests to execute a POST command with the contents of that file to the following endpoint: http://localhost:5590/api/v1/configuration/storage/periodicegressendpoints/ http:  localhost:5590 api v1 configuration storage periodicegressendpoints  Example using cURL, which must be run from the directory where the JSON file is saved: curl -d \"@PeriodicEgressEndpoints.config.json\" -H \"Content-Type: application/json\" application json\" \"http://localhost:5590/api/v1/configuration/storage/periodicegressendpoints\" \"http:  localhost:5590 api v1 configuration storage periodicegressendpoints\" Note The @ symbol is a required prefix for the above command. Parameters Parameter Required Type Description Backfill Optional Boolean An indicator of whether data should be backfilled. Enabling the backfill flag will result in all data from the earliest index to the latest stored index being egressed. Backfilling occurs for each stream, including when a new stream is added. Once backfilling is complete for a stream, any out-of-order data is not egressed. Defaults to false. ClientId Required for OCS endpoint string Used for authentication with the OCS OMF endpoint. ClientSecret Required for OCS endpoint string Used for authentication with the OCS OMF endpoint. DebugExpiration Optional string Enables logging of detailed information, for each outbound HTTP request pertaining to this egress endpoint, to disk. The value represents the date and time this detailed information should stop being saved. Examples of valid strings representing date and time: UTC: \"yyyy-mm-ddThh:mm:ssZ\", Local: \"mm-dd-yyyy hh:mm:ss\". For more information, see Troubleshoot Edge Data Store . Description Optional string Friendly description EgressFilter Optional string A filter used to determine which streams and types are egressed. For more information on valid filters, see Search in SDS . Enabled Optional Boolean An indicator of whether egress is enabled when the egress endpoint is loaded. Defaults to true. Endpoint Required string Destination that accepts OMF v1.1 messages. Supported destinations include OCS and PI. ExecutionPeriod Required string Frequency of time between each egress action. Must be a string in the format d.hh:mm:ss.##. Id Optional string Unique identifier Name Optional string Friendly name NamespaceId Optional string Represents the namespace that will be egressed. There are two available namespaces: default and diagnostics. Default namespace is \"default\". Password Required for PI endpoint string Used for Basic authentication to the PI Web API OMF endpoint. StreamPrefix Optional string Prefix applied to any streams that are egressed. A null string or a string containing only empty spaces will be ignored. The following restricted characters are not allowed: /   : ? # [ ] @ ! $ \u0026 \u0027 ( ) \\ * + , ; = % TokenEndpoint Optional for OCS endpoint string Used to retrieve an OCS token from an alternative endpoint. This is not normally necessary with OCS. Only use if directed to do so by customer support . TypePrefix Optional string Prefix applied to any types that are egressed. A null string or a string containing only empty spaces will be ignored. The following restricted characters are not allowed: /   : ? # [ ] @ ! $ \u0026 \u0027 ( ) \\ * + , ; = % Username Required for PI endpoint string Used for Basic authentication to the PI Web API OMF endpoint. If domain is required, the backslash must be escaped (e.g., domain \\\\ username ). ValidateEndpointCertificate Optional Boolean Used to disable verification of destination certificate. Use for testing only with self-signed certificates. Defaults to true. Examples The following are valid egress configuration examples. Egress data to OCS. All streams, every 15 seconds. [{ \"Id\": \"OCS\", \"ExecutionPeriod\" : \"00:00:15\", \"Endpoint\" : \"https://{OcsLocation}/api/Tenants/{tenantId}/Namespaces/{namespaceId}/omf\", \"https:  {OcsLocation} api Tenants {tenantId} Namespaces {namespaceId} omf\", \"ClientId\" : \"{clientId}\", \"ClientSecret\" : \"{clientSecret}\" }] Egress data to OCS - streams with a specific TypeId value, every 15 seconds. [{ \"Id\": \"OCS\", \"ExecutionPeriod\" : \"00:00:15\", \"EgressFilter\" : \"TypeId:myType\", \"Endpoint\" : \"https://{OcsLocation}/api/Tenants/{tenantId}/Namespaces/{namespaceId}/omf\", \"https:  {OcsLocation} api Tenants {tenantId} Namespaces {namespaceId} omf\", \"ClientId\" : \"{clientId}\", \"ClientSecret\" : \"{clientSecret}\" }] Egress data to OCS - all streams, every 15 seconds, including backfilling. [{ \"Id\": \"OCS\", \"ExecutionPeriod\" : \"00:00:15\", \"Backfill\" : true, \"Endpoint\" : \"https://{OcsLocation}/api/Tenants/{tenantId}/Namespaces/{namespaceId}/omf\", \"https:  {OcsLocation} api Tenants {tenantId} Namespaces {namespaceId} omf\", \"ClientId\" : \"{clientId}\", \"ClientSecret\" : \"{clientSecret}\" }] Egress diagnostic data to OCS - every 1 hour. [{ \"Id\": \"OCS\", \"ExecutionPeriod\" : \"01:00:00\", \"Endpoint\" : \"https://{OcsLocation}/api/Tenants/{tenantId}/Namespaces/{namespaceId}/omf\", \"https:  {OcsLocation} api Tenants {tenantId} Namespaces {namespaceId} omf\", \"ClientId\" : \"{clientId}\", \"ClientSecret\" : \"{clientSecret}\", \"NamespaceId\" : \"diagnostics\" }] Egress data to PI - all streams, every 15 seconds, including both type and stream prefix. All properties explicitly listed. [{ \"Id\": \"PI\", \"Name\" : null, \"Description\" : null, \"ExecutionPeriod\" : \"00:00:15\", \"Enabled\" : true, \"Backfill\" : false, \"EgressFilter\" : null, \"Endpoint\" : \"https://{webApiLocation}/piwebapi/omf/\", \"https:  {webApiLocation} piwebapi omf \", \"ClientId\" : null, \"ClientSecret\" : null, \"Username\" : \"{username}\", \"Password\" : \"{password}\", \"StreamPrefix\" : \"1ValidPrefix.\", \"TypePrefix\" : \"AlsoValid_\", \"DebugExpiration\" : null, \"NamespaceId\" : \"default\", \"TokenEndpoint\" : null, \"ValidateEndpointCertificate\" : true }] Egress data to PI - streams whose Id contains \"Modbus\" or \"Opc\", every 1 minute. Includes use of domain for username. [{ \"Id\": \"PI\", \"ExecutionPeriod\" : \"00:01:00\", \"EgressFilter\" : \"Id:*Modbus* OR Id:*Opc*\", \"Endpoint\" : \"https://{webApiLocation}/piwebapi/omf/\", \"https:  {webApiLocation} piwebapi omf \", \"Username\" : \"{domain}\\\\{username}\", \"Password\" : \"{password}\" }] Egress data to PI - streams containing a field that begins with \"Unique\", every 1 hour. [{ \"Id\": \"PI\", \"ExecutionPeriod\" : \"01:00:00\", \"EgressFilter\" : \"Unique*\", \"Endpoint\" : \"https://{webApiLocation}/piwebapi/omf/\", \"https:  {webApiLocation} piwebapi omf \", \"Username\" : \"{username}\", \"Password\" : \"{password}\" }] REST URLs Relative URL HTTP verb Action api/v1/configuration/storage/periodicegressendpoints api v1 configuration storage periodicegressendpoints GET Gets all configured egress endpoints. api/v1/configuration/storage/periodicegressendpoints api v1 configuration storage periodicegressendpoints DELETE Deletes all configured egress endpoints. api/v1/configuration/storage/periodicegressendpoints api v1 configuration storage periodicegressendpoints POST Adds an array of egress endpoints, fails if any endpoint already exists. api/v1/configuration/storage/periodicegressendpoints api v1 configuration storage periodicegressendpoints POST Adds a single egress endpoint, fails if endpoint already exists. api/v1/configuration/storage/periodicegressendpoints api v1 configuration storage periodicegressendpoints PUT Replaces all egress endpoints. api/v1/configuration/storage/periodicegressendpoints/{id} api v1 configuration storage periodicegressendpoints {id} GET Gets configured endpoint with id . api/v1/configuration/storage/periodicegressendpoints/{id} api v1 configuration storage periodicegressendpoints {id} DELETE Deletes configured endpoint with id . api/v1/configuration/storage/periodicegressendpoints/{id} api v1 configuration storage periodicegressendpoints {id} PUT Replaces egress endpoint with id , fails if endpoint does not exist. api/v1/configuration/storage/periodicegressendpoints/{id} api v1 configuration storage periodicegressendpoints {id} PATCH Allows partial updating of configured endpoint with id ."
                                                 },
    "V1/Docker/EdgeDocker_1-0.html":  {
                                          "href":  "V1/Docker/EdgeDocker_1-0.html",
                                          "title":  "Install Edge Data Store using Docker",
                                          "keywords":  "Install Edge Data Store using Docker Docker is a set of tools that can be used on Linux to manage application deployments. To use Docker, you must be familiar with the underlying technology and have determined that it is appropriate for your planned use of Edge Data Store. Docker is not a requirement to use EDS. The following examples describe how to create a Docker container for EDS. Create a Docker container for EDS Using the example appropriate for your operating system and processor, create the Dockerfile in the directory where you want to create and run the container. The file must be named Dockerfile. Copy the appropriate .tar.gz file to the same directory as the Dockerfile. Run the following command line in the same directory (sudo may be necessary): docker build -t edgedatastore . ARM32 example FROM ubuntu:18.04 WORKDIR /   RUN apt-get update \u0026\u0026 DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends libicu60 libssl1.0.0 ADD ./EdgeDataStore_linux-arm.tar.gz . EdgeDataStore_linux-arm.tar.gz . ENTRYPOINT [\"./EdgeDataStore_linux-arm/OSIsoft.Data.System.Host\"] [\". EdgeDataStore_linux-arm OSIsoft.Data.System.Host\"] ARM64 example FROM ubuntu:18.04 WORKDIR /   RUN apt-get update \u0026\u0026 DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends libicu60 libssl1.0.0 ADD ./EdgeDataStore_linux-arm64.tar.gz . EdgeDataStore_linux-arm64.tar.gz . ENTRYPOINT [\"./EdgeDataStore_linux-arm64/OSIsoft.Data.System.Host\"] [\". EdgeDataStore_linux-arm64 OSIsoft.Data.System.Host\"] AMD64 (x64) example FROM ubuntu:18.04 WORKDIR /   RUN apt-get update \u0026\u0026 DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends libicu60 libssl1.0.0 ADD ./EdgeDataStore_linux-x64.tar.gz . EdgeDataStore_linux-x64.tar.gz . ENTRYPOINT [\"./EdgeDataStore_linux-x64/OSIsoft.Data.System.Host\"] [\". EdgeDataStore_linux-x64 OSIsoft.Data.System.Host\"] Run the EDS Docker container Before running the Docker container, determine whether to store the data in the container or in a host directory. REST access from the local machine from Docker Complete the following steps to run the container: Open command line. Type the following in the command line (sudo may be necessary): docker run -d --network host edgedatastore Port 5590 is accessible from the host and you can make REST calls to EDS from applications on the local host computer. In this example, all data collected by EDS is stored in the container itself. When the container is deleted, the data stored is also deleted. Persistent storage on the local file system from Docker Complete the following steps to run the container: Open a terminal window. Type the following in the command line (sudo may be necessary): docker run -d --network host -v /edgeds:/usr/share/OSIsoft/  edgeds: usr share OSIsoft  edgedatastore Port 5590 is accessible from the host and you can make REST calls to EDS from applications on the local host computer. In this example, all data is written to the host directory, and the host directory is a directory on the local machine, /edgeds.  edgeds. You can specify any directory. Port number change To use a port other than 5590, see System port configuration . Changing the configuration of EDS running in the container changes the port exposed to the local machine. Limiting local host access to Docker If you remove the --network host option from the docker run command, no REST access is possible from outside the container. This can be used when you want to host an application in the same container as EDS, and do not want to have external REST access enabled."
                                      },
    "V1/Configuration/EdgeSystemConfiguration_1-0.html":  {
                                                              "href":  "V1/Configuration/EdgeSystemConfiguration_1-0.html",
                                                              "title":  "Edge Data Store configuration",
                                                              "keywords":  "Edge Data Store configuration Edge Data Store requires configuration, which can be performed either for each individual component or for the system as a whole. Use the following procedures to configure Edge Data Store as a whole system with either a minimum or a maximum configuration. Configure minimum Edge Data Store The following JSON file represents minimal configuration of an Edge Data Store. There are no Modbus TCP EDS adapter or OPC UA EDS adapter components, and the Storage component configurations are set to the default. If you configure a system with this JSON file, any existing Modbus TCP EDS adapter or OPC UA EDS adapter components will be disabled and removed. No storage data will be deleted or modified, and OMF and SDS data access will not be impacted. Save or copy the example JSON in a file named EdgeMinimumConfiguration.json in any directory on a device with Edge Data Store installed. Run the following curl command from the directory where the file is located: curl -i -d \"@EdgeMinimumConfiguration.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration http:  localhost:5590 api v1 configuration The following will be set as the configuration of a running Edge Data Store. The configuration takes effect immediately after the command completes. { \"Storage\": { \"PeriodicEgressEndpoints\": [], \"Runtime\": { \"streamStorageLimitMb\": 2, \"streamStorageTargetMb\": 1, \"ingressDebugExpiration\": \"0001-01-01T00:00:00\", \"checkpointRateInSec\": 30, \"transactionLogLimitMB\": 250, \"enableTransactionLog\": true }, \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 } }, \"System\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"HealthEndpoints\": [], \"Port\": { \"port\": 5590 }, \"Components\": [ { \"componentId\": \"Storage\", \"componentType\": \"EDS.Component\" } ] } } This example results in a minimal configuration of Edge Data Store. It only supports OMF and SDS operations using REST. No egress is configured, so no data will be sent to either OCS or PI Web API. Configure maximum Edge Data Store The following JSON file represents maximum configuration of an Edge Data Store. There are Modbus TCP EDS adapter components and OPC UA EDS adapter components, and egress is configured to send to both PI Web API and OCS from both the default (operational data) and diagnostics (diagnostic data) namespace. Using any text editor, create a JSON file using the following example. Fill in any credentials or IP addresses with appropriate values for your environment. Save the edited JSON in a file named EdgeMaximumConfiguration.json in any directory. Run the following curl command from the same directory where the file is located: curl -i -d \"@EdgeMaximumConfiguration.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration http:  localhost:5590 api v1 configuration The following will be set as the configuration for the running Edge Data Store. The configuration takes effect immediately after the command completes. { \"Modbus1\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"DataSource\": { \"IpAddress\": \"\u003cModbus IP address\u003e\", \"Port\": 502, \"ConnectTimeout\": 15000, \"ReconnectInterval\": 5000, \"RequestTimeout\": 9000, \"DelayBetweenRequests\": 0, \"MaxResponseDataLength\": 250 }, \"DataSelection\": [{ \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 1, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 2, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 3, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 4, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 5, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 } ] }, \"Storage\": { \"Runtime\": { \"streamStorageLimitMb\": 2, \"streamStorageTargetMb\": 1, \"ingressDebugExpiration\": \"0001-01-01T00:00:00\" }, \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"PeriodicEgressEndpoints\": [{ \"Id\": \"OCS\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"default\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"ChangeMe\", \"TypePrefix\": \"ChangeMe\", \"Endpoint\": \"\u003cOCS OMF URL for your tenant and namespace\u003e\", \"ClientId\": \"\u003cOCS ClientId\u003e\", \"ClientSecret\": \"\u003cOCS ClientSecret\u003e\", \"UserName\": null, \"Password\": null, \"DebugExpiration\": null }, { \"Id\": \"PWA\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"default\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"ChangeMe\", \"TypePrefix\": \"ChangeMe\", \"Endpoint\": \"https://\u003cyour \"https:  \u003cyour PI Web API server\u003e/piwebapi/omf/\", server\u003e piwebapi omf \", \"ClientId\": null, \"ClientSecret\": null, \"UserName\": \"\u003cusername\u003e\", \"Password\": \"\u003cpassword\u003e\", \"DebugExpiration\": null }, { \"Id\": \"OCSDiag\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"diagnostics\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"ChangeMe\", \"TypePrefix\": \"ChangeMe\", \"Endpoint\": \"\u003cOCS OMF URL for your tenant and namespace\u003e\", \"ClientId\": \"\u003cOCS ClientId\u003e\", \"ClientSecret\": \"\u003cOCS ClientSecret\u003e\", \"UserName\": null, \"Password\": null, \"DebugExpiration\": null }, { \"Id\": \"PWADiag\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"diagnostics\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"ChangeMe\", \"TypePrefix\": \"ChangeMe\", \"Endpoint\": \"https://\u003cyour \"https:  \u003cyour PI Web API server\u003e/piwebapi/omf/\", server\u003e piwebapi omf \", \"ClientId\": null, \"ClientSecret\": null, \"UserName\": \"\u003cusername\u003e\", \"Password\": \"\u003cpassword\u003e\", \"DebugExpiration\": null } ] }, \"OpcUa1\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"DataSource\": { \"EndpointUrl\": \"opc.tcp://\u003cOPC \"opc.tcp:  \u003cOPC UA server IP and port\u003e/OSIsoftTestServer\", port\u003e OSIsoftTestServer\", \"UseSecureConnection\": false, \"UserName\": null, \"Password\": null, \"RootNodeIds\": null, \"IncomingTimestamp\": \"Source\", \"StreamIdPrefix\": \"OpcUa\" }, \"DataSelection\": [{ \"Selected\": true, \"Name\": \"Cold Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.ColdSideInletTemperature\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Cold Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.ColdSideOutletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Hot Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.HotSideInletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Hot Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.HotSideOutletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Cold Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1002.ColdSideInletTemperature\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Cold Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1002.ColdSideOutletTemperature\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Hot Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1002.HotSideInletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Hot Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1002.HotSideOutletTemperature\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Power\", \"NodeId\": \"ns=2;s=Line1.SF_Pump_001.Power\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Efficiency\", \"NodeId\": \"ns=2;s=Line1.SF_Pump_001.Efficiency\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Flowrate\", \"NodeId\": \"ns=2;s=Line1.SF_Pump_001.Flowrate\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Power\", \"NodeId\": \"ns=2;s=Line1.SF_Pump_002.Power\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Efficiency\", \"NodeId\": \"ns=2;s=Line1.SF_Pump_002.Efficiency\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Flowrate\", \"NodeId\": \"ns=2;s=Line1.SF_Pump_002.Flowrate\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Level\", \"NodeId\": \"ns=2;s=Line1.Tank1.Level\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Mass\", \"NodeId\": \"ns=2;s=Line1.Tank1.Mass\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Volume\", \"NodeId\": \"ns=2;s=Line1.Tank1.Volume\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Level\", \"NodeId\": \"ns=2;s=Line1.Tank2.Level\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Mass\", \"NodeId\": \"ns=2;s=Line1.Tank2.Mass\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Volume\", \"NodeId\": \"ns=2;s=Line1.Tank2.Volume\", \"StreamId\": null } ] }, \"System\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"Components\": [{ \"componentId\": \"OpcUa1\", \"componentType\": \"OpcUa\" }, { \"componentId\": \"Modbus1\", \"componentType\": \"Modbus\" }, { \"componentId\": \"Storage\", \"componentType\": \"EDS.Component\" } ], \"HealthEndpoints\": [], \"Port\": { \"port\": 5590 } } }"
                                                          },
    "zArchive/Schemas/OpcUa_DataSource_schema.html":  {
                                                          "href":  "zArchive/Schemas/OpcUa_DataSource_schema.html",
                                                          "title":  "Sample OPC UA data source configuration",
                                                          "keywords":  "Sample OPC UA data source configuration The OPC UA data source configuration schema specifies how to formally describe the data source parameters for OPC UA. { \"EndpointUrl\": \"opc.tcp://\u003cip \"opc.tcp:  \u003cip address\u003e:\u003cport - often 62541\u003e/\u003cserver 62541\u003e \u003cserver path\u003e\", \"UseSecureConnection\": false, \"UserName\": null, \"Password\": null, \"RootNodeIds\": null, \"IncomingTimestamp\": \"Source\", \"StreamIdPrefix\": \"OpcUa\" } OPC UA data source configuration properties Property Type Required Nullable Defined by EndpointUrl string Optional Yes DataSourceConfiguration (this schema) IncomingTimestamp reference Optional No DataSourceConfiguration (this schema) Password string Optional Yes DataSourceConfiguration (this schema) RootNodeIds string Optional Yes DataSourceConfiguration (this schema) StreamIdPrefix string Optional Yes DataSourceConfiguration (this schema) UseSecureConnection boolean Optional No DataSourceConfiguration (this schema) UserName string Optional Yes DataSourceConfiguration (this schema) Note: All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required EndpointUrl string Optional IncomingTimestamp Optional Password string Optional RootNodeIds string Optional StreamIdPrefix string Optional UseSecureConnection boolean Optional UserName string Optional"
                                                      },
    "zArchive/Schemas/OpcUa_DataSelection_schema.html":  {
                                                             "href":  "zArchive/Schemas/OpcUa_DataSelection_schema.html",
                                                             "title":  "Sample OPC UA data selection configuration",
                                                             "keywords":  "Sample OPC UA data selection configuration The OPC UA data selection configuration schema specifies how to formally describe the data selection parameters for OPC UA. [{ \"Selected\": true, \"Name\": \"Cold Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.ColdSideInletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Hot Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.HotSideInletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Hot Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.HotSideOutletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Cold Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1002.ColdSideInletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Hot Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1002.HotSideOutletTemperature\", \"StreamId\": null } ] OPC UA data selection configuration properties Property Type Required Nullable Defined by Name string Optional Yes DataCollectionItem (this schema) NodeId string Optional Yes DataCollectionItem (this schema) Selected boolean Optional No DataCollectionItem (this schema) StreamId string Optional Yes DataCollectionItem (this schema) Note: All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required Name string Optional NodeId string Optional Selected boolean Optional StreamId string Optional"
                                                         },
    "zArchive/Schemas/Modbus_schema.html":  {
                                                "href":  "zArchive/Schemas/Modbus_schema.html",
                                                "title":  "Modbus TCP configuration properties",
                                                "keywords":  "Modbus TCP configuration properties Property Type Required Nullable Defined by Logging ModbusLoggingConfiguration Optional Yes EdgeLoggerConfiguration DataSource DataSourceConfiguration Optional Yes ComponentsConfiguration DataSelection [ModbusDataSelectionConfiguration] Optional Yes DataSelectionConfiguration"
                                            },
    "zArchive/Schemas/Modbus_Logging_schema.html":  {
                                                        "href":  "zArchive/Schemas/Modbus_Logging_schema.html",
                                                        "title":  "ModbusLoggerConfiguration Properties",
                                                        "keywords":  "ModbusLoggerConfiguration Properties Property Type Required Nullable Defined by LogFileCountLimit integer Optional Yes EdgeLoggerConfiguration (this schema) LogFileSizeLimitBytes integer Optional Yes EdgeLoggerConfiguration (this schema) LogLevel reference Optional No EdgeLoggerConfiguration (this schema) LogFileCountLimit LogFileCountLimit is optional type: integer defined in this schema LogFileCountLimit type integer , nullable LogFileSizeLimitBytes LogFileSizeLimitBytes is optional type: integer defined in this schema LogFileSizeLimitBytes type integer , nullable LogLevel LogLevel is optional type: reference defined in this schema LogLevel type ??? #/definitions/EdgeLogLevel # definitions EdgeLogLevel All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required LogFileCountLimit integer Optional LogFileSizeLimitBytes integer Optional LogLevel Optional LogFileCountLimit LogFileCountLimit is optional type: integer LogFileCountLimit type integer , nullable LogFileSizeLimitBytes LogFileSizeLimitBytes is optional type: integer LogFileSizeLimitBytes type integer , nullable LogLevel LogLevel is optional type: reference LogLevel type ??? #/definitions/EdgeLogLevel # definitions EdgeLogLevel"
                                                    },
    "V1/SDS/Read data/Response_format_1-0.html":  {
                                                      "href":  "V1/SDS/Read data/Response_format_1-0.html",
                                                      "title":  "Response format",
                                                      "keywords":  "Response format The format of the response is specified in the API call. For read APIs, the supported response formats are: JSON - the default response format for SDS, which is used in all examples in this documentation. Default JSON responses do not include any values that are equal to the default value for their type. Verbose JSON - responses include all values, including defaults, in the returned JSON payload. To specify verbose JSON return, add the header Accept-Verbosity with a value of verbose to the request. SDS - specified by setting the Accept header in the request to application/sds application sds ."
                                                  },
    "V1/SDS/Read data/Read_characteristics_1-0.html":  {
                                                           "href":  "V1/SDS/Read data/Read_characteristics_1-0.html",
                                                           "title":  "Read characteristics",
                                                           "keywords":  "Read characteristics When data is requested at an index for which no stored event exists, the read characteristics determine whether the result is an error, no event, interpolated event, or extrapolated event. The combination of the type of the index and the interpolation and extrapolation modes of the SdsType and the SdsStream determine the read characteristics. Interpolation Interpolation determines how a stream behaves when asked to return an event at an index between two existing events. InterpolationMode determines how the returned event is constructed. The table below lists InterpolationModes: Mode Enumeration value Operation Default 0 The default InterpolationMode is Continuous. Continuous 0 Interpolates the data using previous and next index values. StepwiseContinuousLeading 1 Returns the data from the previous index. StepwiseContinuousTrailing 2 Returns the data from the next index. Discrete 3 Returns ???null???. Note that Continuous cannot return events for values that cannot be interpolated, such as when the type is not numeric. The table below describes how the Continuous InterpolationMode affects indexes that occur between data in a stream: InterpolationMode = Continuous or Default Type Result for an index between data in a stream Comment Numeric Types Interpolated* Rounding is done as needed for integer types. Time related Types Interpolated DateTime, DateTimeOffset, TimeSpan Nullable Types Interpolated** Limited support for nullable numeric types. Array and List Types No event is returned String Type No event is returned Boolean Type Returns value of nearest index Enumeration Types Returns Enum value at 0 This may have a value for the enumeration. GUID No event is returned Version No event is returned IDictionary or IEnumerable No event is returned Dictionary, Array, List, and so on. *When extreme values are involved in an interpolation (for example, Decimal.MaxValue) the call might result in a BadRequest exception. **For the Continuous interpolation mode, nullable types are interpolated in the same manner as their non-nullable equivalents as long as the values surrounding the requested interpolation index are non-null. If either of the values are null, the interpolated value will be null. If the InterpolationMode is not assigned, the events are interpolated in the default manner, unless the interpolation mode is overridden in the SdsTypeProperty or the SdsStream. For more information on overriding the interpolation mode on a specific type property, see SdsTypeProperty . For more information on overriding the interpolation mode for a specific stream, see Streams . Extrapolation Extrapolation defines how a stream responds to requests with indexes that precede or follow all data in the steam. ExtrapolationMode acts as a master switch to determine whether extrapolation occurs and at which end of the data. ExtrapolationMode works with the InterpolationMode to determine how a stream responds. The following tables show how ExtrapolationMode affects returned values for each InterpolationMode value: ExtrapolationMode with InterpolationMode = Default (or Continuous), StepwiseContinuousLeading and StepwiseContinuousTrailing ExtrapolationMode Enumeration value Index before data Index after data All 0 Returns first data value Returns last data value. None 1 No event is returned No event is returned. Forward 2 No event is returned Returns last data value. Backward 3 Returns first data value No event is returned. ExtrapolationMode with InterpolationMode = Discrete ExtrapolationMode Enumeration value Index before data Index after data All 0 No event is returned. No event is returned. None 1 No event is returned. No event is returned. Forward 2 No event is returned. No event is returned. Backward 3 No event is returned. No event is returned. If the ExtrapolationMode is not assigned, the events are extrapolated in the default manner, unless the extrapolation mode is overridden on the SdsStream. For more information on overriding the extrapolation mode on a specific stream, see Streams . For additional information about the effect of read characteristics for the available read methods, see Read data API ."
                                                       },
    "V1/Overview/PIEgressQuickStart_1-0.html":  {
                                                    "href":  "V1/Overview/PIEgressQuickStart_1-0.html",
                                                    "title":  "PI egress quick start",
                                                    "keywords":  "PI egress quick start Data egress provides a mechanism to transfer data to PI Server using OMF messages through a PI Web API endpoint. To get started sending data stored in Edge Data Store to a PI System, create a PI Web API OMF endpoint and configure periodic egress to use the PI Web API endpoint. Create a PI Web API OMF endpoint Complete the following steps to create a PI Web API OMF endpoint: Install PI Web API and enable the OSIsoft Message Format (OMF) Services feature. During configuration, choose an AF database and PI Data Archive where metadata and data will be stored. The account used in an egress configuration needs permissions to create AF elements, element templates, and PI points. Configure PI Web API to use Basic authentication. For complete steps, as well as best practices and recommendations, see the PI Web API User Guide on Live Library. Note: The certificate used by PI Web API must be trusted by the device running EDS, otherwise the egress configuration ValidateEndpointCertificate property needs to be set to false (this can be the case with a self-signed certificate but should only be used for testing purposes). Create a periodic egress configuration Complete the following steps to configure Edge Storage periodic egress for the PI Web API endpoint and credentials: Create a JSON file containing one or more egress endpoints, by copying the following example into a text editor. [{ \"Id\": \"PWA\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"default\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"\u003cunique stream prefix\u003e\", \"TypePrefix\": \"\u003cunique type prefix\u003e\", \"Endpoint\": \"https://\u003cyour \"https:  \u003cyour PI Web API Server\u003e/piwebapi/omf/\", Server\u003e piwebapi omf \", \"ClientId\": null, \"ClientSecret\": null, \"UserName\": \"\u003cusername\u003e\", \"Password\": \"\u003cpassword\u003e\", \"DebugExpiration\": null, \"ValidateEndpointCertificate\": true, \"TokenEndpoint\": null }] Modify the Endpoint parameter with the name of the PI Web API sever. Modify the Username and Password parameters to specify a valid user account that can write data via PI Web API using Basic authentication. For examples, see Configure data egress . Note: The StreamPrefix and TypePrefix parameters ensure uniqueness on the destination system, if required. The StreamPrefix value creates unique PI Points on the PI System. To only send specific streams, edit the EgressFilter value. For examples of more advanced scenarios, see Data egress configuration . Save the JSON file with the name PeriodicEgressEndpoints.json to any directory on the device where EDS is installed. To configure Edge Storage to send data to the PI System, run the following curl script from the directory where the JSON file is located. curl -d \"@PeriodicEgressEndpoints.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/storage/PeriodicEgressEndpoints/ http:  localhost:5590 api v1 configuration storage PeriodicEgressEndpoints  When the command completes successfully, data egress to the PI System begins."
                                                },
    "V1/Overview/Performance_1-0.html":  {
                                             "href":  "V1/Overview/Performance_1-0.html",
                                             "title":  "Performance",
                                             "keywords":  "Performance Edge Data Store is designed to run on a variety of low powered devices and to serve data to custom applications that run on the same platform. To assist in determining the appropriate hardware and software configuration for a specific use, EDS was tested on a variety of different devices, from single board computers to industrial edge gateways, on Linux and Windows operating systems, with different data stream counts and with the supported ingress methods collecting data at different event rates. Use the following performance testing information to determine the appropriate hardware and software to use with EDS in your scenarios. Edge Data Store Performance Testing Hardware EDS performance test cases were divided into three categories based on commonly available, consumer grade and industrial grade devices. Several devices in each category were tested to validate performance expectations and the results of these tests are summarized below in terms of the maximum supported data stream count and data ingress rate for each category. Small devices (e.g., 1 core ARM CPU, 512 MB RAM, Linux): 30 data streams, 30 events /   sec Medium devices (e.g., 2 core ARM or Intel CPU, 2 GB RAM, Linux or Windows): 300 data streams, 300 events /   sec Large devices (e.g., 4 core ARM or Intel CPU, 4 GB RAM, Linux or Windows): 3,000 data streams, 3,000 events /   sec It is possible that lower performance results may be realized on other devices with similar hardware and software configurations. Other applications running on the same device may also affect actual performance of EDS. The data stream counts and throughput rates shown above are the upper limits of what is supported for EDS for each device category. Ingress Performance EDS can ingress data using the EDS Modbus TCP adapter, the EDS OPC UA adapter, and/or and or a custom OMF application developed by others. Each of these data ingress methods have a different performance profile, so the performance of EDS using these different methods will vary. When selecting the device to host EDS, there are a few general principles that arose from the performance testing: EDS adapters use less CPU than custom OMF applications when using the Edge Data Store OMF endpoint. In general, across all hardware platforms, CPU usage for EDS Modbus TCP and EDS OPC UA adapters is roughly half of that used by custom OMF applications at the same event rates. RAM usage is largely determined by the number of data streams written to. More data streams collected in EDS by any data ingress method require additional RAM (in addition to requiring more storage space). EDS is slightly more efficient running on Windows than Linux on similar devices. Both CPU and RAM usage are slightly lower when EDS is running on Windows 10 than on Linux when comparing them on the AMD64/Intel AMD64 Intel x64 devices, which support both operating systems. SSD storage is recommended for maximum performance and reliability. EDS performance testing was completed on a variety of storage media - SSDs, HDDs, eMMC, and SD cards. EDS performance testing was successful using all storage technologies but for maximum performance and reliability, SSD storage is the best choice. Periodic Egress Performance EDS generates OMF messages when configured to egress data to a PI Server or to OSIsoft Cloud Services. An important part of periodic egress performance is the amount of network bandwidth available between the device hosting the EDS and the PI Web API OMF endpoint or the OSIsoft Cloud Services OMF endpoint. The performance numbers presented in this section reflect use of a network with a 1 GB LAN connection and a high-speed connection to the Internet. If EDS is installed on a device in a location with limited network bandwidth, a lower level of egress performance can be expected. Data egress has a much smaller performance impact on EDS than data ingress. Generally speaking, the performance impact of data egress on CPU and RAM usage is only a small percentage of the CPU and RAM usage of data ingress, so data egress configuration is not a major factor in EDS system design. Periodic Egress Performance to PI Web API Performance testing of periodic egress between EDS and the PI Web API OMF endpoint was completed with a 1 GB LAN connection between the EDS test device and the PI Web API. The PI Web API was hosted on server class PC that also included a PI Server. The EDS device was configured for backfill and several million events were sent to the PI Web API. In all cases, EDS egress performance exceeded 10,000 events per second. In addition, extended tests were run over several weeks with an egress rate of 3,000 events per second. Periodic Egress Performance to OSIsoft Cloud Services (OCS) Performance testing of periodic egress between EDS and the OSIsoft Cloud Services OMF endpoint was completed with a high-speed Internet connection between the EDS test device and OSIsoft Cloud Services running in the Microsoft Azure West US Data Center, approximately 2,500 miles away. The EDS device was configured for backfill and several million events were sent to OSIsoft Cloud Services. In all cases, EDS egress performance exceeded 10,000 events per second. In addition, extended tests were run over several weeks with a lower egress rate."
                                         },
    "V1/Logging/SystemLogging_1-0.html":  {
                                              "href":  "V1/Logging/SystemLogging_1-0.html",
                                              "title":  "System-level logging configuration",
                                              "keywords":  "System-level logging configuration Edge Data Store writes daily log messages to flat text files in the following locations: ??? Windows: %ProgramData%/OSIsoft/EdgeDataStore/Logs %ProgramData% OSIsoft EdgeDataStore Logs ??? Linux: /usr/share/OSIsoft/EdgeDataStore/Logs  usr share OSIsoft EdgeDataStore Logs Each message in the log displays the message severity level, timestamp, and the message itself. Default logging configuration and schema By default, logging captures Information, Warning, Error, and Critical messages in the message logs. The following logging configuration is the default for a component on install: { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 } The schema file specifies how to formally describe the configuration parameters for message logging. It is located in: ??? Windows: %ProgramFiles%/OSIsoft/EdgeDataStore/Schema %ProgramFiles% OSIsoft EdgeDataStore Schema ??? Linux: /opt/OSIsoft/EdgeDataStore/Schema  opt OSIsoft EdgeDataStore Schema Change logging configuration Complete the following to change the logging configuration: Update the parameters of the message logging configuration JSON file that you want as needed. For example, the System_Logging.json file: { \"logLevel\": \"Warning\", \"logFileSizeLimitBytes\": 16777216, \"logFileCountLimit\": 30 } Save the file. Use any tool capable of making HTTP requests to execute a PUT command with the contents of that file to the following endpoint: http://localhost:5590/api/v1/configuration/System/Logging http:  localhost:5590 api v1 configuration System Logging . Example using curl (run this command from the same directory where the file is located): curl -i -d \"@System_Logging.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/System/Logging http:  localhost:5590 api v1 configuration System Logging On successful execution, the log level change takes effect immediately during runtime. The other configurations (log file size and file count) get updated after Edge Data Store is restarted. Note: Any parameter not specified in the updated configuration file will revert to the default schema value. Log levels The logLevel sets the minimum severity for messages to be included in the logs. Messages with a severity below the level set are not included. The log levels in their increasing order of severity are as follows: Trace, Debug, Information, Warning, Error, Critical. Table: General guidelines for setting the log level. Level Description Trace Logs that contain the most detailed messages. These messages may contain sensitive application data like actual received values and should not be enabled in a production environment. Debug Logs that can be used to troubleshoot data flow issues by recording metrics and detailed flow related information. Information Logs that track the general flow of the application. Any non-repetitive general information (like version information relating to the software at startup, what external services are being used, data source connection string, number of measurements, egress URL, change of state \"Starting\", \"Stopping\", or configuration) can be useful for diagnosing potential application errors. Warning Logs that highlight an abnormal or unexpected event in the application flow, but does not otherwise cause the application execution to stop. Warning messages can indicate an unconfigured data source state, that a communication with backup failover instance has been lost, an insecure communication channel in use, or any other event that could require attention, but that does not impact data flow. Error Logs that highlight when the current flow of execution is stopped due to a failure. These should indicate a failure in the current activity, not an application-wide failure. This can indicate an invalid configuration, unavailable external endpoint, internal flow error, and so on. Critical Logs that describe an unrecoverable application or system crash, or a catastrophic failure that requires immediate attention. This can indicate application wide failures like beta timeout expired, unable to start self-hosted endpoint, unable to access vital resource (for example, Data Protection key file), and so on. Parameters for logging The following parameters are available for configuring logging. Parameter Required Type Nullable Description LogFileCountLimit Optional integer Yes The maximum number of log files that the service will create for the component. It must be a positive integer. LogFileSizeLimitBytes Optional integer Yes The maximum size in bytes of log files that the service will create for the component. It must be a positive integer. LogLevel Optional reference No The log level settings that you want. The following options are available: Verbose - Captures all messages: Verbose, Debug, Information, Warning and Error Debug - Captures most messages: Debug, Information, Warning and Error Information - Captures most messages: Information, Warning and Error Warning - Captures only Warning and Error messages Error - Captures Error messages only"
                                          },
    "V1/Logging/LoggingConfiguration_1-0.html":  {
                                                     "href":  "V1/Logging/LoggingConfiguration_1-0.html",
                                                     "title":  "Logging configuration",
                                                     "keywords":  "Logging configuration Use the logging configuration to collect information about how Edge Data Store and its components are performing. Set the severity level for the messages to capture, anywhere from critical errors only to debugging messages for troubleshooting."
                                                 },
    "V1/Health/Health_1-0.html":  {
                                      "href":  "V1/Health/Health_1-0.html",
                                      "title":  "Edge Data Store health",
                                      "keywords":  "Edge Data Store health Edge Data Store and its components produce health information to provide insight into their status, which is critical for monitoring data collection. When configured, EDS transfers health information to OMF endpoints, including the types and containers that represent available health information. To enable this functionality, configure one or more health endpoints. EDS adapter health The following health types and streams are created to reflect the health of EDS adapters. The Adapters static type includes these properties and servers as a root AF element with the ID Adapters. Property Type Description Id string Adapters - root AF element Description string Collection of Adapter assets EDS adapter component health The Adapter Health static type includes the following properties, which are logged in a stream with the ID {machinename}.{componentid}. The stream is linked to root AF element (Adapters). Property Type Description Id string {machinename}.{componentId} Description string {productname} health Adapter Type string {adaptertype} Version string {adapterversion} Device status The DeviceStatus dynamic type includes the following values, which are logged in a stream with the ID Adapters.{machinename}.{componentid}.DeviceStatus. The stream is linked to {machinename}.{componentid} static stream. Property Type Description Time string Timestamp of event DeviceStatus string Device status value Next health message expected The NextHealthMessageExpected dynamic type includes the following values, which are logged in a stream with the ID Adapters.{machinename}.{componentid}.NextHealthMessageExpected. The stream is linked to {machinename}.{componentid} static stream. Heart beat message is expected once a minute. Property Type Description Time string Timestamp of event NextHealthMessageExpected string Time when next health message is expected. Storage component health The following health types and streams are created to reflect the health of the Storage component. The Storage static type includes the following properties and servers as a root AF element with the ID Storage. Property Type Description Id string Storage - root AF element Description string Storage Health Storage health The Storage Health static type includes the following properties, which are logged in a stream with the ID {machinename}.Storage. The stream is linked to root AF element (Storage). Property Type Description Id string {machinename}.Storage Description string {productname} health Adapter Type string {adaptertype} Version string {storageversion} Storage device status The DeviceStatus dynamic type includes the following values, which are logged in a stream with the ID Storage.{machinename}.DeviceStatus. The stream is linked to {machinename}.Storage static stream. Property Type Description Time string Timestamp of event DeviceStatus string Device status value Storage next health message expected The NextHealthMessageExpected dynamic type includes the following values, which are logged in a stream with the ID Storage.{machinename}.NextHealthMessageExpected. The stream is linked to {machinename}.Storage static stream. Heart beat message is expected once a minute. Property Type Description Time string Timestamp of event NextHealthMessageExpected string Time when next health message is expected."
                                  },
    "V1/Configuration/System health endpoints configuration_1-0.html":  {
                                                                            "href":  "V1/Configuration/System health endpoints configuration_1-0.html",
                                                                            "title":  "Health endpoints configuration",
                                                                            "keywords":  "Health endpoints configuration To monitor the status of Edge Data Store, configure health information egress for its components to an OMF endpoint capable of receiving health messages. Health data is transmitted at a one minute interval. Configure system health endpoints Complete the following steps to configure system health endpoints: Using any text editor, create a JSON file containing system health endpoints. For content structure, see System health endpoints example . Update the parameters as needed. For a table of all available parameters, see Parameters . Save the file with the name System_HealthEndpoints.config.json . Use any tool capable of making HTTP requests to execute a POST command with the contents of that file to the following endpoint: http://localhost:5590/api/v1/configuration/System/HealthEndpoints http:  localhost:5590 api v1 configuration System HealthEndpoints , updating the port number if needed. Example using curl (run this command from the same directory where the file is located): curl -v -d \"@System_HealthEndpoints.json\" -H \"Content-Type: application/json\" application json\" http://localhost:5590/api/v1/configuration/System/HealthEndpoints http:  localhost:5590 api v1 configuration System HealthEndpoints Parameters The following parameters are available for configuring system health endpoints. Parameter Required Type Nullable Description Buffering Optional reference No Sets the buffering type for messages to this endpoint. Options are memory, disk, or none. The default is none. ClientId Optional string Yes The Client ID used for authentication to OSIsoft Cloud Services. ClientSecret Optional string Yes The Client Secret used for authentication to OSIsoft Cloud Services. Endpoint Required string Yes The URL of the ingress point which accepts OMF health messages. Id Optional string Yes The ID of the health endpoint configuration. The ID can be any alphanumeric string; for example, Endpoint1. If you do not specify an ID, Edge Data Store generates one automatically. MaxBufferSizeMB Optional integer No The limit on the maximum megabytes of data to buffer for messages to this endpoint if an integer is \u003e 0. This parameter is useful if you want to limit memory or disk usage growth in the event of disconnection to the endpoint. If the buffer is full, old messages will be discarded for new messages. The default is 0. Password Optional string Yes The password used for authentication to PI Web API OMF endpoint. UserName Optional string Yes The user name used for authentication to PI Web API OMF endpoint. ValidateEndpointCertificate Optional Boolean No The OSIsoft Adapter validates the endpoint certificate if set to true (recommended). If set to false, the OSIsoft Adapter accepts any endpoint certificate. OSIsoft strongly recommends using disabled endpoint certificate validation for testing purposes only. System health endpoints example [{ \"endpoint\": \"https://\u003cpi \"https:  \u003cpi web api server\u003e/piwebapi/omf/\", server\u003e piwebapi omf \", \"UserName\": \"\u003cusername\u003e\", \"Password\": \"\u003cpassword\u003e\", \"buffering\": \"none\", \"maxBufferSizeMB\": 0 }, { \"Endpoint\": \"https://\u003cOCS \"https:  \u003cOCS OMF endpoint\u003e\", \"ClientId\": \"\u003cclientid\u003e\", \"ClientSecret\": \"\u003cclientsecret\u003e\", \"buffering\": \"disk\", \"maxBufferSizeMB\": 0 } ]"
                                                                        },
    "V1/Configuration/Configuration_1-0.html":  {
                                                    "href":  "V1/Configuration/Configuration_1-0.html",
                                                    "title":  "Configuration",
                                                    "keywords":  "Configuration Configure each functional area of Edge Data Store to define connectivity and system behavior appropriate to your installation. The topics contained in this section provide instructions for each area. The examples in the Configuration topics use curl, a commonly available tool on both Windows and Linux. Any programming language or tool that supports making REST calls can be used to perform the same operations. The EdgeCmd utility can also be used to configure Edge Data Store components. To validate successful configurations, use a browser to retrieve data using GET commands. For more information on tools for Edge Data Store configuration, see Configuration tools ."
                                                },
    "V1/Installation/Verify installation_1-0.html":  {
                                                         "href":  "V1/Installation/Verify installation_1-0.html",
                                                         "title":  "Verify installation",
                                                         "keywords":  "Verify installation Depending on the device capabilities, it may take some time before the Edge Data Store is fully initialized and running for the first time. After allowing time for start up, use the following steps to verify that Edge Data Store is correctly installed. Open a terminal window and run the following command, replacing \u003cport_number\u003e with the port number specified during installation: curl http://localhost:\u003cport_number\u003e/api/v1/configuration http:  localhost:\u003cport_number\u003e api v1 configuration If you receive an error, wait a few seconds and try the script again. If the installation was successful, a JSON copy of the default system configuration is returned: { \"Storage\": { \"PeriodicEgressEndpoints\": [], \"Runtime\": { \"streamStorageLimitMb\": 2, \"streamStorageTargetMb\": 1, \"ingressDebugExpiration\": \"0001-01-01T00:00:00\", \"checkpointRateInSec\": 30, \"transactionLogLimitMB\": 250, \"enableTransactionLog\": true }, \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 } }, \"System\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"HealthEndpoints\": [], \"Port\": { \"port\": 5590 }, \"Components\": [ { \"componentId\": \"Storage\", \"componentType\": \"EDS.Component\" } ] } }"
                                                     },
    "V1/Installation/System Requirements_1-0.html":  {
                                                         "href":  "V1/Installation/System Requirements_1-0.html",
                                                         "title":  "System requirements",
                                                         "keywords":  "System requirements Edge Data Store is supported on a variety of platforms and processors. Install kits are available for the following platforms: Operating System Installation Kit Processor(s) Windows 10 x64 EdgeDataStore.msi Intel/AMD Intel AMD 64-bit processors Debian 9 or later x64 EdgeDataStore_linux-x64.deb Intel/AMD Intel AMD 64-bit processors Debian 9 or later arm32 EdgeDataStore_linux-arm.deb Arm 32-bit processors Debian 9 or later arm64 EdgeDataStore_linux-arm64.deb Arm 64-bit processors Alternatively, tar.gz files with binaries are available, which can be used to build your own custom installers or containers for Linux. For more information on installing EDS with Docker containers, see Install Edge Data Store using Docker ."
                                                     },
    "zArchive/Schemas/Storage_schema.html":  {
                                                 "href":  "zArchive/Schemas/Storage_schema.html",
                                                 "title":  "Sample Storage configuration",
                                                 "keywords":  "Sample Storage configuration \"Storage\": { \"Runtime\": { \"streamStorageLimitMb\": 2, \"streamStorageTargetMb\": 1, \"ingressDebugExpiration\": \"0001-01-01T00:00:00\" }, \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"PeriodicEgressEndpoints\": [] } Storage configuration properties Property Type Required Nullable Defined by Runtime StorageRuntimeConfiguration Optional Yes StorageRuntimeConfiguration Logging StorageLoggingConfiguration Optional Yes StorageLoggingConfiguration PeriodicEgressEndpoints [PeriodicEgressEndpointsConfiguration] Optional Yes PeriodicEgressEndpointsConfiguration"
                                             },
    "zArchive/Schemas/Storage_Runtime_schema.html":  {
                                                         "href":  "zArchive/Schemas/Storage_Runtime_schema.html",
                                                         "title":  "Sample storage runtime configuration",
                                                         "keywords":  "Sample storage runtime configuration { \"StreamStorageLimitMb\": 2, \"StreamStorageTargetMb\": 1, \"IngressDebugExpiration\": \"0001-01-01T00:00:00\" } Storage runtime configuration properties Property Type Required Nullable Defined by IngressDebugExpiration string Required No StorageRuntimeConfiguration (this schema) StreamStorageLimitMb integer Required No StorageRuntimeConfiguration (this schema) StreamStorageTargetMb integer Required No StorageRuntimeConfiguration (this schema) IngressDebugExpiration Ingress Debug Expiration is a property that can be used when debugging OMF. If the date and time is the future incoming OMF messages will be logged until the date and time specified. Once the configured time is past OMF messages will no longer be logged for debugging purposes. IngressDebugExpiration type string format: date-time ??? date and time (according to RFC 3339, section 5.6 ) minimum length: 1 characters StreamStorageLimitMb StreamStorageLimitMb is the maximum size in megabytes that a stream can reach. When a stream exceeds the size specified, older data will be deleted from the file. Data will be removed from the stream until the stream is at or below the StreamStorageTargetMb value. It is recommended that the target value be smaller than the limit since trimming can be an expensive operation and should be done infrequently. StreamStorageLimitMb type integer minimum value: 2 maximum value: 2147483647 StreamStorageTargetMb StreamStorageTargetMb is the size in megabytes that a stream will be reduced to after StreamStorageLimitMb size is reached for a single stream. When a stream exceeds the size specified, older data will be deleted from the file. Data will be removed from the stream until the stream is at or below the StreamStorageTargetMb value. It is recommended that the target value be smaller than the limit since trimming can be an expensive operation and should be done infrequently. StreamStorageTargetMb type integer minimum value: 1 maximum value: 2147483647 Note: All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required IngressDebugExpiration string Required StreamStorageLimitMb integer Required StreamStorageTargetMb integer Required"
                                                     },
    "V1/SDS/Write data/Writing_Data_API_1-0.html":  {
                                                        "href":  "V1/SDS/Write data/Writing_Data_API_1-0.html",
                                                        "title":  "Write data API",
                                                        "keywords":  "Write data API The following example API calls show different methods for writing data. Example type, stream, and data The descriptions of the following API methods contain example requests and responses in JSON to highlight usage and specific behaviors. The following type, stream, and data are used in the examples: Example type SimpleType is an SdsType with a single index and two additional properties. This type is defined in Python and Javascript: Python class State(Enum): Ok = 0 Warning = 1 Alarm = 2 class SimpleType(object): Time = property(getTime, setTime) def getTime(self): return self.__time def setTime(self, time): self.__time = time State = property(getState, setState) def getState(self): return self.__state def setState(self, state): self.__state = state Measurement = property(getValue, setValue) def getValue(self): return self.__measurement def setValue(self, measurement): self.__measurement = measurement JavaScript var State = { Ok: 0, Warning: 1, Alarm: 2, } var SimpleType = function () { this.Time = null; this.State = null; this.Value = null; } Example stream Simple is an SdsStream of type SimpleType . Example data Simple has stored values as follows: 11/23/2017 11 23 2017 12:00:00 PM: Ok 0 11/23/2017 11 23 2017 1:00:00 PM: Ok 10 11/23/2017 11 23 2017 2:00:00 PM: Ok 20 11/23/2017 11 23 2017 3:00:00 PM: Ok 30 11/23/2017 11 23 2017 4:00:00 PM: Ok 40 All times are represented at offset 0, GMT. Insert Values Inserts data into the specified stream. Returns an error if data is already present at the index of any event. Request POST api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. Request body A serialized list of one or more events of the stream type. Response The response includes a status code. Note: This request will return an error if an event already exists for any index in the request. If any individual index encounters a problem, the entire operation is rolled back and no insertions are made. The streamId and index that caused the issue are included in the error response. Example The following request is used to insert events into stream Simple of SimpleType , POST api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data The request body specifies the values to insert: [ { \"Time\": \"2017-11-23T17:00:00Z\", \"State\": 0, \"Measurement\": 50 }, { \"Time\": \"2017-11-23T18:00:00Z\", \"State\": 0, \"Measurement\": 60 } ] Patch Values Modifies the specified stream event(s). Patching affects only the data item parameters that are included in the call. Request PATCH api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data ?select={selectExpression} Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. string selectExpression Comma-separated list of strings that indicates the event fields to be changed in stream events. Request body A serialized collection of one or more patch property events. Response The response includes a status code. Consider you have a stream Simple of SimpleType , to change one property, Measurement , for one event specify the following request: PATCH api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?select=measurement With the following request body, [ { \"Time\":\"2017-11-23T12:00:00Z\", \"Measurement\":500.0 } ] This request will only change the Measurement value at the specified event index. Note: Patching is used to patch the events of the selected fields for one or more events in the stream. Only the fields indicated in selectExpression are modified. The events to be modified are indicated by the index value of each entry in the collection. If there is a problem patching any individual event, the entire operation is rolled back and the error will indicate the streamId and index of the problem. Remove Values There are two options for specifying which events to remove from a stream: Index Collection : One or more indexes can be specified in the request. Window : A window can be specified with a start index and end index. Index Collection Removes the event at each index from the specified stream. Different overloads are available to make it easier to indicate the index where you want to remove a data event. Request DELETE api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data ?index={index}[\u0026index={index}???] Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. string index One or more indexes of events to remove. Response The response includes a status code. Note: If any individual event fails to be removed, the entire operation is rolled back and no events are removed. The streamId and index that caused the issue are included in the error response. If you attempt to remove events at indexes that have no events, an error is returned. If this occurs, you can use Window request format to remove any events from a specified ???window??? of indexes, which will not return an error if no data is found. Window Removes events at and between the start index and end index. Request DELETE api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data ?startIndex={startIndex}\u0026endIndex={endIndex} Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. string startIndex The index defining the beginning of the window. string endIndex The index defining the end of the window. Response The response includes a status code. Note: If any individual event fails to be removed, the entire operation is rolled back and no removes are done. Replace Values Writes one or more events over existing events in the specified stream. Request PUT api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data ?allowCreate=false Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. Request body A serialized list of one or more events of the stream type. Response The response includes a status code. Note: This request returns an error if the stream does not have an event to be replaced at the specified index. If any individual event fails to be replaced, the entire operation is rolled back and no replaces are performed. The index that caused the issue and the streamId are included in the error response. Update Values Writes one or more events to the specified stream. Request PUT api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Parameters string namespaceId The namespace; either default or diagnostics. string streamId The stream identifier. Request body A serialized list of one or more events of the stream type. Response The response includes a status code. Note: This request performs an insert or a replace depending on whether an event already exists at the event indexes. If any item fails to write, the entire operation is rolled back and no events are written to the stream. The index that caused the issue is included in the error response."
                                                    },
    "V1/SDS/Read data/table_format_1-0.html":  {
                                                   "href":  "V1/SDS/Read data/table_format_1-0.html",
                                                   "title":  "Table format",
                                                   "keywords":  "Table format Results of a query can be organized into tables by directing the form parameter to return a table. Two forms of table are available: table and header table. Apply the table format to any read that returns multiple values and summaries by setting the form variable to specify a table or a table with headers. When the form parameter is specified as table , ?form=table , events are returned in row column form. Results include a collection named Columns that lists column name and type and a collection named Rows containing a collection of rows matching the order of the columns. Specifying a form of type table-headers , ?form=tableh , results in a collection where the Rows collection contains a column header list. The following is a request to retrieve values using the window parameters: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-04-01T07:00:00Z\u0026endIndex=2017-04-01T07:10:00Z The following response would be returned from the above code: Content-Type: application/json application json [ { \"Time\":\"2017-04-01T07:00:00Z\", \"State\":1 }, { \"Time\":\"2017-04-01T07:01:00Z\", \"State\":1, \"Measurement\":1.0 }, { \"Time\":\"2017-04-01T07:02:00Z\", \"State\":1, \"Measurement\":2.0 }, { \"Time\":\"2017-04-01T07:03:00Z\", \"State\":1, \"Measurement\":3.0 }, { \"Time\":\"2017-04-01T07:04:00Z\", \"State\":1, \"Measurement\":4.0 }, { \"Time\":\"2017-04-01T07:05:00Z\", \"State\":1, \"Measurement\":5.0 }, { \"Time\":\"2017-04-01T07:06:00Z\", \"State\":1, \"Measurement\":6.0 }, { \"Time\":\"2017-04-01T07:07:00Z\", \"State\":1, \"Measurement\":7.0 }, { \"Time\":\"2017-04-01T07:08:00Z\", \"State\":1, \"Measurement\":8.0 }, { \"Time\":\"2017-04-01T07:09:00Z\", \"State\":1, \"Measurement\":9.0 } ] To retrieve the results in table format, add the form variable and specify table . GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-04-01T07:00:00Z\u0026endIndex=2017-04-01T07:10:00Z \u0026form=table Response Content-Type: application/json application json { \"Name\":\"Simple\", \"Columns\":[ { \"Name\":\"Time\", \"Type\":\"DateTime\" }, { \"Name\":\"State\", \"Type\":\"Int32Enum\" }, { \"Name\":\"Measurement\", \"Type\":\"Double\" } ], \"Rows\":[ [ \"2017-04-01T07:00:00Z\", 1, 0.0 ], [ \"2017-04-01T07:01:00Z\", 1, 1.0 ], [ \"2017-04-01T07:02:00Z\", 1, 2.0 ], [ \"2017-04-01T07:03:00Z\", 1, 3.0 ], [ \"2017-04-01T07:04:00Z\", 1, 4.0 ], [ \"2017-04-01T07:05:00Z\", 1, 5.0 ], [ \"2017-04-01T07:06:00Z\", 1, 6.0 ], [ \"2017-04-01T07:07:00Z\", 1, 7.0 ], [ \"2017-04-01T07:08:00Z\", 1, 8.0 ], [ \"2017-04-01T07:09:00Z\", 1, 9.0 ] ] } To retrieve the results in table format with column headers, add the form variable and specify tableh . GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-04-01T07:00:00Z\u0026endIndex=2017-04-01T07:10:00Z \u0026form=tableh Response Content-Type: application/json application json { \"Name\":\"Simple\", \"Columns\":[ { \"Name\":\"Time\", \"Type\":\"DateTime\" }, { \"Name\":\"State\", \"Type\":\"Int32Enum\" }, { \"Name\":\"Measurement\", \"Type\":\"Double\" } ], \"Rows\":[ [ \"Time\", \"State\", \"Measurement\" ], [ \"2017-04-01T07:00:00Z\", 1, 0.0 ], [ \"2017-04-01T07:01:00Z\", 1, 1.0 ], [ \"2017-04-01T07:02:00Z\", 1, 2.0 ], [ \"2017-04-01T07:03:00Z\", 1, 3.0 ], [ \"2017-04-01T07:04:00Z\", 1, 4.0 ], [ \"2017-04-01T07:05:00Z\", 1, 5.0 ], [ \"2017-04-01T07:06:00Z\", 1, 6.0 ], [ \"2017-04-01T07:07:00Z\", 1, 7.0 ], [ \"2017-04-01T07:08:00Z\", 1, 8.0 ], [ \"2017-04-01T07:09:00Z\", 1, 9.0 ] ] }"
                                               },
    "V1/Overview/OpcUaQuickStart_1-0.html":  {
                                                 "href":  "V1/Overview/OpcUaQuickStart_1-0.html",
                                                 "title":  "OPC UA EDS adapter quick start",
                                                 "keywords":  "OPC UA EDS adapter quick start The OPC UA EDS adapter is a component of Edge Data Store that defines connections to and receives data from OPC UA capable devices. The OPC UA EDS adapter can connect to multiple devices by defining one instance of the adapter for each device. The EDS installation includes the OPC UA EDS adapter and the option to add a single OPC UA EDS adapter instance. Add additional instances after installation using the system components configuration. For more information about installation, see Install Edge Data Store . To get started collecting data with an instance of the OPC UA EDS adapter, you need to configure the data source, which specifies the device connection, and the data selection, which specifies the data to collect. The following diagram depicts the data flow for a single instance of OPC UA EDS adapter instance: The adapter instance polls the OPC UA device and then collects data from the device. The adapter then sends the data to the storage component where it is held until it can be egressed to permanent storage in PI Server or OSIsoft Cloud Services. The adapter instance can be configured from the device where EDS is installed, and EDS collects health information about the adapter that can be egressed. Configure an OPC UA data source To configure a data source to connect an OPC UA device to an OPC UA EDS adapter instance, perform the following steps: Using a text editor, copy the example below to create a file in JSON format with the location of the OPC UA data source. { \"EndpointUrl\": \"opc.tcp://\u003cip \"opc.tcp:  \u003cip address\u003e:\u003cport - often 62541\u003e/\u003cserver 62541\u003e \u003cserver path\u003e\", \"UseSecureConnection\": false, \"UserName\": null, \"Password\": null, \"RootNodeIds\": null, \"IncomingTimestamp\": \"Source\", \"StreamIdPrefix\": \"OpcUa\" } Modify the values in the example to match your environment, including the IP address and port for the OPC UA data source. Save the file to the device with EDS installed using a file name based on the adapter instance name. For example, to use the adapter instance created during installation, which is OpcUa1, name the file OpcUa1Datasource.json . Run the following curl script from the directory where the file is located, updating the file name and the destination in the script if needed. curl -d \"@OpcUa1Datasource.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/OpcUa1/Datasource http:  localhost:5590 api v1 configuration OpcUa1 Datasource When the command completes successfully (a 204 message is returned by curl), the OPC UA data source has been created. If you receive a 400 error, check the data source JSON file for errors. If you receive a 404 or 500 error, check that Edge Data Store is running on the device. Configure OPC UA data selection When you create the data source file, the OPC UA adapter auto generates the data selection file, which lists all available streams in the designated data source. To configure the data selection file, perform the following steps: Save the data selection file to the local device and name it based on the adapter instance name. For example, to use the adapter instance created during installation, which is OpcUa1, name the file OpcUa1Dataselection.json . Open the file in a text editor. It should look similar to the following example: [{ \"Selected\": false, \"Name\": \"Cold Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.ColdSideInletTemperature\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Hot Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.HotSideInletTemperature\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Hot Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.HotSideOutletTemperature\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Cold Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1002.ColdSideInletTemperature\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Hot Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1002.HotSideOutletTemperature\", \"StreamId\": null } ] To ingress a stream to Edge Data Store, change the value of the Selected key from false to true . All streams in the auto generated data selection file are initially set to false . Save the the file. Run the following curl script from the directory where the file is located, updating the file name and destination in the script if needed: curl -d \"@OpcUa1Dataselection.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/OpcUa1/Dataselection http:  localhost:5590 api v1 configuration OpcUa1 Dataselection"
                                             },
    "V1/Overview/ModbusQuickStart_1-0.html":  {
                                                  "href":  "V1/Overview/ModbusQuickStart_1-0.html",
                                                  "title":  "Modbus TCP EDS adapter quick start",
                                                  "keywords":  "Modbus TCP EDS adapter quick start The Modbus TCP EDS adapter is a component of Edge Data Store that defines connections to and receives data from Modbus TCP capable devices. The Modbus TCP EDS adapter can connect to multiple devices by defining one instance of the adapter for each device. The EDS installation includes the Modbus TCP EDS adapter and the option to add a single Modbus TCP EDS adapter instance. Add additional instances after installation using the system components configuration. For more information about installation, see Install Edge Data Store . To get started collecting data with an instance of the Modbus TCP EDS adapter, you need to configure the data source, which specifies the device connection, and the data selection, which specifies the data to collect. The following diagram depicts the data flow of a single instance of Modbus TCP EDS adapter: The adapter instance requests data from the Modbus TCP device and then the device sends its data. The adapter sends the collected data to the storage component where it is held until it can be egressed to permanent storage in PI Server or OSIsoft Cloud Services. The adapter instance can be configured from the device where EDS is installed, and EDS collects health information about the adapter that can be egressed. Configure a Modbus TCP data source To configure a data source to connect a Modbus TCP device to the Modbus TCP EDS adapter instance, perform the following steps Using a text editor, copy the example below to create a file in JSON format to describe the location of the Modbus TCP data source. { \"IpAddress\": \"\u003cModbus IP Address\u003e\", \"Port\": \u003cPort - usually 502\u003e, \"ConnectTimeout\": 15000, \"ReconnectInterval\": 5000, \"RequestTimeout\": 9000, \"DelayBetweenRequests\": 0, \"MaxResponseDataLength\": 250 } Modify the values in the example to match your environment, including the IP address and port for the Modbus data source. Save the file to the device with EDS installed using a file name based on the adapter instance name. For example, to use the adapter instance created during installation, which is Modbus1, name the file Modbus1DataSource.json . Run the following curl script from the same directory where the file is located, updating the file name and destination in the script if needed. curl -d \"@Modbus1Datasource.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/Modbus1/Datasource http:  localhost:5590 api v1 configuration Modbus1 Datasource When the command completes successfully (a 204 is returned by curl), the Modbus TCP data source has been created. If you get a 400 error, check the JSON file for errors. If you receive a 404 or 500 error, check that EDS is running on the device. Configure Modbus TCP data selection After you create the data source file, select the streams to store in EDS by configuring Modbus data selection. To configure the data selection file, complete the following steps: Using a text editor, copy the example below to create a file in JSON format to define each stream to ingress to EDS. [{ \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 1, \"DataTypeCode\": 20, \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 2, \"DataTypeCode\": 20, \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 3, \"DataTypeCode\": 20, \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 4, \"DataTypeCode\": 20, \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 5, \"DataTypeCode\": 20, \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 } ] Modify the values in the example to match your environment. Save the file to the device with EDS installed using a file name based on the adapter instance name. For example, to use the adapter instance created during installation, which is Modbus1, name the file Modbus1DataSelection.json . Run the following curl script from the same directory where the file is located, updating the file name and the endpoint URL in the script if needed. curl -d \"@Modbus1Dataselection.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/Modbus1/Dataselection http:  localhost:5590 api v1 configuration Modbus1 Dataselection"
                                              },
    "V1/Overview/CommandLineLinuxQuickStart_1-0.html":  {
                                                            "href":  "V1/Overview/CommandLineLinuxQuickStart_1-0.html",
                                                            "title":  "Command line quick start - Linux",
                                                            "keywords":  "Command line quick start - Linux The EdgeCmd utility is OSIsoft\u0027s proprietary tool for configuring Edge Data Store from a command line. EdgeCmd must be installed on the device with Edge Data Store. For instructions on installing EdgeCmd, see the EdgeCmd utility help . Complete the following steps to access EdgeCmd on Linux: Open a command prompt. Enter the following command to start the edgecmd.exe tool from any directory. debian@beaglebone:~$ edgecmd help Type edgecmd help and press Enter. The EdgeCmd utility launches, displaying the following introductory material and a command prompt at the end: ************************************************************************************************************************ Welcome to OSIsoft Edge Data Store configuration utility. Utility version: 1.0.0.148 ************************************************************************************************************************ --------------------------------------------------------------------------------------------------------- Command-line options =\u003e \u0027Configuration\u0027, \u0027Help\u0027 --------------------------------------------------------------------------------------------------------- Please enter ID of a component you would like to configure or to get component specific help output. Example: ./edgecmd . edgecmd Help ComponentId ./edgecmd . edgecmd Configuration ComponentId To get set of components registered to the Edge Data Store please run: ./edgecmd . edgecmd Configuration System Components To configure the system, please use \u0027System\u0027 as the ComponentId. Example of getting System help output: ./edgecmd . edgecmd Help System Example of configuring System Logging level: ./edgecmd . edgecmd Configuration System logging LogLevel=Warning debian@beaglebone:~$"
                                                        }
}
